<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>TSP Manual add</title>
    <link>https://example.com</link>
    <description>TSP manual</description>


<item>
<title><![CDATA[My first publication: Quantum Immortality]]></title>
<link>https://disagreeableme.substack.com/p/my-first-publication-quantum-immortality</link>
<pubDate>Thu, 16 Oct 2025 22:41:36 -0300</pubDate>
<description><![CDATA[Title: My first publication: Quantum Immortality

URL Source: http://disagreeableme.substack.com/p/my-first-publication-quantum-immortality

Published Time: 2025-09-29T20:13:10+00:00

Markdown Content:
[![Image 1](https://substackcdn.com/image/fetch/$s_!VzzG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd84cc8ce-0539-4048-a146-4a961f35f83b_345x511.png)](https://substackcdn.com/image/fetch/$s_!VzzG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd84cc8ce-0539-4048-a146-4a961f35f83b_345x511.png)

Encouraged by my friend Philip Goff, I’ve recently made a bit of an effort to publish something in a philosophy journal. Why? I’m not sure. I’m not an academic, so there’s no real incentive from a career point of view. But it’s an interesting challenge, and a way to prove to myself that perhaps I’m not a crank.

I found it to be an enjoyable and challenging process, so not that bad as a hobby. Especially now that I’ve had my first acceptance, from _Synthese_, on a paper outlining my perspective on the idea of quantum immortality (free [preprint here](https://philsci-archive.pitt.edu/26903/), paywalled [official version here](https://link.springer.com/article/10.1007/s11229-025-05304-z)).

Quantum immortality is, on the face of it, a dumb idea. The red-headed step-child (with apologies to any red-headed step-children reading this) of the Many Worlds Interpretation of quantum mechanics. No Everettian _wants_ it to be true, and so it is often dismissed. The problem is that, as far as I can see, none of the arguments against it hold water. In this paper, I tackle arguments against quantum immortality from David Papineau, David Wallace and Sean Carroll and aim to show that their position is inconsistent.

The idea of quantum immortality arises when thinking through some of the consequences of Everettian quantum mechanics, where every quantum measurement splits the world, including you. This is often illustrated with the example of Schrödinger’s cat, where just such a measurement results in a cat either living or dying. You either find yourself on a branch where the cat is alive or where it is dead. But what if you’re the cat? The suggestion of quantum immortality is that the cat should always expect to survive, because a dead cat makes no observations.

This can be thought of in terms of a quantum suicide thought experiment, where you play a game of quantum Russian roulette with a gun which kills you instantly if it measures spin-up on an appropriately prepared electron—a quantum coin-flip. If you keep repeating this experiment, then, from an objective point of view, you would not expect to survive very long. But if quantum immortality is right, then, from your own point of view, you will always survive.

In the paper, I look at two questions we might want to ask regarding quantum immortality. First, suppose that I engage in such a repeated quantum suicide experiment, and find that I survive after many rounds. If we rule out the idea that the apparatus is not working as expected, does my unlikely survival provide me with evidence that Everettian quantum mechanics is right? And second, does it give me reason to believe that my luck will continue, because of quantum immortality?

David Papineau takes on the first question, of whether quantum immortality can provide evidence of the many worlds interpretation, and says that it cannot. I draw a parallel between the argument he presents and Roger White’s argument that the fine-tuning of the constants cannot provide evidence for a cosmological multiverse. This is interesting because White’s argument is not likely to be readily accepted by Everettians, for various reason. Both arguments work by pointing out that the hypothesis that there are many other instances in the multiverse where things work out differently doesn’t explain why things have worked out so suspiciously to your advantage in _this_ universe. Specifically, for Papineau, that the many worlds interpretation is true doesn’t make it any more likely that this specific copy of you would survive, and so it is just as much a freak coincidence as if the many worlds interpretation were not true.

My argument against this is detailed and technical, but it boils down to this: the only way to make sense of the idea that things could have gone otherwise is if we posit a mysterious sense of personal identity, or _haecceity_, to differentiate the different versions of you, allowing us to track which is which irrespective of their qualities. For example, if we label two versions of you as you-alpha and you-beta, maybe you-alpha dies and you-beta survives, and then you-beta considers themselves lucky it turned out this way.

But without such a posit, all we have left are the qualitative differences. There’s the dead you, and the surviving you, and that’s all there is to it. It is a tautology that the surviving you survives, so it is not surprising. Conversely, if you’re not duplicating all the time, then it is surprising that there should be a surviving you at all. This is why I think that survival is evidence for many worlds.

So it would seem that it’s up in the air, depending on whether we accept haecceities (or something like them). The problem for the targets of my paper—Papineau, Carroll and Wallace—is that they are all on record as being _against_ haecceities. And for good reason! Everettianism is for them motivated by parsimony, as the picture that emerges if we accept the unitary evolution of the wavefunction and discard unnecessary complications such as collapse postulates or hidden variables. Haecceities are just the sort of unnecessary complication that Everettians typically prefer to do without. As such, while Papineau’s view here is defensible, it comes with a cost he may not be willing to pay.

For the other question, about whether you should expect to survive, all three of my targets have been dismissive. There’s a lot to address here, but I suppose the easiest way of summing up the general attitude is to note that the Born rule is what we use to make predictions in quantum mechanics, and the Born rule says you should expect to die with overwhelming probability in a repeated quantum suicide experiment. For my targets, there is no motivation to deviate from the Born rule, and so quantum immortality is silly.

The Born rule tells us what we should expect to _happen_. But, as I argue in the paper, there is another question we could ask: what should you expect to _experience_? If death cannot be experienced, then the Born rule cannot be telling us what to expect to experience in cases of quantum suicide, because the Born rule will assign a high probability to an outcome that cannot be experienced. If many worlds is not true, we might, I suppose, expect experience to end. But if many worlds is true, then there is always some branch where experience continues, and so we cannot expect experience to end. Even if experience ends on a particular branch, all three of my targets seem to follow Parfit’s view that what matters for survival is psychological continuity and not physical continuity in a particular location. Only in many worlds are we guaranteed that somewhere in the multiverse there will always be a psychological successor, so that we should expect to experience immortality.

If there are two versions of the question of what to expect—what to expect to happen versus what to expect to experience—then it seems we are at an impasse. But then we are faced with a meta-question: which is the right question to ask? Which question should I really care about? To me, this looks like a Humean is/ought problem. If reason is the slave of the passions, then these look like alternative passions, not a question reason can mediate. Different agents might want to ask different questions. We can rule out quantum immortality as irrational only by adopting some incompatible axiom of rationality, such as that rational agents must care only about what will happen in all branches, and not only about what will happen in branches they experience. But this sort of ad hoc move again runs counter to the parsimonious spirit of the Everettianism promoted by the targets of the paper.

I close out my argument by sketching a science-fictional scenario designed to pump our intuitions towards quantum immortality. I won’t recapitulate the scenario here, but you can find it in the preprint starting 2/3 of the way down page 17. If this scenario does what it’s supposed to do , then in these circumstances it will seem to you that it only makes sense to care about what will be experienced, and not about what will happen from a more objective point of view. At least, that is how the scenario strikes me—your mileage may vary. But if you agree, then there is at least one case where quantum immortality seems to be the right way to think about survival. And if there is at least one such scenario, then perhaps quantum immortality is an idea Everettians should be taking more seriously in general.

As I said, quantum immortality is not something Everettians _want_ to be true. Not only is it counter-intuitive and absurd, it’s not good news, really. On the worst interpretation, it means that subjective death is impossible not only in idealised quantum suicide experiments but in general, because everything that happens at a macroscopic scale ultimately supervenes on microscopic quantum events that can play out in many ways. In that case, we are each condemned to live forever, long after we have tired of life, ultimately in a world where everything and everyone we love has passed away. I’m not looking forward to ending up as essentially a Boltzmann brain eking out a miserable eternal existence in the heat death epoch. As an Everettian myself, I want there to be good arguments against quantum immortality. But the arguments presented so far are not good.
]]></description>
</item>
<item>
<title><![CDATA[ C R Y P T O N O M I C O N]]></title>
<link>https://web.stanford.edu/class/cs81n/command.txt</link>
<pubDate>Thu, 16 Oct 2025 22:48:44 -0300</pubDate>
<description><![CDATA[Title: 

URL Source: http://web.stanford.edu/class/cs81n/command.txt

Published Time: Fri, 10 Apr 2015 01:19:05 GMT

Markdown Content:
In the Beginning was the Command Line

by Neal Stephenson


About twenty years ago Jobs and Wozniak, the founders of Apple, came up with the very strange idea of selling information processing machines for use in the home. The business took off, and its founders made a lot of money and received the credit they deserved for being daring visionaries. But around the same time, Bill Gates and Paul Allen came up with an idea even stranger and more fantastical: selling computer operating systems. This was much weirder than the idea of Jobs and Wozniak. A computer at least had some sort of physical reality to it. It came in a box, you could open it up and plug it in and watch lights blink. An operating system had no tangible incarnation at all. It arrived on a disk, of course, but the disk was, in effect, nothing more than the box that the OS came in. The product itself was a very long string of ones and zeroes that, when properly installed and coddled, gave you the ability to manipulate other very long strings of ones and zeroes. Even those few who actually understood what a computer operating system was were apt to think of it as a fantastically arcane engineering prodigy, like a breeder reactor or a U-2 spy plane, and not something that could ever be (in the parlance of high-tech) "productized."

Yet now the company that Gates and Allen founded is selling operating systems like Gillette sells razor blades. New releases of operating systems are launched as if they were Hollywood blockbusters, with celebrity endorsements, talk show appearances, and world tours. The market for them is vast enough that people worry about whether it has been monopolized by one company. Even the least technically-minded people in our society now have at least a hazy idea of what operating systems do; what is more, they have strong opinions about their relative merits. It is commonly understood, even by technically unsophisticated computer users, that if you have a piece of software that works on your Macintosh, and you move it over onto a Windows machine, it will not run. That this would, in fact, be a laughable and idiotic mistake, like nailing horseshoes to the tires of a Buick.

A person who went into a coma before Microsoft was founded, and woke up now, could pick up this morning's New York Times and understand everything in it--almost:


Item: the richest man in the world made his fortune from-what? Railways? Shipping? Oil? No, operating systems. Item: the Department of Justice is tackling Microsoft's supposed OS monopoly with legal tools that were invented to restrain the power of Nineteenth-Century robber barons. Item: a woman friend of mine recently told me that she'd broken off a (hitherto) stimulating exchange of e-mail with a young man. At first he had seemed like such an intelligent and interesting guy, she said, but then "he started going all PC-versus-Mac on me."

What the hell is going on here? And does the operating system business have a future, or only a past? Here is my view, which is entirely subjective; but since I have spent a fair amount of time not only using, but programming, Macintoshes, Windows machines, Linux boxes and the BeOS, perhaps it is not so ill-informed as to be completely worthless. This is a subjective essay, more review than research paper, and so it might seem unfair or biased compared to the technical reviews you can find in PC magazines. But ever since the Mac came out, our operating systems have been based on metaphors, and anything with metaphors in it is fair game as far as I'm concerned.


MGBs, TANKS, AND BATMOBILES

Around the time that Jobs, Wozniak, Gates, and Allen were dreaming up these unlikely schemes, I was a teenager living in Ames, Iowa. One of my friends' dads had an old MGB sports car rusting away in his garage. Sometimes he would actually manage to get it running and then he would take us for a spin around the block, with a memorable look of wild youthful exhiliration on his face; to his worried passengers, he was a madman, stalling and backfiring around Ames, Iowa and eating the dust of rusty Gremlins and Pintos, but in his own mind he was Dustin Hoffman tooling across the Bay Bridge with the wind in his hair.

In retrospect, this was telling me two things about people's relationship to technology. One was that romance and image go a long way towards shaping their opinions. If you doubt it (and if you have a lot of spare time on your hands) just ask anyone who owns a Macintosh and who, on those grounds, imagines him- or herself to be a member of an oppressed minority group.

The other, somewhat subtler point, was that interface is very important. Sure, the MGB was a lousy car in almost every way that counted: balky, unreliable, underpowered. But it was fun to drive. It was responsive. Every pebble on the road was felt in the bones, every nuance in the pavement transmitted instantly to the driver's hands. He could listen to the engine and tell what was wrong with it. The steering responded immediately to commands from his hands. To us passengers it was a pointless exercise in going nowhere--about as interesting as peering over someone's shoulder while he punches numbers into a spreadsheet. But to the driver it was an experience. For a short time he was extending his body and his senses into a larger realm, and doing things that he couldn't do unassisted.

The analogy between cars and operating systems is not half bad, and so let me run with it for a moment, as a way of giving an executive summary of our situation today.

Imagine a crossroads where four competing auto dealerships are situated. One of them (Microsoft) is much, much bigger than the others. It started out years ago selling three-speed bicycles (MS-DOS); these were not perfect, but they worked, and when they broke you could easily fix them.

There was a competing bicycle dealership next door (Apple) that one day began selling motorized vehicles--expensive but attractively styled cars with their innards hermetically sealed, so that how they worked was something of a mystery.

The big dealership responded by rushing a moped upgrade kit (the original Windows) onto the market. This was a Rube Goldberg contraption that, when bolted onto a three-speed bicycle, enabled it to keep up, just barely, with Apple-cars. The users had to wear goggles and were always picking bugs out of their teeth while Apple owners sped along in hermetically sealed comfort, sneering out the windows. But the Micro-mopeds were cheap, and easy to fix compared with the Apple-cars, and their market share waxed.

Eventually the big dealership came out with a full-fledged car: a colossal station wagon (Windows 95). It had all the aesthetic appeal of a Soviet worker housing block, it leaked oil and blew gaskets, and it was an enormous success. A little later, they also came out with a hulking off-road vehicle intended for industrial users (Windows NT) which was no more beautiful than the station wagon, and only a little more reliable.

Since then there has been a lot of noise and shouting, but little has changed. The smaller dealership continues to sell sleek Euro-styled sedans and to spend a lot of money on advertising campaigns. They have had GOING OUT OF BUSINESS! signs taped up in their windows for so long that they have gotten all yellow and curly. The big one keeps making bigger and bigger station wagons and ORVs.

On the other side of the road are two competitors that have come along more recently.

One of them (Be, Inc.) is selling fully operational Batmobiles (the BeOS). They are more beautiful and stylish even than the Euro-sedans, better designed, more technologically advanced, and at least as reliable as anything else on the market--and yet cheaper than the others.

With one exception, that is: Linux, which is right next door, and which is not a business at all. It's a bunch of RVs, yurts, tepees, and geodesic domes set up in a field and organized by consensus. The people who live there are making tanks. These are not old-fashioned, cast-iron Soviet tanks; these are more like the M1 tanks of the U.S. Army, made of space-age materials and jammed with sophisticated technology from one end to the other. But they are better than Army tanks. They've been modified in such a way that they never, ever break down, are light and maneuverable enough to use on ordinary streets, and use no more fuel than a subcompact car. These tanks are being cranked out, on the spot, at a terrific pace, and a vast number of them are lined up along the edge of the road with keys in the ignition. Anyone who wants can simply climb into one and drive it away for free.

Customers come to this crossroads in throngs, day and night. Ninety percent of them go straight to the biggest dealership and buy station wagons or off-road vehicles. They do not even look at the other dealerships.

Of the remaining ten percent, most go and buy a sleek Euro-sedan, pausing only to turn up their noses at the philistines going to buy the station wagons and ORVs. If they even notice the people on the opposite side of the road, selling the cheaper, technically superior vehicles, these customers deride them cranks and half-wits.

The Batmobile outlet sells a few vehicles to the occasional car nut who wants a second vehicle to go with his station wagon, but seems to accept, at least for now, that it's a fringe player.

The group giving away the free tanks only stays alive because it is staffed by volunteers, who are lined up at the edge of the street with bullhorns, trying to draw customers' attention to this incredible situation. A typical conversation goes something like this:

Hacker with bullhorn: "Save your money! Accept one of our free tanks! It is invulnerable, and can drive across rocks and swamps at ninety miles an hour while getting a hundred miles to the gallon!"

Prospective station wagon buyer: "I know what you say is true...but...er...I don't know how to maintain a tank!"

Bullhorn: "You don't know how to maintain a station wagon either!"

Buyer: "But this dealership has mechanics on staff. If something goes wrong with my station wagon, I can take a day off work, bring it here, and pay them to work on it while I sit in the waiting room for hours, listening to elevator music."

Bullhorn: "But if you accept one of our free tanks we will send volunteers to your house to fix it for free while you sleep!"

Buyer: "Stay away from my house, you freak!"

Bullhorn: "But..."

Buyer: "Can't you see that everyone is buying station wagons?"


BIT-FLINGER


The connection between cars, and ways of interacting with computers, wouldn't have occurred to me at the time I was being taken for rides in that MGB. I had signed up to take a computer programming class at Ames High School. After a few introductory lectures, we students were granted admission into a tiny room containing a teletype, a telephone, and an old-fashioned modem consisting of a metal box with a pair of rubber cups on the top (note: many readers, making their way through that last sentence, probably felt an initial pang of dread that this essay was about to turn into a tedious, codgerly reminiscence about how tough we had it back in the old days; rest assured that I am actually positioning my pieces on the chessboard, as it were, in preparation to make a point about truly hip and up-to-the minute topics like Open Source Software). The teletype was exactly the same sort of machine that had been used, for decades, to send and receive telegrams. It was basically a loud typewriter that could only produce UPPERCASE LETTERS. Mounted to one side of it was a smaller machine with a long reel of paper tape on it, and a clear plastic hopper underneath.

In order to connect this device (which was not a computer at all) to the Iowa State University mainframe across town, you would pick up the phone, dial the computer's number, listen for strange noises, and then slam the handset down into the rubber cups. If your aim was true, one would wrap its neoprene lips around the earpiece and the other around the mouthpiece, consummating a kind of informational soixante-neuf.  The teletype would shudder as it was possessed by the spirit of the distant mainframe, and begin to hammer out cryptic messages.

Since computer time was a scarce resource, we used a sort of batch processing technique. Before dialing the phone, we would turn on the tape puncher (a subsidiary machine bolted to the side of the teletype) and type in our programs. Each time we depressed a key, the teletype would bash out a letter on the paper in front of us, so we could read what we'd typed; but at the same time it would convert the letter into a set of eight binary digits, or bits, and punch a corresponding pattern of holes across the width of a paper tape. The tiny disks of paper knocked out of the tape would flutter down into the clear plastic hopper, which would slowly fill up what can only be described as actual bits. On the last day of the school year, the smartest kid in the class (not me) jumped out from behind his desk and flung several quarts of these bits over the head of our teacher, like confetti, as a sort of semi-affectionate practical joke. The image of this man sitting there, gripped in the opening stages of an atavistic fight-or-flight reaction, with millions of bits (megabytes) sifting down out of his hair and into his nostrils and mouth, his face gradually turning purple as he built up to an explosion, is the single most memorable scene from my formal education.

Anyway, it will have been obvious that my interaction with the computer was of an extremely formal nature, being sharply divided up into different phases, viz.: (1) sitting at home with paper and pencil, miles and miles from any computer, I would think very, very hard about what I wanted the computer to do, and translate my intentions into a computer language--a series of alphanumeric symbols on a page. (2) I would carry this across a sort of informational cordon sanitaire (three miles of snowdrifts) to school and type those letters into a machine--not a computer--which would convert the symbols into binary numbers and record them visibly on a tape. (3) Then, through the rubber-cup modem, I would cause those numbers to be sent to the university mainframe, which would (4) do arithmetic on them and send different numbers back to the teletype. (5) The teletype would convert these numbers back into letters and hammer them out on a page and (6) I, watching, would construe the letters as meaningful symbols.

The division of responsibilities implied by all of this is admirably clean: computers do arithmetic on bits of information. Humans construe the bits as meaningful symbols. But this distinction is now being blurred, or at least complicated, by the advent of modern operating systems that use, and frequently abuse, the power of metaphor to make computers accessible to a larger audience. Along the way--possibly because of those metaphors, which make an operating system a sort of work of art--people start to get emotional, and grow attached to pieces of software in the way that my friend's dad did to his MGB.

People who have only interacted with computers through graphical user interfaces like the MacOS or Windows--which is to say, almost everyone who has ever used a computer--may have been startled, or at least bemused, to hear about the telegraph machine that I used to communicate with a computer in 1973. But there was, and is, a good reason for using this particular kind of technology. Human beings have various ways of communicating to each other, such as music, art, dance, and facial expressions, but some of these are more amenable than others to being expressed as strings of symbols. Written language is the easiest of all, because, of course, it consists of strings of symbols to begin with. If the symbols happen to belong to a phonetic alphabet (as opposed to, say, ideograms), converting them into bits is a trivial procedure, and one that was nailed, technologically, in the early nineteenth century, with the introduction of Morse code and other forms of telegraphy.

We had a human/computer interface a hundred years before we had computers. When computers came into being around the time of the Second World War, humans, quite naturally, communicated with them by simply grafting them on to the already-existing technologies for translating letters into bits and vice versa: teletypes and punch card machines.

These embodied two fundamentally different approaches to computing. When you were using cards, you'd punch a whole stack of them and run them through the reader all at once, which was called batch processing. You could also do batch processing with a teletype, as I have already described, by using the paper tape reader, and we were certainly encouraged to use this approach when I was in high school. But--though efforts were made to keep us unaware of this--the teletype could do something that the card reader could not. On the teletype, once the modem link was established, you could just type in a line and hit the return key. The teletype would send that line to the computer, which might or might not respond with some lines of its own, which the teletype would hammer out--producing, over time, a transcript of your exchange with the machine. This way of doing it did not even have a name at the time, but when, much later, an alternative became available, it was retroactively dubbed the Command Line Interface.

When I moved on to college, I did my computing in large, stifling rooms where scores of students would sit in front of slightly updated versions of the same machines and write computer programs: these used dot-matrix printing mechanisms, but were (from the computer's point of view) identical to the old teletypes. By that point, computers were better at time-sharing--that is, mainframes were still mainframes, but they were better at communicating with a large number of terminals at once. Consequently, it was no longer necessary to use batch processing. Card readers were shoved out into hallways and boiler rooms, and batch processing became a nerds-only kind of thing, and consequently took on a certain eldritch flavor among those of us who even knew it existed. We were all off the Batch, and on the Command Line, interface now--my very first shift in operating system paradigms, if only I'd known it.

A huge stack of accordion-fold paper sat on the floor underneath each one of these glorified teletypes, and miles of paper shuddered through their platens. Almost all of this paper was thrown away or recycled without ever having been touched by ink--an ecological atrocity so glaring that those machines soon replaced by video terminals--so-called "glass teletypes"--which were quieter and didn't waste paper. Again, though, from the computer's point of view these were indistinguishable from World War II-era teletype machines. In effect we still used Victorian technology to communicate with computers until about 1984, when the Macintosh was introduced with its Graphical User Interface. Even after that, the Command Line continued to exist as an underlying stratum--a sort of brainstem reflex--of many modern computer systems all through the heyday of Graphical User Interfaces, or GUIs as I will call them from now on.


GUIs


Now the first job that any coder needs to do when writing a new piece of software is to figure out how to take the information that is being worked with (in a graphics program, an image; in a spreadsheet, a grid of numbers) and turn it into a linear string of bytes. These strings of bytes are commonly called files or (somewhat more hiply) streams. They are to telegrams what modern humans are to Cro-Magnon man, which is to say the same thing under a different name. All that you see on your computer screen--your Tomb Raider, your digitized voice mail messages, faxes, and word processing documents written in thirty-seven different typefaces--is still, from the computer's point of view, just like telegrams, except much longer, and demanding of more arithmetic.

The quickest way to get a taste of this is to fire up your web browser, visit a site, and then select the View/Document Source menu item. You will get a bunch of computer code that looks something like this:

  C R Y P T O N O M I C O N

===============
      
 ![Image 1](http://web.stanford.edu/class/cs81n/command.txt) ![Image 2](http://web.stanford.edu/class/cs81n/command.txt)
 This crud is called HTML (HyperText Markup Language) and it is basically a very simple programming language instructing your web browser how to draw a page on a screen. Anyone can learn HTML and many people do. The important thing is that no matter what splendid multimedia web pages they might represent, HTML files are just telegrams. When Ronald Reagan was a radio announcer, he used to call baseball games by reading the terse descriptions that trickled in over the telegraph wire and were printed out on a paper tape. He would sit there, all by himself in a padded room with a microphone, and the paper tape would eke out of the machine and crawl over the palm of his hand printed with cryptic abbreviations. If the count went to three and two, Reagan would describe the scene as he saw it in his mind's eye: "The brawny left-hander steps out of the batter's box to wipe the sweat from his brow. The umpire steps forward to sweep the dirt from home plate." and so on. When the cryptogram on the paper tape announced a base hit, he would whack the edge of the table with a pencil, creating a little sound effect, and describe the arc of the ball as if he could actually see it. His listeners, many of whom presumably thought that Reagan was actually at the ballpark watching the game, would reconstruct the scene in their minds according to his descriptions. This is exactly how the World Wide Web works: the HTML files are the pithy description on the paper tape, and your Web browser is Ronald Reagan. The same is true of Graphical User Interfaces in general. So an OS is a stack of metaphors and abstractions that stands between you and the telegrams, and embodying various tricks the programmer used to convert the information you're working with--be it images, e-mail messages, movies, or word processing documents--into the necklaces of bytes that are the only things computers know how to work with. When we used actual telegraph equipment (teletypes) or their higher-tech substitutes ("glass teletypes," or the MS-DOS command line) to work with our computers, we were very close to the bottom of that stack. When we use most modern operating systems, though, our interaction with the machine is heavily mediated. Everything we do is interpreted and translated time and again as it works its way down through all of the metaphors and abstractions. The Macintosh OS was a revolution in both the good and bad senses of that word. Obviously it was true that command line interfaces were not for everyone, and that it would be a good thing to make computers more accessible to a less technical audience--if not for altruistic reasons, then because those sorts of people constituted an incomparably vaster market. It was clear the the Mac's engineers saw a whole new country stretching out before them; you could almost hear them muttering, "Wow! We don't have to be bound by files as linear streams of bytes anymore, vive la revolution, let's see how far we can take this!" No command line interface was available on the Macintosh; you talked to it with the mouse, or not at all. This was a statement of sorts, a credential of revolutionary purity. It seemed that the designers of the Mac intended to sweep Command Line Interfaces into the dustbin of history. My own personal love affair with the Macintosh began in the spring of 1984 in a computer store in Cedar Rapids, Iowa, when a friend of mine--coincidentally, the son of the MGB owner--showed me a Macintosh running MacPaint, the revolutionary drawing program. It ended in July of 1995 when I tried to save a big important file on my Macintosh Powerbook and instead instead of doing so, it annihilated the data so thoroughly that two different disk crash utility programs were unable to find any trace that it had ever existed. During the intervening ten years, I had a passion for the MacOS that seemed righteous and reasonable at the time but in retrospect strikes me as being exactly the same sort of goofy infatuation that my friend's dad had with his car. The introduction of the Mac triggered a sort of holy war in the computer world. Were GUIs a brilliant design innovation that made computers more human-centered and therefore accessible to the masses, leading us toward an unprecedented revolution in human society, or an insulting bit of audiovisual gimcrackery dreamed up by flaky Bay Area hacker types that stripped computers of their power and flexibility and turned the noble and serious work of computing into a childish video game? This debate actually seems more interesting to me today than it did in the mid-1980s. But people more or less stopped debating it when Microsoft endorsed the idea of GUIs by coming out with the first Windows. At this point, command-line partisans were relegated to the status of silly old grouches, and a new conflict was touched off, between users of MacOS and users of Windows. There was plenty to argue about. The first Macintoshes looked different from other PCs even when they were turned off: they consisted of one box containing both CPU (the part of the computer that does arithmetic on bits) and monitor screen. This was billed, at the time, as a philosophical statement of sorts: Apple wanted to make the personal computer into an appliance, like a toaster. But it also reflected the purely technical demands of running a graphical user interface. In a GUI machine, the chips that draw things on the screen have to be integrated with the computer's central processing unit, or CPU, to a far greater extent than is the case with command-line interfaces, which until recently didn't even know that they weren't just talking to teletypes. This distinction was of a technical and abstract nature, but it became clearer when the machine crashed (it is commonly the case with technologies that you can get the best insight about how they work by watching them fail). When everything went to hell and the CPU began spewing out random bits, the result, on a CLI machine, was lines and lines of perfectly formed but random characters on the screen--known to cognoscenti as "going Cyrillic." But to the MacOS, the screen was not a teletype, but a place to put graphics; the image on the screen was a bitmap, a literal rendering of the contents of a particular portion of the computer's memory. When the computer crashed and wrote gibberish into the bitmap, the result was something that looked vaguely like static on a broken television set--a "snow crash." And even after the introduction of Windows, the underlying differences endured; when a Windows machine got into trouble, the old command-line interface would fall down over the GUI like an asbestos fire curtain sealing off the proscenium of a burning opera. When a Macintosh got into trouble it presented you with a cartoon of a bomb, which was funny the first time you saw it. And these were by no means superficial differences. The reversion of Windows to a CLI when it was in distress proved to Mac partisans that Windows was nothing more than a cheap facade, like a garish afghan flung over a rotted-out sofa. They were disturbed and annoyed by the sense that lurking underneath Windows' ostensibly user-friendly interface was--literally--a subtext. For their part, Windows fans might have made the sour observation that all computers, even Macintoshes, were built on that same subtext, and that the refusal of Mac owners to admit that fact to themselves seemed to signal a willingness, almost an eagerness, to be duped. Anyway, a Macintosh had to switch individual bits in the memory chips on the video card, and it had to do it very fast, and in arbitrarily complicated patterns. Nowadays this is cheap and easy, but in the technological regime that prevailed in the early 1980s, the only realistic way to do it was to build the motherboard (which contained the CPU) and the video system (which contained the memory that was mapped onto the screen) as a tightly integrated whole--hence the single, hermetically sealed case that made the Macintosh so distinctive. When Windows came out, it was conspicuous for its ugliness, and its current successors, Windows 95 and Windows NT, are not things that people would pay money to look at either. Microsoft's complete disregard for aesthetics gave all of us Mac-lovers plenty of opportunities to look down our noses at them. That Windows looked an awful lot like a direct ripoff of MacOS gave us a burning sense of moral outrage to go with it. Among people who really knew and appreciated computers (hackers, in Steven Levy's non-pejorative sense of that word) and in a few other niches such as professional musicians, graphic artists and schoolteachers, the Macintosh, for a while, was simply the computer. It was seen as not only a superb piece of engineering, but an embodiment of certain ideals about the use of technology to benefit mankind, while Windows was seen as a pathetically clumsy imitation and a sinister world domination plot rolled into one. So very early, a pattern had been established that endures to this day: people dislike Microsoft, which is okay; but they dislike it for reasons that are poorly considered, and in the end, self-defeating. CLASS STRUGGLE ON THE DESKTOP Now that the Third Rail has been firmly grasped, it is worth reviewing some basic facts here: like any other publicly traded, for-profit corporation, Microsoft has, in effect, borrowed a bunch of money from some people (its stockholders) in order to be in the bit business. As an officer of that corporation, Bill Gates has one responsibility only, which is to maximize return on investment. He has done this incredibly well. Any actions taken in the world by Microsoft-any software released by them, for example--are basically epiphenomena, which can't be interpreted or understood except insofar as they reflect Bill Gates's execution of his one and only responsibility. It follows that if Microsoft sells goods that are aesthetically unappealing, or that don't work very well, it does not mean that they are (respectively) philistines or half-wits. It is because Microsoft's excellent management has figured out that they can make more money for their stockholders by releasing stuff with obvious, known imperfections than they can by making it beautiful or bug-free. This is annoying, but (in the end) not half so annoying as watching Apple inscrutably and relentlessly destroy itself. Hostility towards Microsoft is not difficult to find on the Net, and it blends two strains: resentful people who feel Microsoft is too powerful, and disdainful people who think it's tacky. This is all strongly reminiscent of the heyday of Communism and Socialism, when the bourgeoisie were hated from both ends: by the proles, because they had all the money, and by the intelligentsia, because of their tendency to spend it on lawn ornaments. Microsoft is the very embodiment of modern high-tech prosperity--it is, in a word, bourgeois--and so it attracts all of the same gripes. The opening "splash screen" for Microsoft Word 6.0 summed it up pretty neatly: when you started up the program you were treated to a picture of an expensive enamel pen lying across a couple of sheets of fancy-looking handmade writing paper. It was obviously a bid to make the software look classy, and it might have worked for some, but it failed for me, because the pen was a ballpoint, and I'm a fountain pen man. If Apple had done it, they would've used a Mont Blanc fountain pen, or maybe a Chinese calligraphy brush. And I doubt that this was an accident. Recently I spent a while re-installing Windows NT on one of my home computers, and many times had to double-click on the "Control Panel" icon. For reasons that are difficult to fathom, this icon consists of a picture of a clawhammer and a chisel or screwdriver resting on top of a file folder. These aesthetic gaffes give one an almost uncontrollable urge to make fun of Microsoft, but again, it is all beside the point--if Microsoft had done focus group testing of possible alternative graphics, they probably would have found that the average mid-level office worker associated fountain pens with effete upper management toffs and was more comfortable with ballpoints. Likewise, the regular guys, the balding dads of the world who probably bear the brunt of setting up and maintaining home computers, can probably relate better to a picture of a clawhammer--while perhaps harboring fantasies of taking a real one to their balky computers. This is the only way I can explain certain peculiar facts about the current market for operating systems, such as that ninety percent of all customers continue to buy station wagons off the Microsoft lot while free tanks are there for the taking, right across the street. A string of ones and zeroes was not a difficult thing for Bill Gates to distribute, one he'd thought of the idea. The hard part was selling it--reassuring customers that they were actually getting something in return for their money. Anyone who has ever bought a piece of software in a store has had the curiously deflating experience of taking the bright shrink-wrapped box home, tearing it open, finding that it's 95 percent air, throwing away all the little cards, party favors, and bits of trash, and loading the disk into the computer. The end result (after you've lost the disk) is nothing except some images on a computer screen, and some capabilities that weren't there before. Sometimes you don't even have that--you have a string of error messages instead. But your money is definitely gone. Now we are almost accustomed to this, but twenty years ago it was a very dicey business proposition. Bill Gates made it work anyway. He didn't make it work by selling the best software or offering the cheapest price. Instead he somehow got people to believe that they were receiving something in exchange for their money. The streets of every city in the world are filled with those hulking, rattling station wagons. Anyone who doesn't own one feels a little weird, and wonders, in spite of himself, whether it might not be time to cease resistance and buy one; anyone who does, feels confident that he has acquired some meaningful possession, even on those days when the vehicle is up on a lift in an auto repair shop. All of this is perfectly congruent with membership in the bourgeoisie, which is as much a mental, as a material state. And it explains why Microsoft is regularly attacked, on the Net, from both sides. People who are inclined to feel poor and oppressed construe everything Microsoft does as some sinister Orwellian plot. People who like to think of themselves as intelligent and informed technology users are driven crazy by the clunkiness of Windows. Nothing is more annoying to sophisticated people to see someone who is rich enough to know better being tacky--unless it is to realize, a moment later, that they probably know they are tacky and they simply don't care and they are going to go on being tacky, and rich, and happy, forever. Microsoft therefore bears the same relationship to the Silicon Valley elite as the Beverly Hillbillies did to their fussy banker, Mr. Drysdale--who is irritated not so much by the fact that the Clampetts moved to his neighborhood as by the knowledge that, when Jethro is seventy years old, he's still going to be talking like a hillbilly and wearing bib overalls, and he's still going to be a lot richer than Mr. Drysdale. Even the hardware that Windows ran on, when compared to the machines put out by Apple, looked like white-trash stuff, and still mostly does. The reason was that Apple was and is a hardware company, while Microsoft was and is a software company. Apple therefore had a monopoly on hardware that could run MacOS, whereas Windows-compatible hardware came out of a free market. The free market seems to have decided that people will not pay for cool-looking computers; PC hardware makers who hire designers to make their stuff look distinctive get their clocks cleaned by Taiwanese clone makers punching out boxes that look as if they belong on cinderblocks in front of someone's trailer. But Apple could make their hardware as pretty as they wanted to and simply pass the higher prices on to their besotted consumers, like me. Only last week (I am writing this sentence in early Jan. 1999) the technology sections of all the newspapers were filled with adulatory press coverage of how Apple had released the iMac in several happenin' new colors like Blueberry and Tangerine. Apple has always insisted on having a hardware monopoly, except for a brief period in the mid-1990s when they allowed clone-makers to compete with them, before subsequently putting them out of business. Macintosh hardware was, consequently, expensive. You didn't open it up and fool around with it because doing so would void the warranty. In fact the first Mac was specifically designed to be difficult to open--you needed a kit of exotic tools, which you could buy through little ads that began to appear in the back pages of magazines a few months after the Mac came out on the market. These ads always had a certain disreputable air about them, like pitches for lock-picking tools in the backs of lurid detective magazines. This monopolistic policy can be explained in at least three different ways. THE CHARITABLE EXPLANATION is that the hardware monopoly policy reflected a drive on Apple's part to provide a seamless, unified blending of hardware, operating system, and software. There is something to this. It is hard enough to make an OS that works well on one specific piece of hardware, designed and tested by engineers who work down the hallway from you, in the same company. Making an OS to work on arbitrary pieces of hardware, cranked out by rabidly entrepeneurial clonemakers on the other side of the International Date Line, is very difficult, and accounts for much of the troubles people have using Windows. THE FINANCIAL EXPLANATION is that Apple, unlike Microsoft, is and always has been a hardware company. It simply depends on revenue from selling hardware, and cannot exist without it. THE NOT-SO-CHARITABLE EXPLANATION has to do with Apple's corporate culture, which is rooted in Bay Area Baby Boomdom. Now, since I'm going to talk for a moment about culture, full disclosure is probably in order, to protect myself against allegations of conflict of interest and ethical turpitude: (1) Geographically I am a Seattleite, of a Saturnine temperament, and inclined to take a sour view of the Dionysian Bay Area, just as they tend to be annoyed and appalled by us. (2) Chronologically I am a post-Baby Boomer. I feel that way, at least, because I never experienced the fun and exciting parts of the whole Boomer scene--just spent a lot of time dutifully chuckling at Boomers' maddeningly pointless anecdotes about just how stoned they got on various occasions, and politely fielding their assertions about how great their music was. But even from this remove it was possible to glean certain patterns, and one that recurred as regularly as an urban legend was the one about how someone would move into a commune populated by sandal-wearing, peace-sign flashing flower children, and eventually discover that, underneath this facade, the guys who ran it were actually control freaks; and that, as living in a commune, where much lip service was paid to ideals of peace, love and harmony, had deprived them of normal, socially approved outlets for their control-freakdom, it tended to come out in other, invariably more sinister, ways. Applying this to the case of Apple Computer will be left as an exercise for the reader, and not a very difficult exercise. It is a bit unsettling, at first, to think of Apple as a control freak, because it is completely at odds with their corporate image. Weren't these the guys who aired the famous Super Bowl ads showing suited, blindfolded executives marching like lemmings off a cliff? Isn't this the company that even now runs ads picturing the Dalai Lama (except in Hong Kong) and Einstein and other offbeat rebels? It is indeed the same company, and the fact that they have been able to plant this image of themselves as creative and rebellious free-thinkers in the minds of so many intelligent and media-hardened skeptics really gives one pause. It is testimony to the insidious power of expensive slick ad campaigns and, perhaps, to a certain amount of wishful thinking in the minds of people who fall for them. It also raises the question of why Microsoft is so bad at PR, when the history of Apple demonstrates that, by writing large checks to good ad agencies, you can plant a corporate image in the minds of intelligent people that is completely at odds with reality. (The answer, for people who don't like Damoclean questions, is that since Microsoft has won the hearts and minds of the silent majority--the bourgeoisie--they don't give a damn about having a slick image, any more then Dick Nixon did. "I want to believe,"--the mantra that Fox Mulder has pinned to his office wall in The X-Files--applies in different ways to these two companies; Mac partisans want to believe in the image of Apple purveyed in those ads, and in the notion that Macs are somehow fundamentally different from other computers, while Windows people want to believe that they are getting something for their money, engaging in a respectable business transaction). In any event, as of 1987, both MacOS and Windows were out on the market, running on hardware platforms that were radically different from each other--not only in the sense that MacOS used Motorola CPU chips while Windows used Intel, but in the sense--then overlooked, but in the long run, vastly more significant--that the Apple hardware business was a rigid monopoly and the Windows side was a churning free-for-all. But the full ramifications of this did not become clear until very recently--in fact, they are still unfolding, in remarkably strange ways, as I'll explain when we get to Linux. The upshot is that millions of people got accustomed to using GUIs in one form or another. By doing so, they made Apple/Microsoft a lot of money. The fortunes of many people have become bound up with the ability of these companies to continue selling products whose salability is very much open to question. HONEY-POT, TAR-PIT, WHATEVER When Gates and Allen invented the idea of selling software, they ran into criticism from both hackers and sober-sided businesspeople. Hackers understood that software was just information, and objected to the idea of selling it. These objections were partly moral. The hackers were coming out of the scientific and academic world where it is imperative to make the results of one's work freely available to the public. They were also partly practical; how can you sell something that can be easily copied? Businesspeople, who are polar opposites of hackers in so many ways, had objections of their own. Accustomed to selling toasters and insurance policies, they naturally had a difficult time understanding how a long collection of ones and zeroes could constitute a salable product. Obviously Microsoft prevailed over these objections, and so did Apple. But the objections still exist. The most hackerish of all the hackers, the Ur-hacker as it were, was and is Richard Stallman, who became so annoyed with the evil practice of selling software that, in 1984 (the same year that the Macintosh went on sale) he went off and founded something called the Free Software Foundation, which commenced work on something called GNU. Gnu is an acronym for Gnu's Not Unix, but this is a joke in more ways than one, because GNU most certainly IS Unix,. Because of trademark concerns ("Unix" is trademarked by AT&T) they simply could not claim that it was Unix, and so, just to be extra safe, they claimed that it wasn't. Notwithstanding the incomparable talent and drive possessed by Mr. Stallman and other GNU adherents, their project to build a free Unix to compete against Microsoft and Apple's OSes was a little bit like trying to dig a subway system with a teaspoon. Until, that is, the advent of Linux, which I will get to later. But the basic idea of re-creating an operating system from scratch was perfectly sound and completely doable. It has been done many times. It is inherent in the very nature of operating systems. Operating systems are not strictly necessary. There is no reason why a sufficiently dedicated coder could not start from nothing with every project and write fresh code to handle such basic, low-level operations as controlling the read/write heads on the disk drives and lighting up pixels on the screen. The very first computers had to be programmed in this way. But since nearly every program needs to carry out those same basic operations, this approach would lead to vast duplication of effort. Nothing is more disagreeable to the hacker than duplication of effort. The first and most important mental habit that people develop when they learn how to write computer programs is to generalize, generalize, generalize. To make their code as modular and flexible as possible, breaking large problems down into small subroutines that can be used over and over again in different contexts. Consequently, the development of operating systems, despite being technically unnecessary, was inevitable. Because at its heart, an operating system is nothing more than a library containing the most commonly used code, written once (and hopefully written well) and then made available to every coder who needs it. So a proprietary, closed, secret operating system is a contradiction in terms. It goes against the whole point of having an operating system. And it is impossible to keep them secret anyway. The source code--the original lines of text written by the programmers--can be kept secret. But an OS as a whole is a collection of small subroutines that do very specific, very clearly defined jobs. Exactly what those subroutines do has to be made public, quite explicitly and exactly, or else the OS is completely useless to programmers; they can't make use of those subroutines if they don't have a complete and perfect understanding of what the subroutines do. The only thing that isn't made public is exactly how the subroutines do what they do. But once you know what a subroutine does, it's generally quite easy (if you are a hacker) to write one of your own that does exactly the same thing. It might take a while, and it is tedious and unrewarding, but in most cases it's not really hard. What's hard, in hacking as in fiction, is not writing; it's deciding what to write. And the vendors of commercial OSes have already decided, and published their decisions. This has been generally understood for a long time. MS-DOS was duplicated, functionally, by a rival product, written from scratch, called ProDOS, that did all of the same things in pretty much the same way. In other words, another company was able to write code that did all of the same things as MS-DOS and sell it at a profit. If you are using the Linux OS, you can get a free program called WINE which is a windows emulator; that is, you can open up a window on your desktop that runs windows programs. It means that a completely functional Windows OS has been recreated inside of Unix, like a ship in a bottle. And Unix itself, which is vastly more sophisticated than MS-DOS, has been built up from scratch many times over. Versions of it are sold by Sun, Hewlett-Packard, AT&T, Silicon Graphics, IBM, and others. People have, in other words, been re-writing basic OS code for so long that all of the technology that constituted an "operating system" in the traditional (pre-GUI) sense of that phrase is now so cheap and common that it's literally free. Not only could Gates and Allen not sell MS-DOS today, they could not even give it away, because much more powerful OSes are already being given away. Even the original Windows (which was the only windows until 1995) has become worthless, in that there is no point in owning something that can be emulated inside of Linux--which is, itself, free. In this way the OS business is very different from, say, the car business. Even an old rundown car has some value. You can use it for making runs to the dump, or strip it for parts. It is the fate of manufactured goods to slowly and gently depreciate as they get old and have to compete against more modern products. But it is the fate of operating systems to become free. Microsoft is a great software applications company. Applications--such as Microsoft Word--are an area where innovation brings real, direct, tangible benefits to users. The innovations might be new technology straight from the research department, or they might be in the category of bells and whistles, but in any event they are frequently useful and they seem to make users happy. And Microsoft is in the process of becoming a great research company. But Microsoft is not such a great operating systems company. And this is not necessarily because their operating systems are all that bad from a purely technological standpoint. Microsoft's OSes do have their problems, sure, but they are vastly better than they used to be, and they are adequate for most people. Why, then, do I say that Microsoft is not such a great operating systems company? Because the very nature of operating systems is such that it is senseless for them to be developed and owned by a specific company. It's a thankless job to begin with. Applications create possibilities for millions of credulous users, whereas OSes impose limitations on thousands of grumpy coders, and so OS-makers will forever be on the shit-list of anyone who counts for anything in the high-tech world. Applications get used by people whose big problem is understanding all of their features, whereas OSes get hacked by coders who are annoyed by their limitations. The OS business has been good to Microsoft only insofar as it has given them the money they needed to launch a really good applications software business and to hire a lot of smart researchers. Now it really ought to be jettisoned, like a spent booster stage from a rocket. The big question is whether Microsoft is capable of doing this. Or is it addicted to OS sales in the same way as Apple is to selling hardware? Keep in mind that Apple's ability to monopolize its own hardware supply was once cited, by learned observers, as a great advantage over Microsoft. At the time, it seemed to place them in a much stronger position. In the end, it nearly killed them, and may kill them yet. The problem, for Apple, was that most of the world's computer users ended up owning cheaper hardware. But cheap hardware couldn't run MacOS, and so these people switched to Windows. Replace "hardware" with "operating systems," and "Apple" with "Microsoft" and you can see the same thing about to happen all over again. Microsoft dominates the OS market, which makes them money and seems like a great idea for now. But cheaper and better OSes are available, and they are growingly popular in parts of the world that are not so saturated with computers as the US. Ten years from now, most of the world's computer users may end up owning these cheaper OSes. But these OSes do not, for the time being, run any Microsoft applications, and so these people will use something else. To put it more directly: every time someone decides to use a non-Microsoft OS, Microsoft's OS division, obviously, loses a customer. But, as things stand now, Microsoft's applications division loses a customer too. This is not such a big deal as long as almost everyone uses Microsoft OSes. But as soon as Windows' market share begins to slip, the math starts to look pretty dismal for the people in Redmond. This argument could be countered by saying that Microsoft could simply re-compile its applications to run under other OSes. But this strategy goes against most normal corporate instincts. Again the case of Apple is instructive. When things started to go south for Apple, they should have ported their OS to cheap PC hardware. But they didn't. Instead, they tried to make the most of their brilliant hardware, adding new features and expanding the product line. But this only had the effect of making their OS more dependent on these special hardware features, which made it worse for them in the end. Likewise, when Microsoft's position in the OS world is threatened, their corporate instincts will tell them to pile more new features into their operating systems, and then re-jigger their software applications to exploit those special features. But this will only have the effect of making their applications dependent on an OS with declining market share, and make it worse for them in the end. The operating system market is a death-trap, a tar-pit, a slough of despond. There are only two reasons to invest in Apple and Microsoft. (1) each of these companies is in what we would call a co-dependency relationship with their customers. The customers Want To Believe, and Apple and Microsoft know how to give them what they want. (2) each company works very hard to add new features to their OSes, which works to secure customer loyalty, at least for a little while. Accordingly, most of the remainder of this essay will be about those two topics. THE TECHNOSPHERE Unix is the only OS remaining whose GUI (a vast suite of code called the X Windows System) is separate from the OS in the old sense of the phrase. This is to say that you can run Unix in pure command-line mode if you want to, with no windows, icons, mouses, etc. whatsoever, and it will still be Unix and capable of doing everything Unix is supposed to do. But the other OSes: MacOS, the Windows family, and BeOS, have their GUIs tangled up with the old-fashioned OS functions to the extent that they have to run in GUI mode, or else they are not really running. So it's no longer really possible to think of GUIs as being distinct from the OS; they're now an inextricable part of the OSes that they belong to--and they are by far the largest part, and by far the most expensive and difficult part to create. There are only two ways to sell a product: price and features. When OSes are free, OS companies cannot compete on price, and so they compete on features. This means that they are always trying to outdo each other writing code that, until recently, was not considered to be part of an OS at all: stuff like GUIs. This explains a lot about how these companies behave. It explains why Microsoft added a browser to their OS, for example. It is easy to get free browsers, just as to get free OSes. If browsers are free, and OSes are free, it would seem that there is no way to make money from browsers or OSes. But if you can integrate a browser into the OS and thereby imbue both of them with new features, you have a salable product. Setting aside, for the moment, the fact that this makes government anti-trust lawyers really mad, this strategy makes sense. At least, it makes sense if you assume (as Microsoft's management appears to) that the OS has to be protected at all costs. The real question is whether every new technological trend that comes down the pike ought to be used as a crutch to maintain the OS's dominant position. Confronted with the Web phenomenon, Microsoft had to develop a really good web browser, and they did. But then they had a choice: they could have made that browser work on many different OSes, which would give Microsoft a strong position in the Internet world no matter what happened to their OS market share. Or they could make the browser one with the OS, gambling that this would make the OS look so modern and sexy that it would help to preserve their dominance in that market. The problem is that when Microsoft's OS position begins to erode (and since it is currently at something like ninety percent, it can't go anywhere but down) it will drag everything else down with it. In your high school geology class you probably were taught that all life on earth exists in a paper-thin shell called the biosphere, which is trapped between thousands of miles of dead rock underfoot, and cold dead radioactive empty space above. Companies that sell OSes exist in a sort of technosphere. Underneath is technology that has already become free. Above is technology that has yet to be developed, or that is too crazy and speculative to be productized just yet. Like the Earth's biosphere, the technosphere is very thin compared to what is above and what is below. But it moves a lot faster. In various parts of our world, it is possible to go and visit rich fossil beds where skeleton lies piled upon skeleton, recent ones on top and more ancient ones below. In theory they go all the way back to the first single-celled organisms. And if you use your imagination a bit, you can understand that, if you hang around long enough, you'll become fossilized there too, and in time some more advanced organism will become fossilized on top of you. The fossil record--the La Brea Tar Pit--of software technology is the Internet. Anything that shows up there is free for the taking (possibly illegal, but free). Executives at companies like Microsoft must get used to the experience--unthinkable in other industries--of throwing millions of dollars into the development of new technologies, such as Web browsers, and then seeing the same or equivalent software show up on the Internet two years, or a year, or even just a few months, later. By continuing to develop new technologies and add features onto their products they can keep one step ahead of the fossilization process, but on certain days they must feel like mammoths caught at La Brea, using all their energies to pull their feet, over and over again, out of the sucking hot tar that wants to cover and envelop them. Survival in this biosphere demands sharp tusks and heavy, stomping feet at one end of the organization, and Microsoft famously has those. But trampling the other mammoths into the tar can only keep you alive for so long. The danger is that in their obsession with staying out of the fossil beds, these companies will forget about what lies above the biosphere: the realm of new technology. In other words, they must hang onto their primitive weapons and crude competitive instincts, but also evolve powerful brains. This appears to be what Microsoft is doing with its research division, which has been hiring smart people right and left (Here I should mention that although I know, and socialize with, several people in that company's research division, we never talk about business issues and I have little to no idea what the hell they are up to. I have learned much more about Microsoft by using the Linux operating system than I ever would have done by using Windows). Never mind how Microsoft used to make money; today, it is making its money on a kind of temporal arbitrage. "Arbitrage," in the usual sense, means to make money by taking advantage of differences in the price of something between different markets. It is spatial, in other words, and hinges on the arbitrageur knowing what is going on simultaneously in different places. Microsoft is making money by taking advantage of differences in the price of technology in different times. Temporal arbitrage, if I may coin a phrase, hinges on the arbitrageur knowing what technologies people will pay money for next year, and how soon afterwards those same technologies will become free. What spatial and temporal arbitrage have in common is that both hinge on the arbitrageur's being extremely well-informed; one about price gradients across space at a given time, and the other about price gradients over time in a given place. So Apple/Microsoft shower new features upon their users almost daily, in the hopes that a steady stream of genuine technical innovations, combined with the "I want to believe" phenomenon, will prevent their customers from looking across the road towards the cheaper and better OSes that are available to them. The question is whether this makes sense in the long run. If Microsoft is addicted to OSes as Apple is to hardware, then they will bet the whole farm on their OSes, and tie all of their new applications and technologies to them. Their continued survival will then depend on these two things: adding more features to their OSes so that customers will not switch to the cheaper alternatives, and maintaining the image that, in some mysterious way, gives those customers the feeling that they are getting something for their money. The latter is a truly strange and interesting cultural phenomenon. THE INTERFACE CULTURE A few years ago I walked into a grocery store somewhere and was presented with the following tableau vivant: near the entrance a young couple were standing in front of a large cosmetics display. The man was stolidly holding a shopping basket between his hands while his mate raked blister-packs of makeup off the display and piled them in. Since then I've always thought of that man as the personification of an interesting human tendency: not only are we not offended to be dazzled by manufactured images, but we like it. We practically insist on it. We are eager to be complicit in our own dazzlement: to pay money for a theme park ride, vote for a guy who's obviously lying to us, or stand there holding the basket as it's filled up with cosmetics. I was in Disney World recently, specifically the part of it called the Magic Kingdom, walking up Main Street USA. This is a perfect gingerbready Victorian small town that culminates in a Disney castle. It was very crowded; we shuffled rather than walked. Directly in front of me was a man with a camcorder. It was one of the new breed of camcorders where instead of peering through a viewfinder you gaze at a flat-panel color screen about the size of a playing card, which televises live coverage of whatever the camcorder is seeing. He was holding the appliance close to his face, so that it obstructed his view. Rather than go see a real small town for free, he had paid money to see a pretend one, and rather than see it with the naked eye he was watching it on television. And rather than stay home and read a book, I was watching him. Americans' preference for mediated experiences is obvious enough, and I'm not going to keep pounding it into the ground. I'm not even going to make snotty comments about it--after all, I was at Disney World as a paying customer. But it clearly relates to the colossal success of GUIs and so I have to talk about it some. Disney does mediated experiences better than anyone. If they understood what OSes are, and why people use them, they could crush Microsoft in a year or two. In the part of Disney World called the Animal Kingdom there is a new attraction, slated to open in March 1999, called the Maharajah Jungle Trek. It was open for sneak previews when I was there. This is a complete stone-by-stone reproduction of a hypothetical ruin in the jungles of India. According to its backstory, it was built by a local rajah in the 16th Century as a game reserve. He would go there with his princely guests to hunt Bengal tigers. As time went on it fell into disrepair and the tigers and monkeys took it over; eventually, around the time of India's independence, it became a government wildlife reserve, now open to visitors. The place looks more like what I have just described than any actual building you might find in India. All the stones in the broken walls are weathered as if monsoon rains had been trickling down them for centuries, the paint on the gorgeous murals is flaked and faded just so, and Bengal tigers loll amid stumps of broken columns. Where modern repairs have been made to the ancient structure, they've been done, not as Disney's engineers would do them, but as thrifty Indian janitors would--with hunks of bamboo and rust-spotted hunks of rebar. The rust is painted on, or course, and protected from real rust by a plastic clear-coat, but you can't tell unless you get down on your knees. In one place you walk along a stone wall with a series of old pitted friezes carved into it. One end of the wall has broken off and settled into the earth, perhaps because of some long-forgotten earthquake, and so a broad jagged crack runs across a panel or two, but the story is still readable: first, primordial chaos leads to a flourishing of many animal species. Next, we see the Tree of Life surrounded by diverse animals. This is an obvious allusion (or, in showbiz lingo, a tie-in) to the gigantic Tree of Life that dominates the center of Disney's Animal Kingdom just as the Castle dominates the Magic Kingdom or the Sphere does Epcot. But it's rendered in historically correct style and could probably fool anyone who didn't have a Ph.D. in Indian art history. The next panel shows a mustachioed H. sapiens chopping down the Tree of Life with a scimitar, and the animals fleeing every which way. The one after that shows the misguided human getting walloped by a tidal wave, part of a latter-day Deluge presumably brought on by his stupidity. The final panel, then, portrays the Sapling of Life beginning to grow back, but now Man has ditched the edged weapon and joined the other animals in standing around to adore and praise it. It is, in other words, a prophecy of the Bottleneck: the scenario, commonly espoused among modern-day environmentalists, that the world faces an upcoming period of grave ecological tribulations that will last for a few decades or centuries and end when we find a new harmonious modus vivendi with Nature. Taken as a whole the frieze is a pretty brilliant piece of work. Obviously it's not an ancient Indian ruin, and some person or people now living deserve credit for it. But there are no signatures on the Maharajah's game reserve at Disney World. There are no signatures on anything, because it would ruin the whole effect to have long strings of production credits dangling from every custom-worn brick, as they do from Hollywood movies. Among Hollywood writers, Disney has the reputation of being a real wicked stepmother. It's not hard to see why. Disney is in the business of putting out a product of seamless illusion--a magic mirror that reflects the world back better than it really is. But a writer is literally talking to his or her readers, not just creating an ambience or presenting them with something to look at; and just as the command-line interface opens a much more direct and explicit channel from user to machine than the GUI, so it is with words, writer, and reader. The word, in the end, is the only system of encoding thoughts--the only medium--that is not fungible, that refuses to dissolve in the devouring torrent of electronic media (the richer tourists at Disney World wear t-shirts printed with the names of famous designers, because designs themselves can be bootlegged easily and with impunity. The only way to make clothing that cannot be legally bootlegged is to print copyrighted and trademarked words on it; once you have taken that step, the clothing itself doesn't really matter, and so a t-shirt is as good as anything else. T-shirts with expensive words on them are now the insignia of the upper class. T-shirts with cheap words, or no words at all, are for the commoners). But this special quality of words and of written communication would have the same effect on Disney's product as spray-painted graffiti on a magic mirror. So Disney does most of its communication without resorting to words, and for the most part, the words aren't missed. Some of Disney's older properties, such as Peter Pan, Winnie the Pooh, and Alice in Wonderland, came out of books. But the authors' names are rarely if ever mentioned, and you can't buy the original books at the Disney store. If you could, they would all seem old and queer, like very bad knockoffs of the purer, more authentic Disney versions. Compared to more recent productions like Beauty and the Beast and Mulan, the Disney movies based on these books (particularly Alice in Wonderland and Peter Pan) seem deeply bizarre, and not wholly appropriate for children. That stands to reason, because Lewis Carroll and J.M. Barrie were very strange men, and such is the nature of the written word that their personal strangeness shines straight through all the layers of Disneyfication like x-rays through a wall. Probably for this very reason, Disney seems to have stopped buying books altogether, and now finds its themes and characters in folk tales, which have the lapidary, time-worn quality of the ancient bricks in the Maharajah's ruins. If I can risk a broad generalization, most of the people who go to Disney World have zero interest in absorbing new ideas from books. Which sounds snide, but listen: they have no qualms about being presented with ideas in other forms. Disney World is stuffed with environmental messages now, and the guides at Animal Kingdom can talk your ear off about biology. If you followed those tourists home, you might find art, but it would be the sort of unsigned folk art that's for sale in Disney World's African- and Asian-themed stores. In general they only seem comfortable with media that have been ratified by great age, massive popular acceptance, or both. In this world, artists are like the anonymous, illiterate stone carvers who built the great cathedrals of Europe and then faded away into unmarked graves in the churchyard. The cathedral as a whole is awesome and stirring in spite, and possibly because, of the fact that we have no idea who built it. When we walk through it we are communing not with individual stone carvers but with an entire culture. Disney World works the same way. If you are an intellectual type, a reader or writer of books, the nicest thing you can say about this is that the execution is superb. But it's easy to find the whole environment a little creepy, because something is missing: the translation of all its content into clear explicit written words, the attribution of the ideas to specific people. You can't argue with it. It seems as if a hell of a lot might be being glossed over, as if Disney World might be putting one over on us, and possibly getting away with all kinds of buried assumptions and muddled thinking. But this is precisely the same as what is lost in the transition from the command-line interface to the GUI. Disney and Apple/Microsoft are in the same business: short-circuiting laborious, explicit verbal communication with expensively designed interfaces. Disney is a sort of user interface unto itself--and more than just graphical. Let's call it a Sensorial Interface. It can be applied to anything in the world, real or imagined, albeit at staggering expense. Why are we rejecting explicit word-based interfaces, and embracing graphical or sensorial ones--a trend that accounts for the success of both Microsoft and Disney? Part of it is simply that the world is very complicated now--much more complicated than the hunter-gatherer world that our brains evolved to cope with--and we simply can't handle all of the details. We have to delegate. We have no choice but to trust some nameless artist at Disney or programmer at Apple or Microsoft to make a few choices for us, close off some options, and give us a conveniently packaged executive summary. But more importantly, it comes out of the fact that, during this century, intellectualism failed, and everyone knows it. In places like Russia and Germany, the common people agreed to loosen their grip on traditional folkways, mores, and religion, and let the intellectuals run with the ball, and they screwed everything up and turned the century into an abbatoir. Those wordy intellectuals used to be merely tedious; now they seem kind of dangerous as well. We Americans are the only ones who didn't get creamed at some point during all of this. We are free and prosperous because we have inherited political and values systems fabricated by a particular set of eighteenth-century intellectuals who happened to get it right. But we have lost touch with those intellectuals, and with anything like intellectualism, even to the point of not reading books any more, though we are literate. We seem much more comfortable with propagating those values to future generations nonverbally, through a process of being steeped in media. Apparently this actually works to some degree, for police in many lands are now complaining that local arrestees are insisting on having their Miranda rights read to them, just like perps in American TV cop shows. When it's explained to them that they are in a different country, where those rights do not exist, they become outraged. Starsky and Hutch reruns, dubbed into diverse languages, may turn out, in the long run, to be a greater force for human rights than the Declaration of Independence. A huge, rich, nuclear-tipped culture that propagates its core values through media steepage seems like a bad idea. There is an obvious risk of running astray here. Words are the only immutable medium we have, which is why they are the vehicle of choice for extremely important concepts like the Ten Commandments, the Koran, and the Bill of Rights. Unless the messages conveyed by our media are somehow pegged to a fixed, written set of precepts, they can wander all over the place and possibly dump loads of crap into people's minds. Orlando used to have a military installation called McCoy Air Force Base, with long runways from which B-52s could take off and reach Cuba, or just about anywhere else, with loads of nukes. But now McCoy has been scrapped and repurposed. It has been absorbed into Orlando's civilian airport. The long runways are being used to land 747-loads of tourists from Brazil, Italy, Russia and Japan, so that they can come to Disney World and steep in our media for a while. To traditional cultures, especially word-based ones such as Islam, this is infinitely more threatening than the B-52s ever were. It is obvious, to everyone outside of the United States, that our arch-buzzwords, multiculturalism and diversity, are false fronts that are being used (in many cases unwittingly) to conceal a global trend to eradicate cultural differences. The basic tenet of multiculturalism (or "honoring diversity" or whatever you want to call it) is that people need to stop judging each other-to stop asserting (and, eventually, to stop believing) that this is right and that is wrong, this true and that false, one thing ugly and another thing beautiful, that God exists and has this or that set of qualities. The lesson most people are taking home from the Twentieth Century is that, in order for a large number of different cultures to coexist peacefully on the globe (or even in a neighborhood) it is necessary for people to suspend judgment in this way. Hence (I would argue) our suspicion of, and hostility towards, all authority figures in modern culture. As David Foster Wallace has explained in his essay "E Unibus Pluram," this is the fundamental message of television; it is the message that people take home, anyway, after they have steeped in our media long enough. It's not expressed in these highfalutin terms, of course. It comes through as the presumption that all authority figures--teachers, generals, cops, ministers, politicians--are hypocritical buffoons, and that hip jaded coolness is the only way to be. The problem is that once you have done away with the ability to make judgments as to right and wrong, true and false, etc., there's no real culture left. All that remains is clog dancing and macrame. The ability to make judgments, to believe things, is the entire it point of having a culture. I think this is why guys with machine guns sometimes pop up in places like Luxor, and begin pumping bullets into Westerners. They perfectly understand the lesson of McCoy Air Force Base. When their sons come home wearing Chicago Bulls caps with the bills turned sideways, the dads go out of their minds. The global anti-culture that has been conveyed into every cranny of the world by television is a culture unto itself, and by the standards of great and ancient cultures like Islam and France, it seems grossly inferior, at least at first. The only good thing you can say about it is that it makes world wars and Holocausts less likely--and that is actually a pretty good thing! The only real problem is that anyone who has no culture, other than this global monoculture, is completely screwed. Anyone who grows up watching TV, never sees any religion or philosophy, is raised in an atmosphere of moral relativism, learns about civics from watching bimbo eruptions on network TV news, and attends a university where postmodernists vie to outdo each other in demolishing traditional notions of truth and quality, is going to come out into the world as one pretty feckless human being. And--again--perhaps the goal of all this is to make us feckless so we won't nuke each other. On the other hand, if you are raised within some specific culture, you end up with a basic set of tools that you can use to think about and understand the world. You might use those tools to reject the culture you were raised in, but at least you've got some tools. In this country, the people who run things--who populate major law firms and corporate boards--understand all of this at some level. They pay lip service to multiculturalism and diversity and non-judgmentalness, but they don't raise their own children that way. I have highly educated, technically sophisticated friends who have moved to small towns in Iowa to live and raise their children, and there are Hasidic Jewish enclaves in New York where large numbers of kids are being brought up according to traditional beliefs. Any suburban community might be thought of as a place where people who hold certain (mostly implicit) beliefs go to live among others who think the same way. And not only do these people feel some responsibility to their own children, but to the country as a whole. Some of the upper class are vile and cynical, of course, but many spend at least part of their time fretting about what direction the country is going in, and what responsibilities they have. And so issues that are important to book-reading intellectuals, such as global environmental collapse, eventually percolate through the porous buffer of mass culture and show up as ancient Hindu ruins in Orlando. You may be asking: what the hell does all this have to do with operating systems? As I've explained, there is no way to explain the domination of the OS market by Apple/Microsoft without looking to cultural explanations, and so I can't get anywhere, in this essay, without first letting you know where I'm coming from vis-a-vis contemporary culture. Contemporary culture is a two-tiered system, like the Morlocks and the Eloi in H.G. Wells's The Time Machine, except that it's been turned upside down. In The Time Machine the Eloi were an effete upper class, supported by lots of subterranean Morlocks who kept the technological wheels turning. But in our world it's the other way round. The Morlocks are in the minority, and they are running the show, because they understand how everything works. The much more numerous Eloi learn everything they know from being steeped from birth in electronic media directed and controlled by book-reading Morlocks. So many ignorant people could be dangerous if they got pointed in the wrong direction, and so we've evolved a popular culture that is (a) almost unbelievably infectious and (b) neuters every person who gets infected by it, by rendering them unwilling to make judgments and incapable of taking stands. Morlocks, who have the energy and intelligence to comprehend details, go out and master complex subjects and produce Disney-like Sensorial Interfaces so that Eloi can get the gist without having to strain their minds or endure boredom. Those Morlocks will go to India and tediously explore a hundred ruins, then come home and built sanitary bug-free versions: highlight films, as it were. This costs a lot, because Morlocks insist on good coffee and first-class airline tickets, but that's no problem because Eloi like to be dazzled and will gladly pay for it all. Now I realize that most of this probably sounds snide and bitter to the point of absurdity: your basic snotty intellectual throwing a tantrum about those unlettered philistines. As if I were a self-styled Moses, coming down from the mountain all alone, carrying the stone tablets bearing the Ten Commandments carved in immutable stone--the original command-line interface--and blowing his stack at the weak, unenlightened Hebrews worshipping images. Not only that, but it sounds like I'm pumping some sort of conspiracy theory. But that is not where I'm going with this. The situation I describe, here, could be bad, but doesn't have to be bad and isn't necessarily bad now: It simply is the case that we are way too busy, nowadays, to comprehend everything in detail. And it's better to comprehend it dimly, through an interface, than not at all. Better for ten million Eloi to go on the Kilimanjaro Safari at Disney World than for a thousand cardiovascular surgeons and mutual fund managers to go on "real" ones in Kenya. The boundary between these two classes is more porous than I've made it sound. I'm always running into regular dudes--construction workers, auto mechanics, taxi drivers, galoots in general--who were largely aliterate until something made it necessary for them to become readers and start actually thinking about things. Perhaps they had to come to grips with alcoholism, perhaps they got sent to jail, or came down with a disease, or suffered a crisis in religious faith, or simply got bored. Such people can get up to speed on particular subjects quite rapidly. Sometimes their lack of a broad education makes them over-apt to go off on intellectual wild goose chases, but, hey, at least a wild goose chase gives you some exercise. The spectre of a polity controlled by the fads and whims of voters who actually believe that there are significant differences between Bud Lite and Miller Lite, and who think that professional wrestling is for real, is naturally alarming to people who don't. But then countries controlled via the command-line interface, as it were, by double-domed intellectuals, be they religious or secular, are generally miserable places to live. Sophisticated people deride Disneyesque entertainments as pat and saccharine, but, hey, if the result of that is to instill basically warm and sympathetic reflexes, at a preverbal level, into hundreds of millions of unlettered media-steepers, then how bad can it be? We killed a lobster in our kitchen last night and my daughter cried for an hour. The Japanese, who used to be just about the fiercest people on earth, have become infatuated with cuddly adorable cartoon characters. My own family--the people I know best--is divided about evenly between people who will probably read this essay and people who almost certainly won't, and I can't say for sure that one group is necessarily warmer, happier, or better-adjusted than the other. MORLOCKS AND ELOI AT THE KEYBOARD Back in the days of the command-line interface, users were all Morlocks who had to convert their thoughts into alphanumeric symbols and type them in, a grindingly tedious process that stripped away all ambiguity, laid bare all hidden assumptions, and cruelly punished laziness and imprecision. Then the interface-makers went to work on their GUIs, and introduced a new semiotic layer between people and machines. People who use such systems have abdicated the responsibility, and surrendered the power, of sending bits directly to the chip that's doing the arithmetic, and handed that responsibility and power over to the OS. This is tempting because giving clear instructions, to anyone or anything, is difficult. We cannot do it without thinking, and depending on the complexity of the situation, we may have to think hard about abstract things, and consider any number of ramifications, in order to do a good job of it. For most of us, this is hard work. We want things to be easier. How badly we want it can be measured by the size of Bill Gates's fortune. The OS has (therefore) become a sort of intellectual labor-saving device that tries to translate humans' vaguely expressed intentions into bits. In effect we are asking our computers to shoulder responsibilities that have always been considered the province of human beings--we want them to understand our desires, to anticipate our needs, to foresee consequences, to make connections, to handle routine chores without being asked, to remind us of what we ought to be reminded of while filtering out noise. At the upper (which is to say, closer to the user) levels, this is done through a set of conventions--menus, buttons, and so on. These work in the sense that analogies work: they help Eloi understand abstract or unfamiliar concepts by likening them to something known. But the loftier word "metaphor" is used. The overarching concept of the MacOS was the "desktop metaphor" and it subsumed any number of lesser (and frequently conflicting, or at least mixed) metaphors. Under a GUI, a file (frequently called "document") is metaphrased as a window on the screen (which is called a "desktop"). The window is almost always too small to contain the document and so you "move around," or, more pretentiously, "navigate" in the document by "clicking and dragging" the "thumb" on the "scroll bar." When you "type" (using a keyboard) or "draw" (using a "mouse") into the "window" or use pull-down "menus" and "dialog boxes" to manipulate its contents, the results of your labors get stored (at least in theory) in a "file," and later you can pull the same information back up into another "window." When you don't want it anymore, you "drag" it into the "trash." There is massively promiscuous metaphor-mixing going on here, and I could deconstruct it 'til the cows come home, but I won't. Consider only one word: "document." When we document something in the real world, we make fixed, permanent, immutable records of it. But computer documents are volatile, ephemeral constellations of data. Sometimes (as when you've just opened or saved them) the document as portrayed in the window is identical to what is stored, under the same name, in a file on the disk, but other times (as when you have made changes without saving them) it is completely different. In any case, every time you hit "Save" you annihilate the previous version of the "document" and replace it with whatever happens to be in the window at the moment. So even the word "save" is being used in a sense that is grotesquely misleading---"destroy one version, save another" would be more accurate. Anyone who uses a word processor for very long inevitably has the experience of putting hours of work into a long document and then losing it because the computer crashes or the power goes out. Until the moment that it disappears from the screen, the document seems every bit as solid and real as if it had been typed out in ink on paper. But in the next moment, without warning, it is completely and irretrievably gone, as if it had never existed. The user is left with a feeling of disorientation (to say nothing of annoyance) stemming from a kind of metaphor shear--you realize that you've been living and thinking inside of a metaphor that is essentially bogus. So GUIs use metaphors to make computing easier, but they are bad metaphors. Learning to use them is essentially a word game, a process of learning new definitions of words like "window" and "document" and "save" that are different from, and in many cases almost diametrically opposed to, the old. Somewhat improbably, this has worked very well, at least from a commercial standpoint, which is to say that Apple/Microsoft have made a lot of money off of it. All of the other modern operating systems have learned that in order to be accepted by users they must conceal their underlying gutwork beneath the same sort of spackle. This has some advantages: if you know how to use one GUI operating system, you can probably work out how to use any other in a few minutes. Everything works a little differently, like European plumbing--but with some fiddling around, you can type a memo or surf the web. Most people who shop for OSes (if they bother to shop at all) are comparing not the underlying functions but the superficial look and feel. The average buyer of an OS is not really paying for, and is not especially interested in, the low-level code that allocates memory or writes bytes onto the disk. What we're really buying is a system of metaphors. And--much more important--what we're buying into is the underlying assumption that metaphors are a good way to deal with the world. Recently a lot of new hardware has become available that gives computers numerous interesting ways of affecting the real world: making paper spew out of printers, causing words to appear on screens thousands of miles away, shooting beams of radiation through cancer patients, creating realistic moving pictures of the Titanic. Windows is now used as an OS for cash registers and bank tellers' terminals. My satellite TV system uses a sort of GUI to change channels and show program guides. Modern cellular telephones have a crude GUI built into a tiny LCD screen. Even Legos now have a GUI: you can buy a Lego set called Mindstorms that enables you to build little Lego robots and program them through a GUI on your computer. So we are now asking the GUI to do a lot more than serve as a glorified typewriter. Now we want to become a generalized tool for dealing with reality. This has become a bonanza for companies that make a living out of bringing new technology to the mass market. Obviously you cannot sell a complicated technological system to people without some sort of interface that enables them to use it. The internal combustion engine was a technological marvel in its day, but useless as a consumer good until a clutch, transmission, steering wheel and throttle were connected to it. That odd collection of gizmos, which survives to this day in every car on the road, made up what we would today call a user interface. But if cars had been invented after Macintoshes, carmakers would not have bothered to gin up all of these arcane devices. We would have a computer screen instead of a dashboard, and a mouse (or at best a joystick) instead of a steering wheel, and we'd shift gears by pulling down a menu: PARK --- REVERSE --- NEUTRAL ---- 3 2 1 --- Help... A few lines of computer code can thus be made to substitute for any imaginable mechanical interface. The problem is that in many cases the substitute is a poor one. Driving a car through a GUI would be a miserable experience. Even if the GUI were perfectly bug-free, it would be incredibly dangerous, because menus and buttons simply can't be as responsive as direct mechanical controls. My friend's dad, the gentleman who was restoring the MGB, never would have bothered with it if it had been equipped with a GUI. It wouldn't have been any fun. The steering wheel and gearshift lever were invented during an era when the most complicated technology in most homes was a butter churn. Those early carmakers were simply lucky, in that they could dream up whatever interface was best suited to the task of driving an automobile, and people would learn it. Likewise with the dial telephone and the AM radio. By the time of the Second World War, most people knew several interfaces: they could not only churn butter but also drive a car, dial a telephone, turn on a radio, summon flame from a cigarette lighter, and change a light bulb. But now every little thing--wristwatches, VCRs, stoves--is jammed with features, and every feature is useless without an interface. If you are like me, and like most other consumers, you have never used ninety percent of the available features on your microwave oven, VCR, or cellphone. You don't even know that these features exist. The small benefit they might bring you is outweighed by the sheer hassle of having to learn about them. This has got to be a big problem for makers of consumer goods, because they can't compete without offering features. It's no longer acceptable for engineers to invent a wholly novel user interface for every new product, as they did in the case of the automobile, partly because it's too expensive and partly because ordinary people can only learn so much. If the VCR had been invented a hundred years ago, it would have come with a thumbwheel to adjust the tracking and a gearshift to change between forward and reverse and a big cast-iron handle to load or to eject the cassettes. It would have had a big analog clock on the front of it, and you would have set the time by moving the hands around on the dial. But because the VCR was invented when it was--during a sort of awkward transitional period between the era of mechanical interfaces and GUIs--it just had a bunch of pushbuttons on the front, and in order to set the time you had to push the buttons in just the right way. This must have seemed reasonable enough to the engineers responsible for it, but to many users it was simply impossible. Thus the famous blinking 12:00 that appears on so many VCRs. Computer people call this "the blinking twelve problem". When they talk about it, though, they usually aren't talking about VCRs. Modern VCRs usually have some kind of on-screen programming, which means that you can set the time and control other features through a sort of primitive GUI. GUIs have virtual pushbuttons too, of course, but they also have other types of virtual controls, like radio buttons, checkboxes, text entry boxes, dials, and scrollbars. Interfaces made out of these components seem to be a lot easier, for many people, than pushing those little buttons on the front of the machine, and so the blinking 12:00 itself is slowly disappearing from America's living rooms. The blinking twelve problem has moved on to plague other technologies. So the GUI has gone beyond being an interface to personal computers, and become a sort of meta-interface that is pressed into service for every new piece of consumer technology. It is rarely an ideal fit, but having an ideal, or even a good interface is no longer the priority; the important thing now is having some kind of interface that customers will actually use, so that manufacturers can claim, with a straight face, that they are offering new features. We want GUIs largely because they are convenient and because they are easy-- or at least the GUI makes it seem that way Of course, nothing is really easy and simple, and putting a nice interface on top of it does not change that fact. A car controlled through a GUI would be easier to drive than one controlled through pedals and steering wheel, but it would be incredibly dangerous. By using GUIs all the time we have insensibly bought into a premise that few people would have accepted if it were presented to them bluntly: namely, that hard things can be made easy, and complicated things simple, by putting the right interface on them. In order to understand how bizarre this is, imagine that book reviews were written according to the same values system that we apply to user interfaces: "The writing in this book is marvelously simple-minded and glib; the author glosses over complicated subjects and employs facile generalizations in almost every sentence. Readers rarely have to think, and are spared all of the difficulty and tedium typically involved in reading old-fashioned books." As long as we stick to simple operations like setting the clocks on our VCRs, this is not so bad. But as we try to do more ambitious things with our technologies, we inevitably run into the problem of: METAPHOR SHEAR I began using Microsoft Word as soon as the first version was released around 1985. After some initial hassles I found it to be a better tool than MacWrite, which was its only competition at the time. I wrote a lot of stuff in early versions of Word, storing it all on floppies, and transferred the contents of all my floppies to my first hard drive, which I acquired around 1987. As new versions of Word came out I faithfully upgraded, reasoning that as a writer it made sense for me to spend a certain amount of money on tools. Sometime in the mid-1980's I attempted to open one of my old, circa-1985 Word documents using the version of Word then current: 6.0 It didn't work. Word 6.0 did not recognize a document created by an earlier version of itself. By opening it as a text file, I was able to recover the sequences of letters that made up the text of the document. My words were still there. But the formatting had been run through a log chipper--the words I'd written were interrupted by spates of empty rectangular boxes and gibberish. Now, in the context of a business (the chief market for Word) this sort of thing is only an annoyance--one of the routine hassles that go along with using computers. It's easy to buy little file converter programs that will take care of this problem. But if you are a writer whose career is words, whose professional identity is a corpus of written documents, this kind of thing is extremely disquieting. There are very few fixed assumptions in my line of work, but one of them is that once you have written a word, it is written, and cannot be unwritten. The ink stains the paper, the chisel cuts the stone, the stylus marks the clay, and something has irrevocably happened (my brother-in-law is a theologian who reads 3250-year-old cuneiform tablets--he can recognize the handwriting of particular scribes, and identify them by name). But word-processing software--particularly the sort that employs special, complex file formats--has the eldritch power to unwrite things. A small change in file formats, or a few twiddled bits, and months' or years' literary output can cease to exist. Now this was technically a fault in the application (Word 6.0 for the Macintosh) not the operating system (MacOS 7 point something) and so the initial target of my annoyance was the people who were responsible for Word. But. On the other hand, I could have chosen the "save as text" option in Word and saved all of my documents as simple telegrams, and this problem would not have arisen. Instead I had allowed myself to be seduced by all of those flashy formatting options that hadn't even existed until GUIs had come along to make them practicable. I had gotten into the habit of using them to make my documents look pretty (perhaps prettier than they deserved to look; all of the old documents on those floppies turned out to be more or less crap). Now I was paying the price for that self-indulgence. Technology had moved on and found ways to make my documents look even prettier, and the consequence of it was that all old ugly documents had ceased to exist. It was--if you'll pardon me for a moment's strange little fantasy--as if I'd gone to stay at some resort, some exquisitely designed and art-directed hotel, placing myself in the hands of past masters of the Sensorial Interface, and had sat down in my room and written a story in ballpoint pen on a yellow legal pad, and when I returned from dinner, discovered that the maid had taken my work away and left behind in its place a quill pen and a stack of fine parchment--explaining that the room looked ever so much finer this way, and it was all part of a routine upgrade. But written on these sheets of paper, in flawless penmanship, were long sequences of words chosen at random from the dictionary. Appalling, sure, but I couldn't really lodge a complaint with the management, because by staying at this resort I had given my consent to it. I had surrendered my Morlock credentials and become an Eloi. LINUX During the late 1980's and early 1990's I spent a lot of time programming Macintoshes, and eventually decided for fork over several hundred dollars for an Apple product called the Macintosh Programmer's Workshop, or MPW. MPW had competitors, but it was unquestionably the premier software development system for the Mac. It was what Apple's own engineers used to write Macintosh code. Given that MacOS was far more technologically advanced, at the time, than its competition, and that Linux did not even exist yet, and given that this was the actual program used by Apple's world-class team of creative engineers, I had high expectations. It arrived on a stack of floppy disks about a foot high, and so there was plenty of time for my excitement to build during the endless installation process. The first time I launched MPW, I was probably expecting some kind of touch-feely multimedia showcase. Instead it was austere, almost to the point of being intimidating. It was a scrolling window into which you could type simple, unformatted text. The system would then interpret these lines of text as commands, and try to execute them. It was, in other words, a glass teletype running a command line interface. It came with all sorts of cryptic but powerful commands, which could be invoked by typing their names, and which I learned to use only gradually. It was not until a few years later, when I began messing around with Unix, that I understood that the command line interface embodied in MPW was a re-creation of Unix. In other words, the first thing that Apple's hackers had done when they'd got the MacOS up and running--probably even before they'd gotten it up and running--was to re-create the Unix interface, so that they would be able to get some useful work done. At the time, I simply couldn't get my mind around this, but: as far as Apple's hackers were concerned, the Mac's vaunted Graphical User Interface was an impediment, something to be circumvented before the little toaster even came out onto the market. Even before my Powerbook crashed and obliterated my big file in July 1995, there had been danger signs. An old college buddy of mine, who starts and runs high-tech companies in Boston, had developed a commercial product using Macintoshes as the front end. Basically the Macs were high-performance graphics terminals, chosen for their sweet user interface, giving users access to a large database of graphical information stored on a network of much more powerful, but less user-friendly, computers. This fellow was the second person who turned me on to Macintoshes, by the way, and through the mid-1980's we had shared the thrill of being high-tech cognoscenti, using superior Apple technology in a world of DOS-using knuckleheads. Early versions of my friend's system had worked well, he told me, but when several machines joined the network, mysterious crashes began to occur; sometimes the whole network would just freeze. It was one of those bugs that could not be reproduced easily. Finally they figured out that these network crashes were triggered whenever a user, scanning the menus for a particular item, held down the mouse button for more than a couple of seconds. Fundamentally, the MacOS could only do one thing at a time. Drawing a menu on the screen is one thing. So when a menu was pulled down, the Macintosh was not capable of doing anything else until that indecisive user released the button. This is not such a bad thing in a single-user, single-process machine (although it's a fairly bad thing), but it's no good in a machine that is on a network, because being on a network implies some kind of continual low-level interaction with other machines. By failing to respond to the network, the Mac caused a network-wide crash. In order to work with other computers, and with networks, and with various different types of hardware, an OS must be incomparably more complicated and powerful than either MS-DOS or the original MacOS. The only way of connecting to the Internet that's worth taking seriously is PPP, the Point-to-Point Protocol, which (never mind the details) makes your computer--temporarily--a full-fledged member of the Global Internet, with its own unique address, and various privileges, powers, and responsibilities appertaining thereunto. Technically it means your machine is running the TCP/IP protocol, which, to make a long story short, revolves around sending packets of data back and forth, in no particular order, and at unpredictable times, according to a clever and elegant set of rules. But sending a packet of data is one thing, and so an OS that can only do one thing at a time cannot simultaneously be part of the Internet and do anything else. When TCP/IP was invented, running it was an honor reserved for Serious Computers--mainframes and high-powered minicomputers used in technical and commercial settings--and so the protocol is engineered around the assumption that every computer using it is a serious machine, capable of doing many things at once. Not to put too fine a point on it, a Unix machine. Neither MacOS nor MS-DOS was originally built with that in mind, and so when the Internet got hot, radical changes had to be made. When my Powerbook broke my heart, and when Word stopped recognizing my old files, I jumped to Unix. The obvious alternative to MacOS would have been Windows. I didn't really have anything against Microsoft, or Windows. But it was pretty obvious, now, that old PC operating systems were overreaching, and showing the strain, and, perhaps, were best avoided until they had learned to walk and chew gum at the same time. The changeover took place on a particular day in the summer of 1995. I had been San Francisco for a couple of weeks, using my PowerBook to work on a document. The document was too big to fit onto a single floppy, and so I hadn't made a backup since leaving home. The PowerBook crashed and wiped out the entire file. It happened just as I was on my way out the door to visit a company called Electric Communities, which in those days was in Los Altos. I took my PowerBook with me. My friends at Electric Communities were Mac users who had all sorts of utility software for unerasing files and recovering from disk crashes, and I was certain I could get most of the file back. As it turned out, two different Mac crash recovery utilities were unable to find any trace that my file had ever existed. It was completely and systematically wiped out. We went through that hard disk block by block and found disjointed fragments of countless old, discarded, forgotten files, but none of what I wanted. The metaphor shear was especially brutal that day. It was sort of like watching the girl you've been in love with for ten years get killed in a car wreck, and then attending her autopsy, and learning that underneath the clothes and makeup she was just flesh and blood. I must have been reeling around the offices of Electric Communities in some kind of primal Jungian fugue, because at this moment three weirdly synchronistic things happened. (1) Randy Farmer, a co-founder of the company, came in for a quick visit along with his family--he was recovering from back surgery at the time. He had some hot gossip: "Windows 95 mastered today." What this meant was that Microsoft's new operating system had, on this day, been placed on a special compact disk known as a golden master, which would be used to stamp out a jintillion copies in preparation for its thunderous release a few weeks later. This news was received peevishly by the staff of Electric Communities, including one whose office door was plastered with the usual assortment of cartoons and novelties, e.g. (2) a copy of a Dilbert cartoon in which Dilbert, the long-suffering corporate software engineer, encounters a portly, bearded, hairy man of a certain age--a bit like Santa Claus, but darker, with a certain edge about him. Dilbert recognizes this man, based upon his appearance and affect, as a Unix hacker, and reacts with a certain mixture of nervousness, awe, and hostility. Dilbert jabs weakly at the disturbing interloper for a couple of frames; the Unix hacker listens with a kind of infuriating, beatific calm, then, in the last frame, reaches into his pocket. "Here's a nickel, kid," he says, "go buy yourself a real computer." (3) the owner of the door, and the cartoon, was one Doug Barnes. Barnes was known to harbor certain heretical opinions on the subject of operating systems. Unlike most Bay Area techies who revered the Macintosh, considering it to be a true hacker's machine, Barnes was fond of pointing out that the Mac, with its hermetically sealed architecture, was actually hostile to hackers, who are prone to tinkering and dogmatic about openness. By contrast, the IBM-compatible line of machines, which can easily be taken apart and plugged back together, was much more hackable. So when I got home I began messing around with Linux, which is one of many, many different concrete implementations of the abstract, Platonic ideal called Unix. I was not looking forward to changing over to a new OS, because my credit cards were still smoking from all the money I'd spent on Mac hardware over the years. But Linux's great virtue was, and is, that it would run on exactly the same sort of hardware as the Microsoft OSes--which is to say, the cheapest hardware in existence. As if to demonstrate why this was a great idea, I was, within a week or two of returning home, able to get my hand on a then-decent computer (a 33-MHz 486 box) for free, because I knew a guy who worked in an office where they were simply being thrown away. Once I got it home, I yanked the hood off, stuck my hands in, and began switching cards around. If something didn't work, I went to a used-computer outlet and pawed through a bin full of components and bought a new card for a few bucks. The availability of all this cheap but effective hardware was an unintended consequence of decisions that had been made more than a decade earlier by IBM and Microsoft. When Windows came out, and brought the GUI to a much larger market, the hardware regime changed: the cost of color video cards and high-resolution monitors began to drop, and is dropping still. This free-for-all approach to hardware meant that Windows was unavoidably clunky compared to MacOS. But the GUI brought computing to such a vast audience that volume went way up and prices collapsed. Meanwhile Apple, which so badly wanted a clean, integrated OS with video neatly integrated into processing hardware, had fallen far behind in market share, at least partly because their beautiful hardware cost so much. But the price that we Mac owners had to pay for superior aesthetics and engineering was not merely a financial one. There was a cultural price too, stemming from the fact that we couldn't open up the hood and mess around with it. Doug Barnes was right. Apple, in spite of its reputation as the machine of choice of scruffy, creative hacker types, had actually created a machine that discouraged hacking, while Microsoft, viewed as a technological laggard and copycat, had created a vast, disorderly parts bazaar--a primordial soup that eventually self-assembled into Linux. THE HOLE HAWG OF OPERATING SYSTEMS Unix has always lurked provocatively in the background of the operating system wars, like the Russian Army. Most people know it only by reputation, and its reputation, as the Dilbert cartoon suggests, is mixed. But everyone seems to agree that if it could only get its act together and stop surrendering vast tracts of rich agricultural land and hundreds of thousands of prisoners of war to the onrushing invaders, it could stomp them (and all other opposition) flat. It is difficult to explain how Unix has earned this respect without going into mind-smashing technical detail. Perhaps the gist of it can be explained by telling a story about drills. The Hole Hawg is a drill made by the Milwaukee Tool Company. If you look in a typical hardware store you may find smaller Milwaukee drills but not the Hole Hawg, which is too powerful and too expensive for homeowners. The Hole Hawg does not have the pistol-like design of a cheap homeowner's drill. It is a cube of solid metal with a handle sticking out of one face and a chuck mounted in another. The cube contains a disconcertingly potent electric motor. You can hold the handle and operate the trigger with your index finger, but unless you are exceptionally strong you cannot control the weight of the Hole Hawg with one hand; it is a two-hander all the way. In order to fight off the counter-torque of the Hole Hawg you use a separate handle (provided), which you screw into one side of the iron cube or the other depending on whether you are using your left or right hand to operate the trigger. This handle is not a sleek, ergonomically designed item as it would be in a homeowner's drill. It is simply a foot-long chunk of regular galvanized pipe, threaded on one end, with a black rubber handle on the other. If you lose it, you just go to the local plumbing supply store and buy another chunk of pipe. During the Eighties I did some construction work. One day, another worker leaned a ladder against the outside of the building that we were putting up, climbed up to the second-story level, and used the Hole Hawg to drill a hole through the exterior wall. At some point, the drill bit caught in the wall. The Hole Hawg, following its one and only imperative, kept going. It spun the worker's body around like a rag doll, causing him to knock his own ladder down. Fortunately he kept his grip on the Hole Hawg, which remained lodged in the wall, and he simply dangled from it and shouted for help until someone came along and reinstated the ladder. I myself used a Hole Hawg to drill many holes through studs, which it did as a blender chops cabbage. I also used it to cut a few six-inch-diameter holes through an old lath-and-plaster ceiling. I chucked in a new hole saw, went up to the second story, reached down between the newly installed floor joists, and began to cut through the first-floor ceiling below. Where my homeowner's drill had labored and whined to spin the huge bit around, and had stalled at the slightest obstruction, the Hole Hawg rotated with the stupid consistency of a spinning planet. When the hole saw seized up, the Hole Hawg spun itself and me around, and crushed one of my hands between the steel pipe handle and a joist, producing a few lacerations, each surrounded by a wide corona of deeply bruised flesh. It also bent the hole saw itself, though not so badly that I couldn't use it. After a few such run-ins, when I got ready to use the Hole Hawg my heart actually began to pound with atavistic terror. But I never blamed the Hole Hawg; I blamed myself. The Hole Hawg is dangerous because it does exactly what you tell it to. It is not bound by the physical limitations that are inherent in a cheap drill, and neither is it limited by safety interlocks that might be built into a homeowner's product by a liability-conscious manufacturer. The danger lies not in the machine itself but in the user's failure to envision the full consequences of the instructions he gives to it. A smaller tool is dangerous too, but for a completely different reason: it tries to do what you tell it to, and fails in some way that is unpredictable and almost always undesirable. But the Hole Hawg is like the genie of the ancient fairy tales, who carries out his master's instructions literally and precisely and with unlimited power, often with disastrous, unforeseen consequences. Pre-Hole Hawg, I used to examine the drill selection in hardware stores with what I thought was a judicious eye, scorning the smaller low-end models and hefting the big expensive ones appreciatively, wishing I could afford one of them babies. Now I view them all with such contempt that I do not even consider them to be real drills--merely scaled-up toys designed to exploit the self-delusional tendencies of soft-handed homeowners who want to believe that they have purchased an actual tool. Their plastic casings, carefully designed and focus-group-tested to convey a feeling of solidity and power, seem disgustingly flimsy and cheap to me, and I am ashamed that I was ever bamboozled into buying such knicknacks. It is not hard to imagine what the world would look like to someone who had been raised by contractors and who had never used any drill other than a Hole Hawg. Such a person, presented with the best and most expensive hardware-store drill, would not even recognize it as such. He might instead misidentify it as a child's toy, or some kind of motorized screwdriver. If a salesperson or a deluded homeowner referred to it as a drill, he would laugh and tell them that they were mistaken--they simply had their terminology wrong. His interlocutor would go away irritated, and probably feeling rather defensive about his basement full of cheap, dangerous, flashy, colorful tools. Unix is the Hole Hawg of operating systems, and Unix hackers, like Doug Barnes and the guy in the Dilbert cartoon and many of the other people who populate Silicon Valley, are like contractor's sons who grew up using only Hole Hawgs. They might use Apple/Microsoft OSes to write letters, play video games, or balance their checkbooks, but they cannot really bring themselves to take these operating systems seriously. THE ORAL TRADITION Unix is hard to learn. The process of learning it is one of multiple small epiphanies. Typically you are just on the verge of inventing some necessary tool or utility when you realize that someone else has already invented it, and built it in, and this explains some odd file or directory or command that you have noticed but never really understood before. For example there is a command (a small program, part of the OS) called whoami, which enables you to ask the computer who it thinks you are. On a Unix machine, you are always logged in under some name--possibly even your own! What files you may work with, and what software you may use, depends on your identity. When I started out using Linux, I was on a non-networked machine in my basement, with only one user account, and so when I became aware of the whoami command it struck me as ludicrous. But once you are logged in as one person, you can temporarily switch over to a pseudonym in order to access different files. If your machine is on the Internet, you can log onto other computers, provided you have a user name and a password. At that point the distant machine becomes no different in practice from the one right in front of you. These changes in identity and location can easily become nested inside each other, many layers deep, even if you aren't doing anything nefarious. Once you have forgotten who and where you are, the whoami command is indispensible. I use it all the time. The file systems of Unix machines all have the same general structure. On your flimsy operating systems, you can create directories (folders) and give them names like Frodo or My Stuff and put them pretty much anywhere you like. But under Unix the highest level--the root--of the filesystem is always designated with the single character "/" and it always contains the same set of top-level directories: /usr /etc /var /bin /proc /boot /home /root /sbin /dev /lib /tmp and each of these directories typically has its own distinct structure of subdirectories. Note the obsessive use of abbreviations and avoidance of capital letters; this is a system invented by people to whom repetitive stress disorder is what black lung is to miners. Long names get worn down to three-letter nubbins, like stones smoothed by a river. This is not the place to try to explain why each of the above directories exists, and what is contained in it. At first it all seems obscure; worse, it seems deliberately obscure. When I started using Linux I was accustomed to being able to create directories wherever I wanted and to give them whatever names struck my fancy. Under Unix you are free to do that, of course (you are free to do anything) but as you gain experience with the system you come to understand that the directories listed above were created for the best of reasons and that your life will be much easier if you follow along (within /home, by the way, you have pretty much unlimited freedom). After this kind of thing has happened several hundred or thousand times, the hacker understands why Unix is the way it is, and agrees that it wouldn't be the same any other way. It is this sort of acculturation that gives Unix hackers their confidence in the system, and the attitude of calm, unshakable, annoying superiority captured in the Dilbert cartoon. Windows 95 and MacOS are products, contrived by engineers in the service of specific companies. Unix, by contrast, is not so much a product as it is a painstakingly compiled oral history of the hacker subculture. It is our Gilgamesh epic. What made old epics like Gilgamesh so powerful and so long-lived was that they were living bodies of narrative that many people knew by heart, and told over and over again--making their own personal embellishments whenever it struck their fancy. The bad embellishments were shouted down, the good ones picked up by others, polished, improved, and, over time, incorporated into the story. Likewise, Unix is known, loved, and understood by so many hackers that it can be re-created from scratch whenever someone needs it. This is very difficult to understand for people who are accustomed to thinking of OSes as things that absolutely have to be bought. Many hackers have launched more or less successful re-implementations of the Unix ideal. Each one brings in new embellishments. Some of them die out quickly, some are merged with similar, parallel innovations created by different hackers attacking the same problem, others still are embraced, and adopted into the epic. Thus Unix has slowly accreted around a simple kernel and acquired a kind of complexity and asymmetry about it that is organic, like the roots of a tree, or the branchings of a coronary artery. Understanding it is more like anatomy than physics. For at least a year, prior to my adoption of Linux, I had been hearing about it. Credible, well-informed people kept telling me that a bunch of hackers had got together an implentation of Unix that could be downloaded, free of charge, from the Internet. For a long time I could not bring myself to take the notion seriously. It was like hearing rumors that a group of model rocket enthusiasts had created a completely functional Saturn V by exchanging blueprints on the Net and mailing valves and flanges to each other. But it's true. Credit for Linux generally goes to its human namesake, one Linus Torvalds, a Finn who got the whole thing rolling in 1991 when he used some of the GNU tools to write the beginnings of a Unix kernel that could run on PC-compatible hardware. And indeed Torvalds deserves all the credit he has ever gotten, and a whole lot more. But he could not have made it happen by himself, any more than Richard Stallman could have. To write code at all, Torvalds had to have cheap but powerful development tools, and these he got from Stallman's GNU project. And he had to have cheap hardware on which to write that code. Cheap hardware is a much harder thing to arrange than cheap software; a single person (Stallman) can write software and put it up on the Net for free, but in order to make hardware it's necessary to have a whole industrial infrastructure, which is not cheap by any stretch of the imagination. Really the only way to make hardware cheap is to punch out an incredible number of copies of it, so that the unit cost eventually drops. For reasons already explained, Apple had no desire to see the cost of hardware drop. The only reason Torvalds had cheap hardware was Microsoft. Microsoft refused to go into the hardware business, insisted on making its software run on hardware that anyone could build, and thereby created the market conditions that allowed hardware prices to plummet. In trying to understand the Linux phenomenon, then, we have to look not to a single innovator but to a sort of bizarre Trinity: Linus Torvalds, Richard Stallman, and Bill Gates. Take away any of these three and Linux would not exist. OS SHOCK Young Americans who leave their great big homogeneous country and visit some other part of the world typically go through several stages of culture shock: first, dumb wide-eyed astonishment. Then a tentative engagement with the new country's manners, cuisine, public transit systems and toilets, leading to a brief period of fatuous confidence that they are instant experts on the new country. As the visit wears on, homesickness begins to set in, and the traveler begins to appreciate, for the first time, how much he or she took for granted at home. At the same time it begins to seem obvious that many of one's own cultures and traditions are essentially arbitrary, and could have been different; driving on the right side of the road, for example. When the traveler returns home and takes stock of the experience, he or she may have learned a good deal more about America than about the country they went to visit. For the same reasons, Linux is worth trying. It is a strange country indeed, but you don't have to live there; a brief sojourn suffices to give some flavor of the place and--more importantly--to lay bare everything that is taken for granted, and all that could have been done differently, under Windows or MacOS. You can't try it unless you install it. With any other OS, installing it would be a straightforward transaction: in exchange for money, some company would give you a CD-ROM, and you would be on your way. But a lot is subsumed in that kind of transaction, and has to be gone through and picked apart. We like plain dealings and straightforward transactions in America. If you go to Egypt and, say, take a taxi somewhere, you become a part of the taxi driver's life; he refuses to take your money because it would demean your friendship, he follows you around town, and weeps hot tears when you get in some other guy's taxi. You end up meeting his kids at some point, and have to devote all sort of ingenuity to finding some way to compensate him without insulting his honor. It is exhausting. Sometimes you just want a simple Manhattan-style taxi ride. But in order to have an American-style setup, where you can just go out and hail a taxi and be on your way, there must exist a whole hidden apparatus of medallions, inspectors, commissions, and so forth--which is fine as long as taxis are cheap and you can always get one. When the system fails to work in some way, it is mysterious and infuriating and turns otherwise reasonable people into conspiracy theorists. But when the Egyptian system breaks down, it breaks down transparently. You can't get a taxi, but your driver's nephew will show up, on foot, to explain the problem and apologize. Microsoft and Apple do things the Manhattan way, with vast complexity hidden behind a wall of interface. Linux does things the Egypt way, with vast complexity strewn about all over the landscape. If you've just flown in from Manhattan, your first impulse will be to throw up your hands and say "For crying out loud! Will you people get a grip on yourselves!?" But this does not make friends in Linux-land any better than it would in Egypt. You can suck Linux right out of the air, as it were, by downloading the right files and putting them in the right places, but there probably are not more than a few hundred people in the world who could create a functioning Linux system in that way. What you really need is a distribution of Linux, which means a prepackaged set of files. But distributions are a separate thing from Linux per se. Linux per se is not a specific set of ones and zeroes, but a self-organizing Net subculture. The end result of its collective lucubrations is a vast body of source code, almost all written in C (the dominant computer programming language). "Source code" just means a computer program as typed in and edited by some hacker. If it's in C, the file name will probably have .c or .cpp on the end of it, depending on which dialect was used; if it's in some other language it will have some other suffix. Frequently these sorts of files can be found in a directory with the name /src which is the hacker's Hebraic abbreviation of "source." Source files are useless to your computer, and of little interest to most users, but they are of gigantic cultural and political significance, because Microsoft and Apple keep them secret while Linux makes them public. They are the family jewels. They are the sort of thing that in Hollywood thrillers is used as a McGuffin: the plutonium bomb core, the top-secret blueprints, the suitcase of bearer bonds, the reel of microfilm. If the source files for Windows or MacOS were made public on the Net, then those OSes would become free, like Linux--only not as good, because no one would be around to fix bugs and answer questions. Linux is "open source" software meaning, simply, that anyone can get copies of its source code files. Your computer doesn't want source code any more than you do; it wants object code. Object code files typically have the suffix .o and are unreadable all but a few, highly strange humans, because they consist of ones and zeroes. Accordingly, this sort of file commonly shows up in a directory with the name /bin, for "binary." Source files are simply ASCII text files. ASCII denotes a particular way of encoding letters into bit patterns. In an ASCII file, each character has eight bits all to itself. This creates a potential "alphabet" of 256 distinct characters, in that eight binary digits can form that many unique patterns. In practice, of course, we tend to limit ourselves to the familiar letters and digits. The bit-patterns used to represent those letters and digits are the same ones that were physically punched into the paper tape by my high school teletype, which in turn were the same one used by the telegraph industry for decades previously. ASCII text files, in other words, are telegrams, and as such they have no typographical frills. But for the same reason they are eternal, because the code never changes, and universal, because every text editing and word processing software ever written knows about this code. Therefore just about any software can be used to create, edit, and read source code files. Object code files, then, are created from these source files by a piece of software called a compiler, and forged into a working application by another piece of software called a linker. The triad of editor, compiler, and linker, taken together, form the core of a software development system. Now, it is possible to spend a lot of money on shrink-wrapped development systems with lovely graphical user interfaces and various ergonomic enhancements. In some cases it might even be a good and reasonable way to spend money. But on this side of the road, as it were, the very best software is usually the free stuff. Editor, compiler and linker are to hackers what ponies, stirrups, and archery sets were to the Mongols. Hackers live in the saddle, and hack on their own tools even while they are using them to create new applications. It is quite inconceivable that superior hacking tools could have been created from a blank sheet of paper by product engineers. Even if they are the brightest engineers in the world they are simply outnumbered. In the GNU/Linux world there are two major text editing programs: the minimalist vi (known in some implementations as elvis) and the maximalist emacs. I use emacs, which might be thought of as a thermonuclear word processor. It was created by Richard Stallman; enough said. It is written in Lisp, which is the only computer language that is beautiful. It is colossal, and yet it only edits straight ASCII text files, which is to say, no fonts, no boldface, no underlining. In other words, the engineer-hours that, in the case of Microsoft Word, were devoted to features like mail merge, and the ability to embed feature-length motion pictures in corporate memoranda, were, in the case of emacs, focused with maniacal intensity on the deceptively simple-seeming problem of editing text. If you are a professional writer--i.e., if someone else is getting paid to worry about how your words are formatted and printed--emacs outshines all other editing software in approximately the same way that the noonday sun does the stars. It is not just bigger and brighter; it simply makes everything else vanish. For page layout and printing you can use TeX: a vast corpus of typesetting lore written in C and also available on the Net for free. I could say a lot about emacs and TeX, but right now I am trying to tell a story about how to actually install Linux on your machine. The hard-core survivalist approach would be to download an editor like emacs, and the GNU Tools--the compiler and linker--which are polished and excellent to the same degree as emacs. Equipped with these, one would be able to start downloading ASCII source code files (/src) and compiling them into binary object code files (/bin) that would run on the machine. But in order to even arrive at this point--to get emacs running, for example--you have to have Linux actually up and running on your machine. And even a minimal Linux operating system requires thousands of binary files all acting in concert, and arranged and linked together just so. Several entities have therefore taken it upon themselves to create "distributions" of Linux. If I may extend the Egypt analogy slightly, these entities are a bit like tour guides who meet you at the airport, who speak your language, and who help guide you through the initial culture shock. If you are an Egyptian, of course, you see it the other way; tour guides exist to keep brutish outlanders from traipsing through your mosques and asking you the same questions over and over and over again. Some of these tour guides are commercial organizations, such as Red Hat Software, which makes a Linux distribution called Red Hat that has a relatively commercial sheen to it. In most cases you put a Red Hat CD-ROM into your PC and reboot and it handles the rest. Just as a tour guide in Egypt will expect some sort of compensation for his services, commercial distributions need to be paid for. In most cases they cost almost nothing and are well worth it. I use a distribution called Debian (the word is a contraction of "Deborah" and "Ian") which is non-commercial. It is organized (or perhaps I should say "it has organized itself") along the same lines as Linux in general, which is to say that it consists of volunteers who collaborate over the Net, each responsible for looking after a different chunk of the system. These people have broken Linux down into a number of packages, which are compressed files that can be downloaded to an already functioning Debian Linux system, then opened up and unpacked using a free installer application. Of course, as such, Debian has no commercial arm--no distribution mechanism. You can download all Debian packages over the Net, but most people will want to have them on a CD-ROM. Several different companies have taken it upon themselves to decoct all of the current Debian packages onto CD-ROMs and then sell them. I buy mine from Linux Systems Labs. The cost for a three-disc set, containing Debian in its entirety, is less than three dollars. But (and this is an important distinction) not a single penny of that three dollars is going to any of the coders who created Linux, nor to the Debian packagers. It goes to Linux Systems Labs and it pays, not for the software, or the packages, but for the cost of stamping out the CD-ROMs. Every Linux distribution embodies some more or less clever hack for circumventing the normal boot process and causing your computer, when it is turned on, to organize itself, not as a PC running Windows, but as a "host" running Unix. This is slightly alarming the first time you see it, but completely harmless. When a PC boots up, it goes through a little self-test routine, taking an inventory of available disks and memory, and then begins looking around for a disk to boot up from. In any normal Windows computer that disk will be a hard drive. But if you have your system configured right, it will look first for a floppy or CD-ROM disk, and boot from that if one is available. Linux exploits this chink in the defenses. Your computer notices a bootable disk in the floppy or CD-ROM drive, loads in some object code from that disk, and blindly begins to execute it. But this is not Microsoft or Apple code, this is Linux code, and so at this point your computer begins to behave very differently from what you are accustomed to. Cryptic messages began to scroll up the screen. If you had booted a commercial OS, you would, at this point, be seeing a "Welcome to MacOS" cartoon, or a screen filled with clouds in a blue sky, and a Windows logo. But under Linux you get a long telegram printed in stark white letters on a black screen. There is no "welcome!" message. Most of the telegram has the semi-inscrutable menace of graffiti tags. Dec 14 15:04:15 theRev syslogd 1.3-3#17: restart. Dec 14 15:04:15 theRev kernel: klogd 1.3-3, log source = /proc/kmsg started. Dec 14 15:04:15 theRev kernel: Loaded 3535 symbols from /System.map. Dec 14 15:04:15 theRev kernel: Symbols match kernel version 2.0.30. Dec 14 15:04:15 theRev kernel: No module symbols loaded. Dec 14 15:04:15 theRev kernel: Intel MultiProcessor Specification v1.4 Dec 14 15:04:15 theRev kernel: Virtual Wire compatibility mode. Dec 14 15:04:15 theRev kernel: OEM ID: INTEL Product ID: 440FX APIC at: 0xFEE00000 Dec 14 15:04:15 theRev kernel: Processor #0 Pentium(tm) Pro APIC version 17 Dec 14 15:04:15 theRev kernel: Processor #1 Pentium(tm) Pro APIC version 17 Dec 14 15:04:15 theRev kernel: I/O APIC #2 Version 17 at 0xFEC00000. Dec 14 15:04:15 theRev kernel: Processors: 2 Dec 14 15:04:15 theRev kernel: Console: 16 point font, 400 scans Dec 14 15:04:15 theRev kernel: Console: colour VGA+ 80x25, 1 virtual console (max 63) Dec 14 15:04:15 theRev kernel: pcibios_init : BIOS32 Service Directory structure at 0x000fdb70 Dec 14 15:04:15 theRev kernel: pcibios_init : BIOS32 Service Directory entry at 0xfdb80 Dec 14 15:04:15 theRev kernel: pcibios_init : PCI BIOS revision 2.10 entry at 0xfdba1 Dec 14 15:04:15 theRev kernel: Probing PCI hardware. Dec 14 15:04:15 theRev kernel: Warning : Unknown PCI device (10b7:9001). Please read include/linux/pci.h Dec 14 15:04:15 theRev kernel: Calibrating delay loop.. ok - 179.40 BogoMIPS Dec 14 15:04:15 theRev kernel: Memory: 64268k/66556k available (700k kernel code, 384k reserved, 1204k data) Dec 14 15:04:15 theRev kernel: Swansea University Computer Society NET3.035 for Linux 2.0 Dec 14 15:04:15 theRev kernel: NET3: Unix domain sockets 0.13 for Linux NET3.035. Dec 14 15:04:15 theRev kernel: Swansea University Computer Society TCP/IP for NET3.034 Dec 14 15:04:15 theRev kernel: IP Protocols: ICMP, UDP, TCP Dec 14 15:04:15 theRev kernel: Checking 386/387 coupling... Ok, fpu using exception 16 error reporting. Dec 14 15:04:15 theRev kernel: Checking 'hlt' instruction... Ok. Dec 14 15:04:15 theRev kernel: Linux version 2.0.30 (root@theRev) (gcc version 2.7.2.1) #15 Fri Mar 27 16:37:24 PST 1998 Dec 14 15:04:15 theRev kernel: Booting processor 1 stack 00002000: Calibrating delay loop.. ok - 179.40 BogoMIPS Dec 14 15:04:15 theRev kernel: Total of 2 processors activated (358.81 BogoMIPS). Dec 14 15:04:15 theRev kernel: Serial driver version 4.13 with no serial options enabled Dec 14 15:04:15 theRev kernel: tty00 at 0x03f8 (irq = 4) is a 16550A Dec 14 15:04:15 theRev kernel: tty01 at 0x02f8 (irq = 3) is a 16550A Dec 14 15:04:15 theRev kernel: lp1 at 0x0378, (polling) Dec 14 15:04:15 theRev kernel: PS/2 auxiliary pointing device detected -- driver installed. Dec 14 15:04:15 theRev kernel: Real Time Clock Driver v1.07 Dec 14 15:04:15 theRev kernel: loop: registered device at major 7 Dec 14 15:04:15 theRev kernel: ide: i82371 PIIX (Triton) on PCI bus 0 function 57 Dec 14 15:04:15 theRev kernel: ide0: BM-DMA at 0xffa0-0xffa7 Dec 14 15:04:15 theRev kernel: ide1: BM-DMA at 0xffa8-0xffaf Dec 14 15:04:15 theRev kernel: hda: Conner Peripherals 1275MB - CFS1275A, 1219MB w/64kB Cache, LBA, CHS=619/64/63 Dec 14 15:04:15 theRev kernel: hdb: Maxtor 84320A5, 4119MB w/256kB Cache, LBA, CHS=8928/15/63, DMA Dec 14 15:04:15 theRev kernel: hdc: , ATAPI CDROM drive Dec 15 11:58:06 theRev kernel: ide0 at 0x1f0-0x1f7,0x3f6 on irq 14 Dec 15 11:58:06 theRev kernel: ide1 at 0x170-0x177,0x376 on irq 15 Dec 15 11:58:06 theRev kernel: Floppy drive(s): fd0 is 1.44M Dec 15 11:58:06 theRev kernel: Started kswapd v 1.4.2.2 Dec 15 11:58:06 theRev kernel: FDC 0 is a National Semiconductor PC87306 Dec 15 11:58:06 theRev kernel: md driver 0.35 MAX_MD_DEV=4, MAX_REAL=8 Dec 15 11:58:06 theRev kernel: PPP: version 2.2.0 (dynamic channel allocation) Dec 15 11:58:06 theRev kernel: TCP compression code copyright 1989 Regents of the University of California Dec 15 11:58:06 theRev kernel: PPP Dynamic channel allocation code copyright 1995 Caldera, Inc. Dec 15 11:58:06 theRev kernel: PPP line discipline registered. Dec 15 11:58:06 theRev kernel: SLIP: version 0.8.4-NET3.019-NEWTTY (dynamic channels, max=256). Dec 15 11:58:06 theRev kernel: eth0: 3Com 3c900 Boomerang 10Mbps/Combo at 0xef00, 00:60:08:a4:3c:db, IRQ 10 Dec 15 11:58:06 theRev kernel: 8K word-wide RAM 3:5 Rx:Tx split, 10base2 interface. Dec 15 11:58:06 theRev kernel: Enabling bus-master transmits and whole-frame receives. Dec 15 11:58:06 theRev kernel: 3c59x.c:v0.49 1/2/98 Donald Becker http://cesdis.gsfc.nasa.gov/linux/drivers/vortex.html Dec 15 11:58:06 theRev kernel: Partition check: Dec 15 11:58:06 theRev kernel: hda: hda1 hda2 hda3 Dec 15 11:58:06 theRev kernel: hdb: hdb1 hdb2 Dec 15 11:58:06 theRev kernel: VFS: Mounted root (ext2 filesystem) readonly. Dec 15 11:58:06 theRev kernel: Adding Swap: 16124k swap-space (priority -1) Dec 15 11:58:06 theRev kernel: EXT2-fs warning: maximal mount count reached, running e2fsck is recommended Dec 15 11:58:06 theRev kernel: hdc: media changed Dec 15 11:58:06 theRev kernel: ISO9660 Extensions: RRIP_1991A Dec 15 11:58:07 theRev syslogd 1.3-3#17: restart. Dec 15 11:58:09 theRev diald[87]: Unable to open options file /etc/diald/diald.options: No such file or directory Dec 15 11:58:09 theRev diald[87]: No device specified. You must have at least one device! Dec 15 11:58:09 theRev diald[87]: You must define a connector script (option 'connect'). Dec 15 11:58:09 theRev diald[87]: You must define the remote ip address. Dec 15 11:58:09 theRev diald[87]: You must define the local ip address. Dec 15 11:58:09 theRev diald[87]: Terminating due to damaged reconfigure. The only parts of this that are readable, for normal people, are the error messages and warnings. And yet it's noteworthy that Linux doesn't stop, or crash, when it encounters an error; it spits out a pithy complaint, gives up on whatever processes were damaged, and keeps on rolling. This was decidedly not true of the early versions of Apple and Microsoft OSes, for the simple reason that an OS that is not capable of walking and chewing gum at the same time cannot possibly recover from errors. Looking for, and dealing with, errors requires a separate process running in parallel with the one that has erred. A kind of superego, if you will, that keeps an eye on all of the others, and jumps in when one goes astray. Now that MacOS and Windows can do more than one thing at a time they are much better at dealing with errors than they used to be, but they are not even close to Linux or other Unices in this respect; and their greater complexity has made them vulnerable to new types of errors. FALLIBILITY, ATONEMENT, REDEMPTION, TRUST, AND OTHER ARCANE TECHNICAL CONCEPTS Linux is not capable of having any centrally organized policies dictating how to write error messages and documentation, and so each programmer writes his own. Usually they are in English even though tons of Linux programmers are Europeans. Frequently they are funny. Always they are honest. If something bad has happened because the software simply isn't finished yet, or because the user screwed something up, this will be stated forthrightly. The command line interface makes it easy for programs to dribble out little comments, warnings, and messages here and there. Even if the application is imploding like a damaged submarine, it can still usually eke out a little S.O.S. message. Sometimes when you finish working with a program and shut it down, you find that it has left behind a series of mild warnings and low-grade error messages in the command-line interface window from which you launched it. As if the software were chatting to you about how it was doing the whole time you were working with it. Documentation, under Linux, comes in the form of man (short for manual) pages. You can access these either through a GUI (xman) or from the command line (man). Here is a sample from the man page for a program called rsh: "Stop signals stop the local rsh process only; this is arguably wrong, but currently hard to fix for reasons too complicated to explain here." The man pages contain a lot of such material, which reads like the terse mutterings of pilots wrestling with the controls of damaged airplanes. The general feel is of a thousand monumental but obscure struggles seen in the stop-action light of a strobe. Each programmer is dealing with his own obstacles and bugs; he is too busy fixing them, and improving the software, to explain things at great length or to maintain elaborate pretensions. In practice you hardly ever encounter a serious bug while running Linux. When you do, it is almost always with commercial software (several vendors sell software that runs under Linux). The operating system and its fundamental utility programs are too important to contain serious bugs. I have been running Linux every day since late 1995 and have seen many application programs go down in flames, but I have never seen the operating system crash. Never. Not once. There are quite a few Linux systems that have been running continuously and working hard for months or years without needing to be rebooted. Commercial OSes have to adopt the same official stance towards errors as Communist countries had towards poverty. For doctrinal reasons it was not possible to admit that poverty was a serious problem in Communist countries, because the whole point of Communism was to eradicate poverty. Likewise, commercial OS companies like Apple and Microsoft can't go around admitting that their software has bugs and that it crashes all the time, any more than Disney can issue press releases stating that Mickey Mouse is an actor in a suit. This is a problem, because errors do exist and bugs do happen. Every few months Bill Gates tries to demo a new Microsoft product in front of a large audience only to have it blow up in his face. Commercial OS vendors, as a direct consequence of being commercial, are forced to adopt the grossly disingenuous position that bugs are rare aberrations, usually someone else's fault, and therefore not really worth talking about in any detail. This posture, which everyone knows to be absurd, is not limited to press releases and ad campaigns. It informs the whole way these companies do business and relate to their customers. If the documentation were properly written, it would mention bugs, errors, and crashes on every single page. If the on-line help systems that come with these OSes reflected the experiences and concerns of their users, they would largely be devoted to instructions on how to cope with crashes and errors. But this does not happen. Joint stock corporations are wonderful inventions that have given us many excellent goods and services. They are good at many things. Admitting failure is not one of them. Hell, they can't even admit minor shortcomings. Of course, this behavior is not as pathological in a corporation as it would be in a human being. Most people, nowadays, understand that corporate press releases are issued for the benefit of the corporation's shareholders and not for the enlightenment of the public. Sometimes the results of this institutional dishonesty can be dreadful, as with tobacco and asbestos. In the case of commercial OS vendors it is nothing of the kind, of course; it is merely annoying. Some might argue that consumer annoyance, over time, builds up into a kind of hardened plaque that can conceal serious decay, and that honesty might therefore be the best policy in the long run; the jury is still out on this in the operating system market. The business is expanding fast enough that it's still much better to have billions of chronically annoyed customers than millions of happy ones. Most system administrators I know who work with Windows NT all the time agree that when it hits a snag, it has to be re-booted, and when it gets seriously messed up, the only way to fix it is to re-install the operating system from scratch. Or at least this is the only way that they know of to fix it, which amounts to the same thing. It is quite possible that the engineers at Microsoft have all sorts of insider knowledge on how to fix the system when it goes awry, but if they do, they do not seem to be getting the message out to any of the actual system administrators I know. Because Linux is not commercial--because it is, in fact, free, as well as rather difficult to obtain, install, and operate--it does not have to maintain any pretensions as to its reliability. Consequently, it is much more reliable. When something goes wrong with Linux, the error is noticed and loudly discussed right away. Anyone with the requisite technical knowledge can go straight to the source code and point out the source of the error, which is then rapidly fixed by whichever hacker has carved out responsibility for that particular program. As far as I know, Debian is the only Linux distribution that has its own constitution (http://www.debian.org/devel/constitution), but what really sold me on it was its phenomenal bug database (http://www.debian.org/Bugs), which is a sort of interactive Doomsday Book of error, fallibility, and redemption. It is simplicity itself. When had a problem with Debian in early January of 1997, I sent in a message describing the problem to submit@bugs.debian.org. My problem was promptly assigned a bug report number (#6518) and a severity level (the available choices being critical, grave, important, normal, fixed, and wishlist) and forwarded to mailing lists where Debian people hang out. Within twenty-four hours I had received five e-mails telling me how to fix the problem: two from North America, two from Europe, and one from Australia. All of these e-mails gave me the same suggestion, which worked, and made my problem go away. But at the same time, a transcript of this exchange was posted to Debian's bug database, so that if other users had the same problem later, they would be able to search through and find the solution without having to enter a new, redundant bug report. Contrast this with the experience that I had when I tried to install Windows NT 4.0 on the very same machine about ten months later, in late 1997. The installation program simply stopped in the middle with no error messages. I went to the Microsoft Support website and tried to perform a search for existing help documents that would address my problem. The search engine was completely nonfunctional; it did nothing at all. It did not even give me a message telling me that it was not working. Eventually I decided that my motherboard must be at fault; it was of a slightly unusual make and model, and NT did not support as many different motherboards as Linux. I am always looking for excuses, no matter how feeble, to buy new hardware, so I bought a new motherboard that was Windows NT logo-compatible, meaning that the Windows NT logo was printed right on the box. I installed this into my computer and got Linux running right away, then attempted to install Windows NT again. Again, the installation died without any error message or explanation. By this time a couple of weeks had gone by and I thought that perhaps the search engine on the Microsoft Support website might be up and running. I gave that a try but it still didn't work. So I created a new Microsoft support account, then logged on to submit the incident. I supplied my product ID number when asked, and then began to follow the instructions on a series of help screens. In other words, I was submitting a bug report just as with the Debian bug tracking system. It's just that the interface was slicker--I was typing my complaint into little text-editing boxes on Web forms, doing it all through the GUI, whereas with Debian you send in an e-mail telegram. I knew that when I was finished submitting the bug report, it would become proprietary Microsoft information, and other users wouldn't be able to see it. Many Linux users would refuse to participate in such a scheme on ethical grounds, but I was willing to give it a shot as an experiment. In the end, though I was never able to submit my bug report, because the series of linked web pages that I was filling out eventually led me to a completely blank page: a dead end. So I went back and clicked on the buttons for "phone support" and eventually was given a Microsoft telephone number. When I dialed this number I got a series of piercing beeps and a recorded message from the phone company saying "We're sorry, your call cannot be completed as dialed." I tried the search page again--it was still completely nonfunctional. Then I tried PPI (Pay Per Incident) again. This led me through another series of Web pages until I dead-ended at one reading: "Notice-there is no Web page matching your request." I tried it again, and eventually got to a Pay Per Incident screen reading: "OUT OF INCIDENTS. There are no unused incidents left in your account. If you would like to purchase a support incident, click OK-you will then be able to prepay for an incident...." The cost per incident was $95. The experiment was beginning to seem rather expensive, so I gave up on the PPI approach and decided to have a go at the FAQs posted on Microsoft's website. None of the available FAQs had anything to do with my problem except for one entitled "I am having some problems installing NT" which appeared to have been written by flacks, not engineers. So I gave up and still, to this day, have never gotten Windows NT installed on that particular machine. For me, the path of least resistance was simply to use Debian Linux. In the world of open source software, bug reports are useful information. Making them public is a service to other users, and improves the OS. Making them public systematically is so important that highly intelligent people voluntarily put time and money into running bug databases. In the commercial OS world, however, reporting a bug is a privilege that you have to pay lots of money for. But if you pay for it, it follows that the bug report must be kept confidential--otherwise anyone could get the benefit of your ninety-five bucks! And yet nothing prevents NT users from setting up their own public bug database. This is, in other words, another feature of the OS market that simply makes no sense unless you view it in the context of culture. What Microsoft is selling through Pay Per Incident isn't technical support so much as the continued illusion that its customers are engaging in some kind of rational business transaction. It is a sort of routine maintenance fee for the upkeep of the fantasy. If people really wanted a solid OS they would use Linux, and if they really wanted tech support they would find a way to get it; Microsoft's customers want something else. As of this writing (Jan. 1999), something like 32,000 bugs have been reported to the Debian Linux bug database. Almost all of them have been fixed a long time ago. There are twelve "critical" bugs still outstanding, of which the oldest was posted 79 days ago. There are 20 outstanding "grave" bugs of which the oldest is 1166 days old. There are 48 "important" bugs and hundreds of "normal" and less important ones. Likewise, BeOS (which I'll get to in a minute) has its own bug database (http://www.be.com/developers/bugs/index.html) with its own classification system, including such categories as "Not a Bug," "Acknowledged Feature," and "Will Not Fix." Some of the "bugs" here are nothing more than Be hackers blowing off steam, and are classified as "Input Acknowledged." For example, I found one that was posted on December 30th, 1998. It's in the middle of a long list of bugs, wedged between one entitled "Mouse working in very strange fashion" and another called "Change of BView frame does not affect, if BView not attached to a BWindow." This one is entitled R4: BeOS missing megalomaniacal figurehead to harness and focus developer rage and it goes like this: ---------------------------- Be Status: Input Acknowledged BeOS Version: R3.2 Component: unknown Full Description: The BeOS needs a megalomaniacal egomaniac sitting on its throne to give it a human character which everyone loves to hate. Without this, the BeOS will languish in the impersonifiable realm of OSs that people can never quite get a handle on. You can judge the success of an OS not by the quality of its features, but by how infamous and disliked the leaders behind them are. I believe this is a side-effect of developer comraderie under miserable conditions. After all, misery loves company. I believe that making the BeOS less conceptually accessible and far less reliable will require developers to band together, thus developing the kind of community where strangers talk to one- another, kind of like at a grocery store before a huge snowstorm. Following this same program, it will likely be necessary to move the BeOS headquarters to a far-less-comfortable climate. General environmental discomfort will breed this attitude within and there truly is no greater recipe for success. I would suggest Seattle, but I think it's already taken. You might try Washington, DC, but definitely not somewhere like San Diego or Tucson. ---------------------------- Unfortunately, the Be bug reporting system strips off the names of the people who report the bugs (to protect them from retribution!?) and so I don't know who wrote this. So it would appear that I'm in the middle of crowing about the technical and moral superiority of Debian Linux. But as almost always happens in the OS world, it's more complicated than that. I have Windows NT running on another machine, and the other day (Jan. 1999), when I had a problem with it, I decided to have another go at Microsoft Support. This time the search engine actually worked (though in order to reach it I had to identify myself as "advanced"). And instead of coughing up some useless FAQ, it located about two hundred documents (I was using very vague search criteria) that were obviously bug reports--though they were called something else. Microsoft, in other words, has got a system up and running that is functionally equivalent to Debian's bug database. It looks and feels different, of course, but it contains technical nitty-gritty and makes no bones about the existence of errors. As I've explained, selling OSes for money is a basically untenable position, and the only way Apple and Microsoft can get away with it is by pursuing technological advancements as aggressively as they can, and by getting people to believe in, and to pay for, a particular image: in the case of Apple, that of the creative free thinker, and in the case of Microsoft, that of the respectable techno-bourgeois. Just like Disney, they're making money from selling an interface, a magic mirror. It has to be polished and seamless or else the whole illusion is ruined and the business plan vanishes like a mirage. Accordingly, it was the case until recently that the people who wrote manuals and created customer support websites for commercial OSes seemed to have been barred, by their employers' legal or PR departments, from admitting, even obliquely, that the software might contain bugs or that the interface might be suffering from the blinking twelve problem. They couldn't address users' actual difficulties. The manuals and websites were therefore useless, and caused even technically self-assured users to wonder whether they were going subtly insane. When Apple engages in this sort of corporate behavior, one wants to believe that they are really trying their best. We all want to give Apple the benefit of the doubt, because mean old Bill Gates kicked the crap out of them, and because they have good PR. But when Microsoft does it, one almost cannot help becoming a paranoid conspiracist. Obviously they are hiding something from us! And yet they are so powerful! They are trying to drive us crazy! This approach to dealing with one's customers was straight out of the Central European totalitarianism of the mid-Twentieth Century. The adjectives "Kafkaesque" and "Orwellian" come to mind. It couldn't last, any more than the Berlin Wall could, and so now Microsoft has a publicly available bug database. It's called something else, and it takes a while to find it, but it's there. They have, in other words, adapted to the two-tiered Eloi/Morlock structure of technological society. If you're an Eloi you install Windows, follow the instructions, hope for the best, and dumbly suffer when it breaks. If you're a Morlock you go to the website, tell it that you are "advanced," find the bug database, and get the truth straight from some anonymous Microsoft engineer. But once Microsoft has taken this step, it raises the question, once again, of whether there is any point to being in the OS business at all. Customers might be willing to pay $95 to report a problem to Microsoft if, in return, they get some advice that no other user is getting. This has the useful side effect of keeping the users alienated from one another, which helps maintain the illusion that bugs are rare aberrations. But once the results of those bug reports become openly available on the Microsoft website, everything changes. No one is going to cough up $95 to report a problem when chances are good that some other sucker will do it first, and that instructions on how to fix the bug will then show up, for free, on a public website. And as the size of the bug database grows, it eventually becomes an open admission, on Microsoft's part, that their OSes have just as many bugs as their competitors'. There is no shame in that; as I mentioned, Debian's bug database has logged 32,000 reports so far. But it puts Microsoft on an equal footing with the others and makes it a lot harder for their customers--who want to believe--to believe. MEMENTO MORI Once the Linux machine has finished spitting out its jargonic opening telegram, it prompts me to log in with a user name and a password. At this point the machine is still running the command line interface, with white letters on a black screen. There are no windows, menus, or buttons. It does not respond to the mouse; it doesn't even know that the mouse is there. It is still possible to run a lot of software at this point. Emacs, for example, exists in both a CLI and a GUI version (actually there are two GUI versions, reflecting some sort of doctrinal schism between Richard Stallman and some hackers who got fed up with him). The same is true of many other Unix programs. Many don't have a GUI at all, and many that do are capable of running from the command line. Of course, since my computer only has one monitor screen, I can only see one command line, and so you might think that I could only interact with one program at a time. But if I hold down the Alt key and then hit the F2 function button at the top of my keyboard, I am presented with a fresh, blank, black screen with a login prompt at the top of it. I can log in here and start some other program, then hit Alt-F1 and go back to the first screen, which is still doing whatever it was when I left it. Or I can do Alt-F3 and log in to a third screen, or a fourth, or a fifth. On one of these screens I might be logged in as myself, on another as root (the system administrator), on yet another I might be logged on to some other computer over the Internet. Each of these screens is called, in Unix-speak, a tty, which is an abbreviation for teletype. So when I use my Linux system in this way I am going right back to that small room at Ames High School where I first wrote code twenty-five years ago, except that a tty is quieter and faster than a teletype, and capable of running vastly superior software, such as emacs or the GNU development tools. It is easy (easy by Unix, not Apple/Microsoft standards) to configure a Linux machine so that it will go directly into a GUI when you boot it up. This way, you never see a tty screen at all. I still have mine boot into the white-on-black teletype screen however, as a computational memento mori. It used to be fashionable for a writer to keep a human skull on his desk as a reminder that he was mortal, that all about him was vanity. The tty screen reminds me that the same thing is true of slick user interfaces. The X Windows System, which is the GUI of Unix, has to be capable of running on hundreds of different video cards with different chipsets, amounts of onboard memory, and motherboard buses. Likewise, there are hundreds of different types of monitors on the new and used market, each with different specifications, and so there are probably upwards of a million different possible combinations of card and monitor. The only thing they all have in common is that they all work in VGA mode, which is the old command-line screen that you see for a few seconds when you launch Windows. So Linux always starts in VGA, with a teletype interface, because at first it has no idea what sort of hardware is attached to your computer. In order to get beyond the glass teletype and into the GUI, you have to tell Linux exactly what kinds of hardware you have. If you get it wrong, you'll get a blank screen at best, and at worst you might actually destroy your monitor by feeding it signals it can't handle. When I started using Linux this had to be done by hand. I once spent the better part of a month trying to get an oddball monitor to work for me, and filled the better part of a composition book with increasingly desperate scrawled notes. Nowadays, most Linux distributions ship with a program that automatically scans the video card and self-configures the system, so getting X Windows up and running is nearly as easy as installing an Apple/Microsoft GUI. The crucial information goes into a file (an ASCII text file, naturally) called XF86Config, which is worth looking at even if your distribution creates it for you automatically. For most people it looks like meaningless cryptic incantations, which is the whole point of looking at it. An Apple/Microsoft system needs to have the same information in order to launch its GUI, but it's apt to be deeply hidden somewhere, and it's probably in a file that can't even be opened and read by a text editor. All of the important files that make Linux systems work are right out in the open. They are always ASCII text files, so you don't need special tools to read them. You can look at them any time you want, which is good, and you can mess them up and render your system totally dysfunctional, which is not so good. At any rate, assuming that my XF86Config file is just so, I enter the command "startx" to launch the X Windows System. The screen blanks out for a minute, the monitor makes strange twitching noises, then reconstitutes itself as a blank gray desktop with a mouse cursor in the middle. At the same time it is launching a window manager. X Windows is pretty low-level software; it provides the infrastructure for a GUI, and it's a heavy industrial infrastructure. But it doesn't do windows. That's handled by another category of application that sits atop X Windows, called a window manager. Several of these are available, all free of course. The classic is twm (Tom's Window Manager) but there is a smaller and supposedly more efficient variant of it called fvwm, which is what I use. I have my eye on a completely different window manager called Enlightenment, which may be the hippest single technology product I have ever seen, in that (a) it is for Linux, (b) it is freeware, (c) it is being developed by a very small number of obsessed hackers, and (d) it looks amazingly cool; it is the sort of window manager that might show up in the backdrop of an Aliens movie. Anyway, the window manager acts as an intermediary between X Windows and whatever software you want to use. It draws the window frames, menus, and so on, while the applications themselves draw the actual content in the windows. The applications might be of any sort: text editors, Web browsers, graphics packages, or utility programs, such as a clock or calculator. In other words, from this point on, you feel as if you have been shunted into a parallel universe that is quite similar to the familiar Apple or Microsoft one, but slightly and pervasively different. The premier graphics program under Apple/Microsoft is Adobe Photoshop, but under Linux it's something called The GIMP. Instead of the Microsoft Office Suite, you can buy something called ApplixWare. Many commercial software packages, such as Mathematica, Netscape Communicator, and Adobe Acrobat, are available in Linux versions, and depending on how you set up your window manager you can make them look and behave just as they would under MacOS or Windows. But there is one type of window you'll see on Linux GUI that is rare or nonexistent under other OSes. These windows are called "xterm" and contain nothing but lines of text--this time, black text on a white background, though you can make them be different colors if you choose. Each xterm window is a separate command line interface--a tty in a window. So even when you are in full GUI mode, you can still talk to your Linux machine through a command-line interface. There are many good pieces of Unix software that do not have GUIs at all. This might be because they were developed before X Windows was available, or because the people who wrote them did not want to suffer through all the hassle of creating a GUI, or because they simply do not need one. In any event, those programs can be invoked by typing their names into the command line of an xterm window. The whoami command, mentioned earlier, is a good example. There is another called wc ("word count") which simply returns the number of lines, words, and characters in a text file. The ability to run these little utility programs on the command line is a great virtue of Unix, and one that is unlikely to be duplicated by pure GUI operating systems. The wc command, for example, is the sort of thing that is easy to write with a command line interface. It probably does not consist of more than a few lines of code, and a clever programmer could probably write it in a single line. In compiled form it takes up just a few bytes of disk space. But the code required to give the same program a graphical user interface would probably run into hundreds or even thousands of lines, depending on how fancy the programmer wanted to make it. Compiled into a runnable piece of software, it would have a large overhead of GUI code. It would be slow to launch and it would use up a lot of memory. This would simply not be worth the effort, and so "wc" would never be written as an independent program at all. Instead users would have to wait for a word count feature to appear in a commercial software package. GUIs tend to impose a large overhead on every single piece of software, even the smallest, and this overhead completely changes the programming environment. Small utility programs are no longer worth writing. Their functions, instead, tend to get swallowed up into omnibus software packages. As GUIs get more complex, and impose more and more overhead, this tendency becomes more pervasive, and the software packages grow ever more colossal; after a point they begin to merge with each other, as Microsoft Word and Excel and PowerPoint have merged into Microsoft Office: a stupendous software Wal-Mart sitting on the edge of a town filled with tiny shops that are all boarded up. It is an unfair analogy, because when a tiny shop gets boarded up it means that some small shopkeeper has lost his business. Of course nothing of the kind happens when "wc" becomes subsumed into one of Microsoft Word's countless menu items. The only real drawback is a loss of flexibility for the user, but it is a loss that most customers obviously do not notice or care about. The most serious drawback to the Wal-Mart approach is that most users only want or need a tiny fraction of what is contained in these giant software packages. The remainder is clutter, dead weight. And yet the user in the next cubicle over will have completely different opinions as to what is useful and what isn't. The other important thing to mention, here, is that Microsoft has included a genuinely cool feature in the Office package: a Basic programming package. Basic is the first computer language that I learned, back when I was using the paper tape and the teletype. By using the version of Basic that comes with Office you can write your own little utility programs that know how to interact with all of the little doohickeys, gewgaws, bells, and whistles in Office. Basic is easier to use than the languages typically employed in Unix command-line programming, and Office has reached many, many more people than the GNU tools. And so it is quite possible that this feature of Office will, in the end, spawn more hacking than GNU. But now I'm talking about application software, not operating systems. And as I've said, Microsoft's application software tends to be very good stuff. I don't use it very much, because I am nowhere near their target market. If Microsoft ever makes a software package that I use and like, then it really will be time to dump their stock, because I am a market segment of one. GEEK FATIGUE Over the years that I've been working with Linux I have filled three and a half notebooks logging my experiences. I only begin writing things down when I'm doing something complicated, like setting up X Windows or fooling around with my Internet connection, and so these notebooks contain only the record of my struggles and frustrations. When things are going well for me, I'll work along happily for many months without jotting down a single note. So these notebooks make for pretty bleak reading. Changing anything under Linux is a matter of opening up various of those little ASCII text files and changing a word here and a character there, in ways that are extremely significant to how the system operates. Many of the files that control how Linux operates are nothing more than command lines that became so long and complicated that not even Linux hackers could type them correctly. When working with something as powerful as Linux, you can easily devote a full half-hour to engineering a single command line. For example, the "find" command, which searches your file system for files that match certain criteria, is fantastically powerful and general. Its "man" is eleven pages long, and these are pithy pages; you could easily expand them into a whole book. And if that is not complicated enough in and of itself, you can always pipe the output of one Unix command to the input of another, equally complicated one. The "pon" command, which is used to fire up a PPP connection to the Internet, requires so much detailed information that it is basically impossible to launch it entirely from the command line. Instead you abstract big chunks of its input into three or four different files. You need a dialing script, which is effectively a little program telling it how to dial the phone and respond to various events; an options file, which lists up to about sixty different options on how the PPP connection is to be set up; and a secrets file, giving information about your password. Presumably there are godlike Unix hackers somewhere in the world who don't need to use these little scripts and options files as crutches, and who can simply pound out fantastically complex command lines without making typographical errors and without having to spend hours flipping through documentation. But I'm not one of them. Like almost all Linux users, I depend on having all of those details hidden away in thousands of little ASCII text files, which are in turn wedged into the recesses of the Unix filesystem. When I want to change something about the way my system works, I edit those files. I know that if I don't keep track of every little change I've made, I won't be able to get your system back in working order after I've gotten it all messed up. Keeping hand-written logs is tedious, not to mention kind of anachronistic. But it's necessary. I probably could have saved myself a lot of headaches by doing business with a company called Cygnus Support, which exists to provide assistance to users of free software. But I didn't, because I wanted to see if I could do it myself. The answer turned out to be yes, but just barely. And there are many tweaks and optimizations that I could probably make in my system that I have never gotten around to attempting, partly because I get tired of being a Morlock some days, and partly because I am afraid of fouling up a system that generally works well. Though Linux works for me and many other users, its sheer power and generality is its Achilles' heel. If you know what you are doing, you can buy a cheap PC from any computer store, throw away the Windows discs that come with it, turn it into a Linux system of mind-boggling complexity and power. You can hook it up to twelve other Linux boxes and make it into part of a parallel computer. You can configure it so that a hundred different people can be logged onto it at once over the Internet, via as many modem lines, Ethernet cards, TCP/IP sockets, and packet radio links. You can hang half a dozen different monitors off of it and play DOOM with someone in Australia while tracking communications satellites in orbit and controlling your house's lights and thermostats and streaming live video from your web-cam and surfing the Net and designing circuit boards on the other screens. But the sheer power and complexity of the system--the qualities that make it so vastly technically superior to other OSes--sometimes make it seem too formidable for routine day-to-day use. Sometimes, in other words, I just want to go to Disneyland. The ideal OS for me would be one that had a well-designed GUI that was easy to set up and use, but that included terminal windows where I could revert to the command line interface, and run GNU software, when it made sense. A few years ago, Be Inc. invented exactly that OS. It is called the BeOS. ETRE Many people in the computer business have had a difficult time grappling with Be, Incorporated, for the simple reason that nothing about it seems to make any sense whatsoever. It was launched in late 1990, which makes it roughly contemporary with Linux. From the beginning it has been devoted to creating a new operating system that is, by design, incompatible with all the others (though, as we shall see, it is compatible with Unix in some very important ways). If a definition of "celebrity" is someone who is famous for being famous, then Be is an anti-celebrity. It is famous for not being famous; it is famous for being doomed. But it has been doomed for an awfully long time. Be's mission might make more sense to hackers than to other people. In order to explain why I need to explain the concept of cruft, which, to people who write code, is nearly as abhorrent as unnecessary repetition. If you've been to San Francisco you may have seen older buildings that have undergone "seismic upgrades," which frequently means that grotesque superstructures of modern steelwork are erected around buildings made in, say, a Classical style. When new threats arrive--if we have an Ice Age, for example--additional layers of even more high-tech stuff may be constructed, in turn, around these, until the original building is like a holy relic in a cathedral--a shard of yellowed bone enshrined in half a ton of fancy protective junk. Analogous measures can be taken to keep creaky old operating systems working. It happens all the time. Ditching an worn-out old OS ought to be simplified by the fact that, unlike old buildings, OSes have no aesthetic or cultural merit that makes them intrinsically worth saving. But it doesn't work that way in practice. If you work with a computer, you have probably customized your "desktop," the environment in which you sit down to work every day, and spent a lot of money on software that works in that environment, and devoted much time to familiarizing yourself with how it all works. This takes a lot of time, and time is money. As already mentioned, the desire to have one's interactions with complex technologies simplified through the interface, and to surround yourself with virtual tchotchkes and lawn ornaments, is natural and pervasive--presumably a reaction against the complexity and formidable abstraction of the computer world. Computers give us more choices than we really want. We prefer to make those choices once, or accept the defaults handed to us by software companies, and let sleeping dogs lie. But when an OS gets changed, all the dogs jump up and start barking. The average computer user is a technological antiquarian who doesn't really like things to change. He or she is like an urban professional who has just bought a charming fixer-upper and is now moving the furniture and knicknacks around, and reorganizing the kitchen cupboards, so that everything's just right. If it is necessary for a bunch of engineers to scurry around in the basement shoring up the foundation so that it can support the new cast-iron claw-foot bathtub, and snaking new wires and pipes through the walls to supply modern appliances, why, so be it--engineers are cheap, at least when millions of OS users split the cost of their services. Likewise, computer users want to have the latest Pentium in their machines, and to be able to surf the web, without messing up all the stuff that makes them feel as if they know what the hell is going on. Sometimes this is actually possible. Adding more RAM to your system is a good example of an upgrade that is not likely to screw anything up. Alas, very few upgrades are this clean and simple. Lawrence Lessig, the whilom Special Master in the Justice Department's antitrust suit against Microsoft, complained that he had installed Internet Explorer on his computer, and in so doing, lost all of his bookmarks--his personal list of signposts that he used to navigate through the maze of the Internet. It was as if he'd bought a new set of tires for his car, and then, when pulling away from the garage, discovered that, owing to some inscrutable side-effect, every signpost and road map in the world had been destroyed. If he's like most of us, he had put a lot of work into compiling that list of bookmarks. This is only a small taste of the sort of trouble that upgrades can cause. Crappy old OSes have value in the basically negative sense that changing to new ones makes us wish we'd never been born. All of the fixing and patching that engineers must do in order to give us the benefits of new technology without forcing us to think about it, or to change our ways, produces a lot of code that, over time, turns into a giant clot of bubble gum, spackle, baling wire and duct tape surrounding every operating system. In the jargon of hackers, it is called "cruft." An operating system that has many, many layers of it is described as "crufty." Hackers hate to do things twice, but when they see something crufty, their first impulse is to rip it out, throw it away, and start anew. If Mark Twain were brought back to San Francisco today and dropped into one of these old seismically upgraded buildings, it would look just the same to him, with all the doors and windows in the same places--but if he stepped outside, he wouldn't recognize it. And--if he'd been brought back with his wits intact--he might question whether the building had been worth going to so much trouble to save. At some point, one must ask the question: is this really worth it, or should we maybe just tear it down and put up a good one? Should we throw another human wave of structural engineers at stabilizing the Leaning Tower of Pisa, or should we just let the damn thing fall over and build a tower that doesn't suck? Like an upgrade to an old building, cruft always seems like a good idea when the first layers of it go on--just routine maintenance, sound prudent management. This is especially true if (as it were) you never look into the cellar, or behind the drywall. But if you are a hacker who spends all his time looking at it from that point of view, cruft is fundamentally disgusting, and you can't avoid wanting to go after it with a crowbar. Or, better yet, simply walk out of the building--let the Leaning Tower of Pisa fall over--and go make a new one THAT DOESN'T LEAN. For a long time it was obvious to Apple, Microsoft, and their customers that the first generation of GUI operating systems was doomed, and that they would eventually need to be ditched and replaced with completely fresh ones. During the late Eighties and early Nineties, Apple launched a few abortive efforts to make fundamentally new post-Mac OSes such as Pink and Taligent. When those efforts failed they launched a new project called Copland which also failed. In 1997 they flirted with the idea of acquiring Be, but instead they acquired Next, which has an OS called NextStep that is, in effect, a variant of Unix. As these efforts went on, and on, and on, and failed and failed and failed, Apple's engineers, who were among the best in the business, kept layering on the cruft. They were gamely trying to turn the little toaster into a multi-tasking, Internet-savvy machine, and did an amazingly good job of it for a while--sort of like a movie hero running across a jungle river by hopping across crocodiles' backs. But in the real world you eventually run out of crocodiles, or step on a really smart one. Speaking of which, Microsoft tackled the same problem in a considerably more orderly way by creating a new OS called Windows NT, which is explicitly intended to be a direct competitor of Unix. NT stands for "New Technology" which might be read as an explicit rejection of cruft. And indeed, NT is reputed to be a lot less crufty than what MacOS eventually turned into; at one point the documentation needed to write code on the Mac filled something like 24 binders. Windows 95 was, and Windows 98 is, crufty because they have to be backward-compatible with older Microsoft OSes. Linux deals with the cruft problem in the same way that Eskimos supposedly dealt with senior citizens: if you insist on using old versions of Linux software, you will sooner or later find yourself drifting through the Bering Straits on a dwindling ice floe. They can get away with this because most of the software is free, so it costs nothing to download up-to-date versions, and because most Linux users are Morlocks. The great idea behind BeOS was to start from a clean sheet of paper and design an OS the right way. And that is exactly what they did. This was obviously a good idea from an aesthetic standpoint, but does not a sound business plan make. Some people I know in the GNU/Linux world are annoyed with Be for going off on this quixotic adventure when their formidable skills could have been put to work helping to promulgate Linux. Indeed, none of it makes sense until you remember that the founder of the company, Jean-Louis Gassee, is from France--a country that for many years maintained its own separate and independent version of the English monarchy at a court in St. Germaines, complete with courtiers, coronation ceremonies, a state religion and a foreign policy. Now, the same annoying yet admirable stiff-neckedness that gave us the Jacobites, the force de frappe, Airbus, and ARRET signs in Quebec, has brought us a really cool operating system. I fart in your general direction, Anglo-Saxon pig-dogs! To create an entirely new OS from scratch, just because none of the existing ones was exactly right, struck me as an act of such colossal nerve that I felt compelled to support it. I bought a BeBox as soon as I could. The BeBox was a dual-processor machine, powered by Motorola chips, made specifically to run the BeOS; it could not run any other operating system. That's why I bought it. I felt it was a way to burn my bridges. Its most distinctive feature is two columns of LEDs on the front panel that zip up and down like tachometers to convey a sense of how hard each processor is working. I thought it looked cool, and besides, I reckoned that when the company went out of business in a few months, my BeBox would be a valuable collector's item. Now it is about two years later and I am typing this on my BeBox. The LEDs (Das Blinkenlights, as they are called in the Be community) flash merrily next to my right elbow as I hit the keys. Be, Inc. is still in business, though they stopped making BeBoxes almost immediately after I bought mine. They made the sad, but probably quite wise decision that hardware was a sucker's game, and ported the BeOS to Macintoshes and Mac clones. Since these used the same sort of Motorola chips that powered the BeBox, this wasn't especially hard. Very soon afterwards, Apple strangled the Mac-clone makers and restored its hardware monopoly. So, for a while, the only new machines that could run BeOS were made by Apple. By this point Be, like Spiderman with his Spider-sense, had developed a keen sense of when they were about to get crushed like a bug. Even if they hadn't, the notion of being dependent on Apple--so frail and yet so vicious--for their continued existence should have put a fright into anyone. Now engaged in their own crocodile-hopping adventure, they ported the BeOS to Intel chips--the same chips used in Windows machines. And not a moment too soon, for when Apple came out with its new top-of-the-line hardware, based on the Motorola G3 chip, they withheld the technical data that Be's engineers would need to make the BeOS run on those machines. This would have killed Be, just like a slug between the eyes, if they hadn't made the jump to Intel. So now BeOS runs on an assortment of hardware that is almost incredibly motley: BeBoxes, aging Macs and Mac orphan-clones, and Intel machines that are intended to be used for Windows. Of course the latter type are ubiquitous and shockingly cheap nowadays, so it would appear that Be's hardware troubles are finally over. Some German hackers have even come up with a Das Blinkenlights replacement: it's a circuit board kit that you can plug into PC-compatible machines running BeOS. It gives you the zooming LED tachometers that were such a popular feature of the BeBox. My BeBox is already showing its age, as all computers do after a couple of years, and sooner or later I'll probably have to replace it with an Intel machine. Even after that, though, I will still be able to use it. Because, inevitably, someone has now ported Linux to the BeBox. At any rate, BeOS has an extremely well-thought-out GUI built on a technological framework that is solid. It is based from the ground up on modern object-oriented software principles. BeOS software consists of quasi-independent software entities called objects, which communicate by sending messages to each other. The OS itself is made up of such objects, and serves as a kind of post office or Internet that routes messages to and fro, from object to object. The OS is multi-threaded, which means that like all other modern OSes it can walk and chew gum at the same time; but it gives programmers a lot of power over spawning and terminating threads, or independent sub-processes. It is also a multi-processing OS, which means that it is inherently good at running on computers that have more than one CPU (Linux and Windows NT can also do this proficiently). For this user, a big selling point of BeOS is the built-in Terminal application, which enables you to open up windows that are equivalent to the xterm windows in Linux. In other words, the command line interface is available if you want it. And because BeOS hews to a certain standard called POSIX, it is capable of running most of the GNU software. That is to say that the vast array of command-line software developed by the GNU crowd will work in BeOS terminal windows without complaint. This includes the GNU development tools-the compiler and linker. And it includes all of the handy little utility programs. I'm writing this using a modern sort of user-friendly text editor called Pe, written by a Dutchman named Maarten Hekkelman, but when I want to find out how long it is, I jump to a terminal window and run "wc." As is suggested by the sample bug report I quoted earlier, people who work for Be, and developers who write code for BeOS, seem to be enjoying themselves more than their counterparts in other OSes. They also seem to be a more diverse lot in general. A couple of years ago I went to an auditorium at a local university to see some representatives of Be put on a dog-and-pony show. I went because I assumed that the place would be empty and echoing, and I felt that they deserved an audience of at least one. In fact, I ended up standing in an aisle, for hundreds of students had packed the place. It was like a rock concert. One of the two Be engineers on the stage was a black man, which unfortunately is a very odd thing in the high-tech world. The other made a ringing denunciation of cruft, and extolled BeOS for its cruft-free qualities, and actually came out and said that in ten or fifteen years, when BeOS had become all crufty like MacOS and Windows 95, it would be time to simply throw it away and create a new OS from scratch. I doubt that this is an official Be, Inc. policy, but it sure made a big impression on everyone in the room! During the late Eighties, the MacOS was, for a time, the OS of cool people-artists and creative-minded hackers-and BeOS seems to have the potential to attract the same crowd now. Be mailing lists are crowded with hackers with names like Vladimir and Olaf and Pierre, sending flames to each other in fractured techno-English. The only real question about BeOS is whether or not it is doomed. Of late, Be has responded to the tiresome accusation that they are doomed with the assertion that BeOS is "a media operating system" made for media content creators, and hence is not really in competition with Windows at all. This is a little bit disingenuous. To go back to the car dealership analogy, it is like the Batmobile dealer claiming that he is not really in competition with the others because his car can go three times as fast as theirs and is also capable of flying. Be has an office in Paris, and, as mentioned, the conversation on Be mailing lists has a strongly European flavor. At the same time they have made strenuous efforts to find a niche in Japan, and Hitachi has recently begun bundling BeOS with their PCs. So if I had to make wild guess I'd say that they are playing Go while Microsoft is playing chess. They are staying clear, for now, of Microsoft's overwhelmingly strong position in North America. They are trying to get themselves established around the edges of the board, as it were, in Europe and Japan, where people may be more open to alternative OSes, or at least more hostile to Microsoft, than they are in the United States. What holds Be back in this country is that the smart people are afraid to look like suckers. You run the risk of looking naive when you say "I've tried the BeOS and here's what I think of it." It seems much more sophisticated to say "Be's chances of carving out a new niche in the highly competitive OS market are close to nil." It is, in techno-speak, a problem of mindshare. And in the OS business, mindshare is more than just a PR issue; it has direct effects on the technology itself. All of the peripheral gizmos that can be hung off of a personal computer--the printers, scanners, PalmPilot interfaces, and Lego Mindstorms--require pieces of software called drivers. Likewise, video cards and (to a lesser extent) monitors need drivers. Even the different types of motherboards on the market relate to the OS in different ways, and separate code is required for each one. All of this hardware-specific code must not only written but also tested, debugged, upgraded, maintained, and supported. Because the hardware market has become so vast and complicated, what really determines an OS's fate is not how good the OS is technically, or how much it costs, but rather the availability of hardware-specific code. Linux hackers have to write that code themselves, and they have done an amazingly good job of keeping up to speed. Be, Inc. has to write all their own drivers, though as BeOS has begun gathering momentum, third-party developers have begun to contribute drivers, which are available on Be's web site. But Microsoft owns the high ground at the moment, because it doesn't have to write its own drivers. Any hardware maker bringing a new video card or peripheral device to market today knows that it will be unsalable unless it comes with the hardware-specific code that will make it work under Windows, and so each hardware maker has accepted the burden of creating and maintaining its own library of drivers. MINDSHARE The U.S. Government's assertion that Microsoft has a monopoly in the OS market might be the most patently absurd claim ever advanced by the legal mind. Linux, a technically superior operating system, is being given away for free, and BeOS is available at a nominal price. This is simply a fact, which has to be accepted whether or not you like Microsoft. Microsoft is really big and rich, and if some of the government's witnesses are to be believed, they are not nice guys. But the accusation of a monopoly simply does not make any sense. What is really going on is that Microsoft has seized, for the time being, a certain type of high ground: they dominate in the competition for mindshare, and so any hardware or software maker who wants to be taken seriously feels compelled to make a product that is compatible with their operating systems. Since Windows-compatible drivers get written by the hardware makers, Microsoft doesn't have to write them; in effect, the hardware makers are adding new components to Windows, making it a more capable OS, without charging Microsoft for the service. It is a very good position to be in. The only way to fight such an opponent is to have an army of highly competetent coders who write equivalent drivers for free, which Linux does. But possession of this psychological high ground is different from a monopoly in any normal sense of that word, because here the dominance has nothing to do with technical performance or price. The old robber-baron monopolies were monopolies because they physically controlled means of production and/or distribution. But in the software business, the means of production is hackers typing code, and the means of distribution is the Internet, and no one is claiming that Microsoft controls those. Here, instead, the dominance is inside the minds of people who buy software. Microsoft has power because people believe it does. This power is very real. It makes lots of money. Judging from recent legal proceedings in both Washingtons, it would appear that this power and this money have inspired some very peculiar executives to come out and work for Microsoft, and that Bill Gates should have administered saliva tests to some of them before issuing them Microsoft ID cards. But this is not the sort of power that fits any normal definition of the word "monopoly," and it's not amenable to a legal fix. The courts may order Microsoft to do things differently. They might even split the company up. But they can't really do anything about a mindshare monopoly, short of taking every man, woman, and child in the developed world and subjecting them to a lengthy brainwashing procedure. Mindshare dominance is, in other words, a really odd sort of beast, something that the framers of our antitrust laws couldn't possibly have imagined. It looks like one of these modern, wacky chaos-theory phenomena, a complexity thing, in which a whole lot of independent but connected entities (the world's computer users), making decisions on their own, according to a few simple rules of thumb, generate a large phenomenon (total domination of the market by one company) that cannot be made sense of through any kind of rational analysis. Such phenomena are fraught with concealed tipping-points and all a-tangle with bizarre feedback loops, and cannot be understood; people who try, end up (a) going crazy, (b) giving up, (c) forming crackpot theories, or (d) becoming high-paid chaos theory consultants. Now, there might be one or two people at Microsoft who are dense enough to believe that mindshare dominance is some kind of stable and enduring position. Maybe that even accounts for some of the weirdos they've hired in the pure-business end of the operation, the zealots who keep getting hauled into court by enraged judges. But most of them must have the wit to understand that phenomena like these are maddeningly unstable, and that there's no telling what weird, seemingly inconsequential event might cause the system to shift into a radically different configuration. To put it another way, Microsoft can be confident that Thomas Penfield Jackson will not hand down an order that the brains of everyone in the developed world are to be summarily re-programmed. But there's no way to predict when people will decide, en masse, to re-program their own brains. This might explain some of Microsoft's behavior, such as their policy of keeping eerily large reserves of cash sitting around, and the extreme anxiety that they display whenever something like Java comes along. I have never seen the inside of the building at Microsoft where the top executives hang out, but I have this fantasy that in the hallways, at regular intervals, big red alarm boxes are bolted to the wall. Each contains a large red button protected by a windowpane. A metal hammer dangles on a chain next to it. Above is a big sign reading: IN THE EVENT OF A CRASH IN MARKET SHARE, BREAK GLASS. What happens when someone shatters the glass and hits the button, I don't know, but it sure would be interesting to find out. One imagines banks collapsing all over the world as Microsoft withdraws its cash reserves, and shrink-wrapped pallet-loads of hundred-dollar bills dropping from the skies. No doubt, Microsoft has a plan. But what I would really like to know is whether, at some level, their programmers might heave a big sigh of relief if the burden of writing the One Universal Interface to Everything were suddenly lifted from their shoulders. THE RIGHT PINKY OF GOD In his book The Life of the Cosmos, which everyone should read, Lee Smolin gives the best description I've ever read of how our universe emerged from an uncannily precise balancing of different fundamental constants. The mass of the proton, the strength of gravity, the range of the weak nuclear force, and a few dozen other fundamental constants completely determine what sort of universe will emerge from a Big Bang. If these values had been even slightly different, the universe would have been a vast ocean of tepid gas or a hot knot of plasma or some other basically uninteresting thing--a dud, in other words. The only way to get a universe that's not a dud--that has stars, heavy elements, planets, and life--is to get the basic numbers just right. If there were some machine, somewhere, that could spit out universes with randomly chosen values for their fundamental constants, then for every universe like ours it would produce 10^229 duds. Though I haven't sat down and run the numbers on it, to me this seems comparable to the probability of making a Unix computer do something useful by logging into a tty and typing in command lines when you have forgotten all of the little options and keywords. Every time your right pinky slams that ENTER key, you are making another try. In some cases the operating system does nothing. In other cases it wipes out all of your files. In most cases it just gives you an error message. In other words, you get many duds. But sometimes, if you have it all just right, the computer grinds away for a while and then produces something like emacs. It actually generates complexity, which is Smolin's criterion for interestingness. Not only that, but it's beginning to look as if, once you get below a certain size--way below the level of quarks, down into the realm of string theory--the universe can't be described very well by physics as it has been practiced since the days of Newton. If you look at a small enough scale, you see processes that look almost computational in nature. I think that the message is very clear here: somewhere outside of and beyond our universe is an operating system, coded up over incalculable spans of time by some kind of hacker-demiurge. The cosmic operating system uses a command-line interface. It runs on something like a teletype, with lots of noise and heat; punched-out bits flutter down into its hopper like drifting stars. The demiurge sits at his teletype, pounding out one command line after another, specifying the values of fundamental constants of physics: universe -G 6.672e-11 -e 1.602e-19 -h 6.626e-34 -protonmass 1.673e-27.... and when he's finished typing out the command line, his right pinky hesitates above the ENTER key for an aeon or two, wondering what's going to happen; then down it comes--and the WHACK you hear is another Big Bang. Now THAT is a cool operating system, and if such a thing were actually made available on the Internet (for free, of course) every hacker in the world would download it right away and then stay up all night long messing with it, spitting out universes right and left. Most of them would be pretty dull universes but some of them would be simply amazing. Because what those hackers would be aiming for would be much more ambitious than a universe that had a few stars and galaxies in it. Any run-of-the-mill hacker would be able to do that. No, the way to gain a towering reputation on the Internet would be to get so good at tweaking your command line that your universes would spontaneously develop life. And once the way to do that became common knowledge, those hackers would move on, trying to make their universes develop the right kind of life, trying to find the one change in the Nth decimal place of some physical constant that would give us an Earth in which, say, Hitler had been accepted into art school after all, and had ended up his days as a street artist with cranky political opinions. Even if that fantasy came true, though, most users (including myself, on certain days) wouldn't want to bother learning to use all of those arcane commands, and struggling with all of the failures; a few dud universes can really clutter up your basement. After we'd spent a while pounding out command lines and hitting that ENTER key and spawning dull, failed universes, we would start to long for an OS that would go all the way to the opposite extreme: an OS that had the power to do everything--to live our life for us. In this OS, all of the possible decisions we could ever want to make would have been anticipated by clever programmers, and condensed into a series of dialog boxes. By clicking on radio buttons we could choose from among mutually exclusive choices (HETEROSEXUAL/HOMOSEXUAL). Columns of check boxes would enable us to select the things that we wanted in our life (GET MARRIED/WRITE GREAT AMERICAN NOVEL) and for more complicated options we could fill in little text boxes (NUMBER OF DAUGHTERS: NUMBER OF SONS:). Even this user interface would begin to look awfully complicated after a while, with so many choices, and so many hidden interactions between choices. It could become damn near unmanageable--the blinking twelve problem all over again. The people who brought us this operating system would have to provide templates and wizards, giving us a few default lives that we could use as starting places for designing our own. Chances are that these default lives would actually look pretty damn good to most people, good enough, anyway, that they'd be reluctant to tear them open and mess around with them for fear of making them worse. So after a few releases the software would begin to look even simpler: you would boot it up and it would present you with a dialog box with a single large button in the middle labeled: LIVE. Once you had clicked that button, your life would begin. If anything got out of whack, or failed to meet your expectations, you could complain about it to Microsoft's Customer Support Department. If you got a flack on the line, he or she would tell you that your life was actually fine, that there was not a thing wrong with it, and in any event it would be a lot better after the next upgrade was rolled out. But if you persisted, and identified yourself as Advanced, you might get through to an actual engineer. What would the engineer say, after you had explained your problem, and enumerated all of the dissatisfactions in your life? He would probably tell you that life is a very hard and complicated thing; that no interface can change that; that anyone who believes otherwise is a sucker; and that if you don't like having choices made for you, you should start making your own.
]]></description>
</item>
<item>
<title><![CDATA[&#8220;Harry Benjamin Syndrome&#8221; Syndrome]]></title>
<link>https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/</link>
<pubDate>Thu, 16 Oct 2025 22:48:49 -0300</pubDate>
<description><![CDATA[Title: “Harry Benjamin Syndrome” Syndrome

URL Source: http://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/

Published Time: 2012-04-02T13:00:22+00:00

Markdown Content:
“Harry Benjamin Syndrome” Syndrome

===============

 Top menu 

*   [About FtB](https://freethoughtblogs.com/advertise-on-freethoughtblogs/)
*   [Privacy Policy](https://freethoughtblogs.com/privacy-policy/)
*   [Tech Issues](https://freethoughtblogs.com/technical-support/)
*   [FTB Shop](https://freethoughtblogs.com/shop/)
*   [Recent Posts](https://freethoughtblogs.com/recent-posts/)

[Sincerely, Natalie Reed](https://freethoughtblogs.com/nataliereed/ "Sincerely, Natalie Reed")
==============================================================================================

Critical Thinking On Gender, Sexuality and Other Human Matters
--------------------------------------------------------------

[![Image 2](https://freethoughtblogs.com/nataliereed/wp-content/themes/ftb2-theme/images/logo.gif)](http://freethoughtblogs.com/)

[![Image 3](https://freethoughtblogs.com/nataliereed/files/2012/12/cropped-header_natalie_final_white.jpg)](https://freethoughtblogs.com/nataliereed)

 Customer service: [is run by John and Stacy](http://freethoughtblogs.com/donttouch.php)

 Sidebar Menu

 /* 
[![Image 4](https://freethoughtblogs.com/pharyngula/files/2023/12/FtBLogo.png)](https://freethoughtblogs.com/fundraising/)
--------------------------------------------------------------------------------------------------------------------------

 */ 

Freethought Blogs
-----------------

*   [A Trivial Knot](https://freethoughtblogs.com/atrivialknot/)
*   [Affinity](https://freethoughtblogs.com/affinity/)
*   [Against the Grain](https://freethoughtblogs.com/atg/)
*   [Andreas Avester](https://freethoughtblogs.com/andreasavester/)
*   [Atheism, Music, and More...](https://freethoughtblogs.com/natehevens/)
*   [Bill Seymour](https://freethoughtblogs.com/seymour/)
*   [Daylight Atheism](https://freethoughtblogs.com/daylight/)
*   [Death to Squirrels](https://freethoughtblogs.com/iris/)
*   [Fierce Roller](https://freethoughtblogs.com/fierceroller/)
*   [Freethinking Ahead](https://freethoughtblogs.com/freethinkingahead/)
*   [From the Ashes of Faith](https://freethoughtblogs.com/ashes/)
*   [Geeky Humanist](https://freethoughtblogs.com/geekyhumanist/)
*   [I Have Forgiven Jesus](https://freethoughtblogs.com/forgiven/)
*   [Impossible Me](https://freethoughtblogs.com/impossibleme/)
*   [Intransitive](https://freethoughtblogs.com/intransitive/)
*   [Jonathan's Musings](https://freethoughtblogs.com/musings/)
*   [Life's a Gas](https://freethoughtblogs.com/gas/)
*   [Mano Singham](https://freethoughtblogs.com/singham/)
*   [Marissa Explains It All](https://freethoughtblogs.com/marissa/)
*   [Nastik Deliberations](https://freethoughtblogs.com/arun/)
*   [Oceanoxia](https://freethoughtblogs.com/oceanoxia/)
*   [Pervert Justice](https://freethoughtblogs.com/pervertjustice/)
*   [Pharyngula](https://freethoughtblogs.com/pharyngula/)
*   [Primate Chess](https://freethoughtblogs.com/primatechess/)
*   [Pro-Science](https://freethoughtblogs.com/kriswager/)
*   [Recursivity](https://freethoughtblogs.com/recursivity/)
*   [Reprobate Spreadsheet](https://freethoughtblogs.com/reprobate/)
*   [Stderr](https://freethoughtblogs.com/stderr/)
*   [Taslima Nasreen](https://freethoughtblogs.com/taslima/)
*   [The Bolingbrook Babbler](https://freethoughtblogs.com/babbler/)
*   [The Digital Cuttlefish](https://freethoughtblogs.com/cuttlefish/)
*   [YEMMYnisting](https://freethoughtblogs.com/yemmynisting/)

#### Recent Posts on FtB

[[Last 50 Recent Posts]](https://freethoughtblogs.com/recent-posts/)

*   ### [Fingertips](https://freethoughtblogs.com/gas/2025/10/16/fingertips/)

[Life's a Gas](https://freethoughtblogs.com/gas) - Published by [Bébé Mélange](https://freethoughtblogs.com/gas/author/great1american1satan) 
*   ### [Consciousness, measurement, and quantum mechanics - Part 3](https://freethoughtblogs.com/singham/2025/10/16/consciousness-measurement-and-quantum-mechanics-part-3/)

[Mano Singham](https://freethoughtblogs.com/singham) - Published by [Mano Singham](https://freethoughtblogs.com/singham/author/singham) 
*   ### [The problem with trying to make sense of a bad sci-fi movie](https://freethoughtblogs.com/pharyngula/2025/10/16/the-problem-with-trying-to-make-sense-of-a-bad-sci-fi-movie/)

[Pharyngula](https://freethoughtblogs.com/pharyngula) - Published by [PZ Myers](https://freethoughtblogs.com/pharyngula/author/pharyngula) 
*   ### [New on OnlySky: A cure for Huntington's disease?](https://freethoughtblogs.com/daylight/2025/10/15/new-on-onlysky-huntingtons-disease/)

[Daylight Atheism](https://freethoughtblogs.com/daylight) - Published by [Adam Lee](https://freethoughtblogs.com/daylight/author/ebonmuse) 
*   ### [Common gallinule](https://freethoughtblogs.com/fierceroller/?p=6867)

[Fierce Roller](https://freethoughtblogs.com/fierceroller) - Published by [Matthew Herron](https://freethoughtblogs.com/fierceroller/author/matthewherron) 
*   ### [For the Flat Earthers Out There:](https://freethoughtblogs.com/stderr/2025/10/14/for-the-flat-earthers-out-there/)

[Stderr](https://freethoughtblogs.com/stderr) - Published by [Marcus Ranum](https://freethoughtblogs.com/stderr/author/mjranum) 
*   ### [ICE clashes with Chicagoland weredogs over the weekend (Fiction)](https://freethoughtblogs.com/babbler/2025/10/13/ice-clashes-with-chicagoland-weredogs-over-the-weekend-fiction/)

[The Bolingbrook Babbler](https://freethoughtblogs.com/babbler) - Published by [William Brinkman](https://freethoughtblogs.com/babbler/author/williambrinkman) 
*   ### [Deconversion Narrativization](https://freethoughtblogs.com/atrivialknot/2025/10/13/deconversion-narrativization/)

[A Trivial Knot](https://freethoughtblogs.com/atrivialknot) - Published by [Siggy](https://freethoughtblogs.com/atrivialknot/author/atrivialknot) 

*   [Register](https://freethoughtblogs.com/nataliereed/wp-login.php?action=register)
*   [Log in](http://freethoughtblogs.com/wp-login.php?redirect_to=https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/)

*   [Recent Posts](http://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#activity-recent-posts)
*   [Recent Comments](http://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#activity-recent-comments)
*   [Archives](http://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#activity-archives)

*   [Trans 101](https://freethoughtblogs.com/nataliereed/2013/03/19/trans-101/ "Trans 101")
*   [Acknowledgments, Thanks Yous, and Goodbyes](https://freethoughtblogs.com/nataliereed/2013/03/17/acknowledgments-thanks-yous-and-goodbyes/ "Acknowledgments, Thanks Yous, and Goodbyes")
*   [How Do I Know If I'm Trans?](https://freethoughtblogs.com/nataliereed/2013/03/17/how-do-i-know-if-im-trans/ "How Do I Know If I'm Trans?")
*   [My Traumatic Life Story](https://freethoughtblogs.com/nataliereed/2013/03/12/my-traumatic-life-story/ "My Traumatic Life Story")
*   [Homophobia, White-Supremacism and "Disco Sucks!"](https://freethoughtblogs.com/nataliereed/2013/03/12/homophobia-white-supremacism-and-disco-sucks/ "Homophobia, White-Supremacism and \"Disco Sucks!\"")
*   [Privileges and Decoys: Part One](https://freethoughtblogs.com/nataliereed/2013/03/11/privileges-and-decoys-part-one/ "Privileges and Decoys: Part One")
*   [Born This Way (Reprise): The New Essentialism](https://freethoughtblogs.com/nataliereed/2013/03/09/born-this-way-reprise-the-new-essentialism/ "Born This Way (Reprise): The New Essentialism")
*   [Discourse And Intersectionality](https://freethoughtblogs.com/nataliereed/2013/01/19/discourse-and-intersectionality/ "Discourse And Intersectionality")
*   ["Ideal Bodies"](https://freethoughtblogs.com/nataliereed/2013/01/17/ideal-bodies/ "\"Ideal Bodies\"")
*   [Complicity Vs. Cause In Trans-Misogyny And Violence](https://freethoughtblogs.com/nataliereed/2012/12/13/complicity-vs-cause-in-trans-misogyny-and-violence/ "Complicity Vs. Cause In Trans-Misogyny And Violence")

*    brianpansky on [Trans 101](https://freethoughtblogs.com/nataliereed/2013/03/19/trans-101/#comment-106678)
*    skeptifem on [Trans 101](https://freethoughtblogs.com/nataliereed/2013/03/19/trans-101/#comment-98504)
*    tremault on [How Do I Know If I’m Trans?](https://freethoughtblogs.com/nataliereed/2013/03/17/how-do-i-know-if-im-trans/#comment-96816)
*    Missy Dee on [Trans 101](https://freethoughtblogs.com/nataliereed/2013/03/19/trans-101/#comment-96624)
*    3basethriller on […F@#king Trans Women…](https://freethoughtblogs.com/nataliereed/2012/05/30/fking-trans-women/#comment-96462)
*    ‘How do I know I’m trans?’ : Link to a thought provoking article. Well worth reading. | Kate's Gender Dysphoria Blog on [How Do I Know If I’m Trans?](https://freethoughtblogs.com/nataliereed/2013/03/17/how-do-i-know-if-im-trans/#comment-96320)
*    LIsa K. on [“I Always Knew”](https://freethoughtblogs.com/nataliereed/2012/09/03/i-always-knew/#comment-96274)
*    FinlyErkenwald on [Born This Way (Reprise): The New Essentialism](https://freethoughtblogs.com/nataliereed/2013/03/09/born-this-way-reprise-the-new-essentialism/#comment-96195)
*    Swati on [Acknowledgments, Thanks Yous, and Goodbyes](https://freethoughtblogs.com/nataliereed/2013/03/17/acknowledgments-thanks-yous-and-goodbyes/#comment-95775)
*    Natalie Reed on [Free Thoughts #1: Superheroes And Disability](https://freethoughtblogs.com/nataliereed/2012/06/08/free-thoughts-1-superheroes-and-disability/#comment-94428)

*   [March 2013](https://freethoughtblogs.com/nataliereed/2013/03/)
*   [January 2013](https://freethoughtblogs.com/nataliereed/2013/01/)
*   [December 2012](https://freethoughtblogs.com/nataliereed/2012/12/)
*   [November 2012](https://freethoughtblogs.com/nataliereed/2012/11/)
*   [October 2012](https://freethoughtblogs.com/nataliereed/2012/10/)
*   [September 2012](https://freethoughtblogs.com/nataliereed/2012/09/)
*   [August 2012](https://freethoughtblogs.com/nataliereed/2012/08/)
*   [July 2012](https://freethoughtblogs.com/nataliereed/2012/07/)
*   [June 2012](https://freethoughtblogs.com/nataliereed/2012/06/)
*   [May 2012](https://freethoughtblogs.com/nataliereed/2012/05/)
*   [April 2012](https://freethoughtblogs.com/nataliereed/2012/04/)
*   [March 2012](https://freethoughtblogs.com/nataliereed/2012/03/)
*   [February 2012](https://freethoughtblogs.com/nataliereed/2012/02/)
*   [January 2012](https://freethoughtblogs.com/nataliereed/2012/01/)

EVENTS
------

[Lovebombing The Vulnerable](https://freethoughtblogs.com/nataliereed/2012/04/02/lovebombing-the-vulnerable/) »« [Debunking The COGIATI](https://freethoughtblogs.com/nataliereed/2012/03/30/debunking-the-cogiati/)

“Harry Benjamin Syndrome” Syndrome
==================================

* * *

You know, I’m sick of all this “umbrella term” nonsense. Why should I be associated with a bunch of freaks like drag queens, “butch trans dykes” and non-op transgenders? I’m a _real_ transsexual, a _real_ woman. I fought hard in order to be able to be accepted as a woman, and having a bunch of people who aren’t even interested in getting surgery, or wearing skirts, or doing guys, going ahead and jumping into our “community” and making us look bad is just undoing all of what us _real_ transsexuals, who are _really_ women, fought to attain. I’m sorry, but male means penis and female means vagina. You just need to accept that. It’s common sense. Yes, there are women like me who are born trapped in men’s bodies, who get surgery to have vaginas and therefore become women, but you can’t just say “I’m a woman” and have your “self-identification” magically make your penis no longer a penis. It’s crazy and ridiculous, and you make us women who were simply born with a physical defect and sought to have it corrected look crazy and ridiculous too. I don’t care what you transgenderists want to do with your weird perverted fetishes and such, but don’t go dragging us _real women_ who are _really_ transsexual down with you. I’m femme, androphilic, binary-identified and transsexual, so I count, and you don’t. I have Harry Benjamin Syndrome.

April Fool’s! That’s today, right?

No? I missed it?

Shucks.

Anyway, yeah, this is the kind of thing one actually does, sadly, come across in the trans community _way_ more often than is (personally) comfortable. For all we’ve been through, trans people are not necessarily above falling into the same binary or hierarchical attitudes about gender common to our culture, nor does finding oneself on the receiving end of cissexism necessarily cause someone to immediately divest themselves of all the cisnormative ideas that have been drilled into them over the course of their lives. Deciding to transition doesn’t magically or instantly cause someone to let go of things like gender binarism, genital essentialism, misogyny, transphobia, the confusion of gender expression and role with gender identity, heteronormativity and heterosexism, the idea of sexuality and gender having a deterministic relationship to one another, the idea that gender and sex have a deterministic relationship to one another, or the one million and one ways that any given concept, object, characteristic or behaviour is gendered one way or the other.

[![Image 5: boromirmeme](https://freethoughtblogs.com/nataliereed/files/2012/04/boromirmeme-e1333344883230.jpg)](https://freethoughtblogs.com/nataliereed/files/2012/04/boromirmeme.jpg)

And as a friend of mine once put it, “most people are only exactly as tolerant as is required to accept _themselves_.”

Not everyone has the strength and confidence to assert for themselves the validity of their identity in a culture that is overtly hostile to it. So when you have certain models or structures within that culture that offer some semblance of conditional external validation (no matter how absurdly high that bar has been set), people _are_ going to build their sense of worth upon how close they get to meeting those conditions.

And the conditions themselves, the structures, the cissexism itself will often be internalized in accordance with the usual “system justification” things… the ways that people will have a sort of psychological predisposition towards wanting to believe that the status quo is just and decent, that things are okay the way they are. It’s difficult, psychologically, to perceive the system one is living in as unfair and flawed, and immensely difficult to believe that, whether good or bad, one’s position in life is undeserved. It’s only when the status quo is compromising other psychological needs like the importance of self-worth that it starts becoming “easier” to oppose the system than rationalize justifications for it, and in this instance, as said, the system is often providing us a means of finding a semblance of conditional self-worth without having to question its framework.

Given all these factors… how hard it is to immediately ditch a lifetime’s worth of cultural gender-baggage, how difficult it is for anyone to learn to extend their sense of tolerance and acceptance beyond themselves and their immediate circle, how immensely hostile our culture is to trans identities, system justification, and how validation is held as a perpetual carrot on a stick leading us to conform to social expectations of gender, be invisible, be non-threatening, and make as little of a fuss as possible… there will of course be trans people who’ll seek their validation through the cis-supremacist systems that invalidated them in the first place, building up their gender’s worth and “realness” in contrast to those of other not-so-“real” trans people, who “make them look bad”.

It becomes an especially tempting possibility for trans women who are “passable”, femme, androphilic, post-op, who transitioned early, who fit the imposed and expected narrative, and who were able to more or less effortlessly work through the gatekeeping system. When that system assures you your gender is valid, that contrasts you as one of the “good” ones, that supports you and provides you care, while most of the culture is attacking your identity, would you have the confidence, compassion and self-determination to question the gatekeeping system? Even if accepting it means throwing those trans people who don’t fit the narrative under the bus?

One of the most insidious aspects of gatekeeping is the way that it demands we play along. We have to smile and nod and jump through all the hoops and not dare openly question the process from within lest we risk having our application (for hormones or surgery) declined. Which is a risk that I wouldn’t blame anyone for being unwilling to take, even if it means we have to play along with a process we vehemently oppose. We have to dress up as “gendered” as we can, and make ourselves sound totally, completely certain in a binary identification, play up everything about ourselves that fits the cultural role of the identified sex and play down absolutely everything that doesn’t, or that might be non-binary or “off”. And like any process where you have to behave as though you believe in its validity, some people inevitably start actually believing in its validity. Especially given everything I mentioned above. Especially especially when the system is rewarding you. It’s hard to be critical of the letter-grade system when you’re getting straight As, much like it’s hard to question your religion when you’re naturally disposed towards the behaviours it describes as righteous.

So we end up with trans people who the system says are “the good ones” believing that they’re the good ones. We have trans people basing the idea that they’re “real” women or “real” men on a contrast to lesbians or non-ops or tomboys or late transitioners or genderqueers, and whose sense of worth becomes dependent on maintaining the cissexist hierarchies that granted them their privileged station. They become the capos and Quislings of the trans community, passing on information to the guards of the gender prison in exchange for an extra cookie on their lunch tray.

The name that has gradually come to be associated with this aspect of the trans community is “Harry Benjamin Syndrome”. The idea here is that these “real transsexuals” are suffering from a particular unique medical condition, the titular HBS (named for one of the pioneering medical practitioners in the field of transgender care). The idea is that HBS is a sort of intersex condition in which the brain is more or less literally the one sex while the body is the other, and that HRT and SRS are the appropriate medical treatments for the physical “birth defect” of having been born with the inappropriately sexed body. Implicit in this is the idea that non-binary gender identities, or the dysphoria experienced by non-ops, or late transitioners, or gay trans people, or whatever, is merely psychological in nature, or at least of a profoundly different etiology, and that it’s damaging to associate these transgender people or “pseudo-transsexuals” with the “true transsexual” suffering from HBS. The idea of these other identities being “lesser”, or simply divorced from their own, is often reinforced by leaning on various cis sexologist’s (usually highly dubious) theories of transgenderism, such as autogynephilia.

So long as we’re making up silly medical conditions to account for minor variations in a socio-cultural category (derived from a loose cluster of related etiologies of gender), how about “Harry Benjamin Syndrome Syndrome”, a psychosocial disorder born from a dependence on external validation of one’s variant gender identity and marked by the denigration of alternately variant identities as inferior to one’s own, therefore artificially inflating the sense of one’s own identity as meaningful within the current assumptions of the culture? Sound good?

I think it’s not necessarily a problematic thing to interrogate the various more or less pronounced differences that occur across distinct types of gender variance, and I think it often is important to not blur the distinctions or confuse particular types of transgenderism with others. I, for instance, become livid when uninformed cis folk make the mistake of thinking drag queen, transvestite, cross-dresser and transsexual are all the same thing, or simply different points on a spectrum. And I find that I don’t really have anything meaningful in common with drag queens or cross-dressers. I’ve often been asked advice from the latter and found myself at a loss for anything substantive to say, and I’ve repeatedly been infuriated by the former’s insistence on often speaking for the transsexual community in the media on matters that pertain to us but not them, such as the relative offensiveness of the word “tranny” or the Libra tampon ad. It’s important, in advancing our understanding of gender, to be able to discuss these distinctions, nuances and subtleties, to think about what they mean, and to disseminate that discourse beyond the boundaries of our own community and into how our culture as a whole understands and interprets gender.

But, where the problem with HBS lies is not simply marking distinctions but in creating hierarchies from them, and suggesting that political coalitions are a bad idea on the basis that the “upper” strata of the hierarchy will only be hindered in their push for acceptance (_in accordance with **externally imposed** standards)_ by cooperation with the “lower” strata. What makes it especially creepy is that we see this happening on other levels of the queer community, too. The _exact same argument_ is brought forth by LGB people as a reason to drop the T from the acronym, to not bother fighting for trans rights, reaching out to trans people, accommodating trans needs, discussing how trans people are impacted by any given issue, or using trans rights as nothing more than a bargaining chip in politics free to be discarded as a “compromise” to attain greater rights for LGBs, etc.

Concepts such as “The Transgender Community” or “LGBT”/”The Queer Community” are not meant to be overarching ideas of who and what we are. It isn’t meant to blur distinctions. The Transgender Umbrella doesn’t mean we don’t acknowledge that cross-dresser is different from transsexual is different from drag queen is different from genderqueer, no more than using “Queer” is to imagine that gay men and trans women are the same thing. These are _political coalitions._

You see, _we_ may understand those nuances and differences. We know the difference between intersex and genderqueer, cross-dressing and drag, trans man and butch lesbian… but the haters _don’t._ They don’t really care. They see a big icky rabble of icky queers and they want us gone, no matter how _exactly_ we differ from their heteronormative, cisnormative expectations.

Such political coalitions are useful and meaningful not on the basis of shared identity or shared etiology of identity, but on the basis of shared _oppression._ Queer, loosely speaking, means “differs from cultural expectations of gender and/or sexuality”. It’s useful to band together and cooperate on that basis because differing from such cultural expectations results in a similar form of oppression (the sexually-based oppression in fact often operating as a subset of gender-based oppression- It isn’t taboo to suck cock, it’s taboo for a _man_ to suck cock). Transgender, similarly, means only to significantly differ from cultural expectations of gender expression, gender identity, or (arguably) physical sex. We cooperate because we all, “HBS” and non-op alike, are oppressed on that basis.

These kinds of internecine divisions, hoping to somehow move forward in cultural acceptance by ridding yourselves of the unseemly lower classes of whatever, do absolutely nothing for progress. What they do is reinforce the scaffolding on which the oppression was based (for instance, the idea that certain kinds of gender are more valid or “real” than others). Whatever extra cookie you may get on your tray when lunch is served in the prison, you’re still stuck in that prison, still _dependent on the guards_, and will remain so until we cooperate effectively and build a tunnel. We won’t be free until we are no longer dependent on someone or something else, like a contrived medical diagnosis, to say our gender is real and valid and worth asserting. We won’t be free until all of us have the ability to provide our _own_ validation. Until we stop asking “am I a woman?” and start shouting “I _am_ a woman!”

Which is why our movement needs to place that as our priority. Self-definition. Self-validation.

Then there won’t be any need to weigh your identity against any other. No need for sacrifice when you’ve gotten rid of the god you sought to appease.

[Lovebombing The Vulnerable](https://freethoughtblogs.com/nataliereed/2012/04/02/lovebombing-the-vulnerable/) »« [Debunking The COGIATI](https://freethoughtblogs.com/nataliereed/2012/03/30/debunking-the-cogiati/)

*   [Natalie Reed](https://freethoughtblogs.com/nataliereed/author/nataliereed/)
*   April 2, 2012
*   [Trans*](https://freethoughtblogs.com/nataliereed/category/trans/)
*   [Log in to comment](http://freethoughtblogs.com/wp-login.php?redirect_to=https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/)

### Comments

1.   ![Image 6](https://secure.gravatar.com/avatar/1eddf911dccd1c3d741eca5e2a9a16c4?s=48&d=mm&r=g)embertine says

[April 2, 2012 at 9:08 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18003)

_“most people are only exactly as tolerant as is required to accept themselves”_

QFMFT. Your friend is extremely wise. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18003#respond) 
2.   ![Image 7](https://secure.gravatar.com/avatar/3daceea89f07238de1c1c5f7e7528efd?s=48&d=mm&r=g)William Burns says

[April 2, 2012 at 9:37 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18008)

It was a day late, but at least it wasn’t another “Some FTB blogger is leaving FTB for some wacky religion-related reason” post. Those got kind of monotonous. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18008#respond) 
3.   ![Image 8](https://secure.gravatar.com/avatar/6fd8b887fa6e8b8e84f41ab2f03ba123?s=48&d=mm&r=g)A. Person says

[April 2, 2012 at 9:44 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18009)

Well, you got me. I thought I somehow ended up at ‘Just Jennifer’. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18009#respond) 
4.   ![Image 9](https://secure.gravatar.com/avatar/e6ff6a822b85d3c90983fda770c1e40d?s=48&d=mm&r=g)[Christianne](https://krelllabs.blogspot.com/)says

[April 2, 2012 at 10:24 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18014)

Having been the object of scorn for some of the HBS people, I’m totally down with this. I sometimes have to remind myself that for all their misguided notions about sex and gender, they’re in the same boat as I am regarding the broader culture. Doesn’t make it any easier to put up with them, though.

I have to say, though, that while I was reading your first paragraph, all I could hear in my head was Chico Marx saying “You canna fool me. There ain’t no Sanity Clause.” [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18014#respond) 
5.   ![Image 10](https://secure.gravatar.com/avatar/ed68163e60b30ba369ee73da6c3691ea?s=48&d=mm&r=g)Sinéad says

[April 2, 2012 at 11:07 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18019)

I love ya Natalie!

The HBSers and Transsexual Separatists really make me as depressed as just about any transmisogynistic trope out there. I don’t think I can count how many have ruined my feeling safe to attend Trans support groups, or online.

I understand wanting to validate one’s identity with something physical because the “mental” is considered “ill”. I have never had my chromosomes checked, and no doubt many if not almost all of these people have never either. It is wrong to co-opt intersex identity. Yes, sometimes I feel like it would help me understand why I am the way I am, but ultimately it is as inconsequential as being a reincarnated female in a male body.

I have been hearing the intersex community discuss how the terms CAMAB and CAFAB are appropriating the surgical coercion orpf sex assignment. I am not educated in that area to make a claim for or against. However, I do believe there is a difference between being considered a “male” in utero or at birth upon seeing a functional penis and being “diagnosed” with ambiguous genitalia, the subsequent surgical decisions, the likelihood of being sterile, and the stigmas I don’t even know about. Even males with micropenis and hypospadias, are going to have different experiences that are not related to gender identity.

I do wonder why my brain and body at odds with one another, but even if there were not, my gender performance should not be stigmatized and pathologized as a paraphilia. I still support the varieties of trans expressions, I don’t think drag queens can speak for transgender/transsexual people who live their lives in hiding or in public. I do believe that all of us have a right to live and be happy and feel safe.

And one final thought, I am a fairly hard femme gynephile, and no gentalia doesn’t define my attraction. I would have the surgery if it were financially feasible, but I am not going to live my life with utter hatred of that part of me, either. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18019#respond) 
6.   ![Image 11](https://secure.gravatar.com/avatar/02233f3791538f73ba775b5ff1dfe42e?s=48&d=mm&r=g)Sebor says

[April 2, 2012 at 11:21 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18021)

While most of the phenomena you talked about are very far removed from my experience, I could not agree more with the need for self-validation.

 Begging for acceptance on any level (queer, trans* or however narrow you choose to define your allegiance) only reinforces the notion that someone (straight cis men?) has the right to decide about your rights. Which they don’t.

On a less serious note, “Harry Benjamin Syndrome Syndrome” doesn’t sound very sciency, how about “Narcissistic gender identity disorder”? The symptoms of a Narcissistic personality disorder only limited to the gender identity part of personality seem to fit disturbingly well. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18021#respond) 
    *   ![Image 12](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 3, 2012 at 4:37 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18284)

Gender Validation Dependency syndrome? [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18284#respond) 
    *   ![Image 13](https://secure.gravatar.com/avatar/043189bc47b6c9eea3110c6bbde58522?s=48&d=mm&r=g)valeriekeefe says

[April 5, 2012 at 2:29 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18948)

Nah, leaving it as Harry Benjamin Syndrome Syndrome is great because it allows those who suffer from RAS* Syndrome to out themselves when they claim their extra cookie.

*Redundant Acronym Syndrome [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18948#respond) 

7.   ![Image 14](https://secure.gravatar.com/avatar/fa095178db73c01edb7effc85123c478?s=48&d=mm&r=g)thaismcrc says

[April 2, 2012 at 11:26 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18023)

In case anyone’s interested and hasn’t read it yet, there’s a really good series on system justification at the Crommunist’s blog: [http://freethoughtblogs.com/crommunist/2011/10/20/why-are-you-hitting-yourself-an-intro-to-system-justification-theory/](https://freethoughtblogs.com/crommunist/2011/10/20/why-are-you-hitting-yourself-an-intro-to-system-justification-theory/)

Great post and this part is just perfect:”Such political coalitions are useful and meaningful not on the basis of shared identity or shared etiology of identity, but on the basis of shared oppression. Queer, loosely speaking, means “differs from cultural expectations of gender and/or sexuality”.” [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18023#respond) 
8.   ![Image 15](https://secure.gravatar.com/avatar/7ef3fe6f3882adcaeff40866d42f3f55?s=48&d=mm&r=g)[hall-of-rage](http://hall-of-rage.dreamwidth.org/)says

[April 2, 2012 at 11:40 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18027)

This is really an excellent piece. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18027#respond) 
9.   ![Image 16](https://secure.gravatar.com/avatar/b713581005a0a03e3004a9e9d9c1857f?s=48&d=mm&r=g)Sas says

[April 2, 2012 at 12:33 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18032)

A common tactic I’ve seen lately is HBSers blaming trans activists and non-ops for the violence against trans people. It’s not poor violent transphobes’ fault that they beat us, it’s that some of us are just so _uppity_ they have no choice. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18032#respond) 
    *   ![Image 17](https://secure.gravatar.com/avatar/211777d523ca3874deb200c2591cbc4a?s=48&d=mm&r=g)Erin W says

[April 2, 2012 at 1:16 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18046)

Ouch. The usual bollocks from the HBSers is bad enough. Abuse-enabling bollocks is just a step too far. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18046#respond) 
    *   ![Image 18](https://secure.gravatar.com/avatar/b00c887a6961e32111be51cd68fde9ce?s=48&d=mm&r=g)[WilloNyx](http://idioprag.com/)says

[April 3, 2012 at 10:04 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18567)

Got to love victim blaming from other victims. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18567#respond) 

10.   ![Image 19](https://secure.gravatar.com/avatar/f70839b93c71dd14171c6700a0243737?s=48&d=mm&r=g)[Melody](http://fawm.org/fawmers/psyt/)says

[April 2, 2012 at 12:36 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18033)

The first paragraph – the one written in jest – is a real attitude that shows up way too frequently in trans-spaces I’m familiar with. It always makes me hesitate in sharing my own narrative. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18033#respond) 
11.   ![Image 20](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 12:49 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18038)

I suppose it must be very tempting to fit in, and to forget those who don’t. And since those on whom you depend for security _must_ be above criticism (because they can kick you out), the fault always lies with those who rock the boat. It’s not up to me to criticize them on a moral basis – I’m much too far removed from the conflict to be able to do that – but it reminds me of Franklin’s maxim “Those who would give up Essential Liberty to purchase a little Temporary Safety, deserve neither Liberty nor Safety.”

Maybe it’s more sad than anything else. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18038#respond) 
    *   ![Image 21](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 1:08 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18042)

So, I discovered a button that would allow me to reset my password. There’s one slight problem – I need to log in using my password to access it. *headdesk*

Can trans people crosdress? I suppose that whenever a trans woman presents as a man it’s crossdressing, and vice versa for trans men. Although crossdressing has to me a tone of doing it for fun, not to survive. And I don’t even know what would count as crossdressing for a genderqueer. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18042#respond) 
        *   ![Image 22](http://graph.facebook.com/100002450271843/picture?type=normal)[Natalie Reed](http://www.freethoughtblogs.com/nataliereed)says

[April 2, 2012 at 1:12 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18044)

Many cross-dressers _definitely_ do it “to survive”, to meet a deep and unchanging emotional need. “For fun” is generally more how one would describe drag. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18044#respond) 
            *   ![Image 23](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 1:14 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18045)

I guess I wasn’t up to specs on my definitions. Hmm… irritating.

I meant what was done for show, so that would be drag I guess? [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18045#respond) 
                *   ![Image 24](https://secure.gravatar.com/avatar/deb7fb58780a570c4b8700ef7f967d10?s=48&d=mm&r=g)Dalillama says

[April 2, 2012 at 1:35 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18053)

To answer that one, yes, trans people can and do perform in drag. I know several trans* drag kings and drag queens. 
                *   ![Image 25](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 1:37 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18055)

Thank you. I wonder if it’s a way of ridiculing their pre-trans existence, make it less threatening? 
                *   ![Image 26](http://graph.facebook.com/100002450271843/picture?type=normal)[Natalie Reed](http://www.freethoughtblogs.com/nataliereed)says

[April 2, 2012 at 1:50 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18061)

Yes, if it’s for show / performance, that’s definitely drag, not CD. 

            *   ![Image 27](https://secure.gravatar.com/avatar/324509be21e997cabfbedd3f89d2b8d4?s=48&d=mm&r=g)Not My Usual Name says

[April 3, 2012 at 7:57 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18302)

Just throwing myself out as someone who crossdresses “for fun” but it’s really a private thing for me so I don’t really think of it as drag. It’s only really an emotional need for me in the sense that since I’ve grown up I feel I need to be honest with myself about what I enjoy doing.

I’m only me of course. Everybody would have a different story. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18302#respond) 

        *   ![Image 28](https://secure.gravatar.com/avatar/211777d523ca3874deb200c2591cbc4a?s=48&d=mm&r=g)Erin W says

[April 2, 2012 at 1:49 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18060)

The Philly Drag Kings have a lot of trans* and genderqueer performers. The thing with drag is, it’s not necessarily about dressing as the ‘opposite’ gender, it’s the exaggeration of gendered stereotypes that makes the performance. So the genderqueer ‘kings’ I know just perform whatever characters they find most interesting, sometimes going very femme or very butch, and sometimes just mixing it all up. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18060#respond) 

12.   ![Image 29](https://secure.gravatar.com/avatar/deb7fb58780a570c4b8700ef7f967d10?s=48&d=mm&r=g)Dalillama says

[April 2, 2012 at 1:29 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18050)

Very good piece, and a window into aspects of trans* issues that I haven’t really explored. Also, you provided a very concise explanation in re: what drag queens particularly are doing under the transgender umbrella, which had always rather confused me; like you, I’ve seen virtually no commonalities between drag queens and trans* people, aside from the trans* people I know who also do drag, of course. That said, I think that the ‘it’s not our commonality, it’s the common hatred from the outside that binds us’ effect that’s why drag queens will talk about reclaiming ‘tranny’: in popular culture, the term is often used interchangeably to refer to drag queens, trans women and male transvestites. I’m not going to make any judgments regarding legitimacy, but I suspect that is why drag queens often consider themselves to be legitimate reclaimers of the word. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18050#respond) 
13.   ![Image 30](https://secure.gravatar.com/avatar/d7e7174749aeeae93eb74236f75a48cc?s=48&d=mm&r=g)[miller](https://skepticsplay.blogspot.com/)says

[April 2, 2012 at 1:29 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18051)

I always found HBS really fascinating, because I felt it exemplified something that privileged people tend not to see. That is, marginalization of a group tends to precipitate a lot of internal conflict as a secondary effect. But I also feel a little awkward about my fascination, because I’m looking at it from an outside (cis) perspective, as a case study, when it’s a real and serious thing for trans people. I don’t suppose there’s really anything I can do about HBSers, is there? [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18051#respond) 
    *   ![Image 31](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 1:39 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18056)

Good question. If their strategy is to fit into the gender binary I suppose any threat to that is a threat to them. And encouraging them to deviate from the script and not punish them when they do…?

Something like that? [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18056#respond) 
        *   ![Image 32](https://secure.gravatar.com/avatar/d7e7174749aeeae93eb74236f75a48cc?s=48&d=mm&r=g)[miller](https://skepticsplay.blogspot.com/)says

[April 2, 2012 at 2:08 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18064)

I’m not sure that is a good idea. People can conform to the gender binary if they want. More to the point, I don’t know any HBSers, or even any “classic transsexuals”. I’m not even sure that it is something I should be doing anything about, besides educating myself, and supporting trans people in general. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18064#respond) 
            *   ![Image 33](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 2, 2012 at 2:14 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18067)

Ok, you may be right. And simply not punishing them for straying from the bigender script is something we shouldn’t do to anyone anyway. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18067#respond) 
                *   ![Image 34](https://secure.gravatar.com/avatar/d186cb31a38c2fc068b038e15314b5e7?s=48&d=mm&r=g)[Brin Convenient](http://www.bigender.net/)says

[April 10, 2012 at 5:41 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20567)

Anders, I’d like to ask if you meant “binary” instead of “bigender?” Bigender is yet one more distinct label beneath the Transgender umbrella, referring to individuals who identify as two (or more, in some cases) distinct genders. Some of us, myself included, present with two different gendered presentations as a way of expressing that gender. Note that the genders comprising the bigender person’s identity need not be binary. You can see more at my youtube channel (brinconvenient). 
                *   ![Image 35](http://graph.facebook.com/100002450271843/picture?type=normal)[Natalie Reed](http://www.freethoughtblogs.com/nataliereed)says

[April 10, 2012 at 6:16 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20574)

Wouldn’t identify as more than two genders be, like, “poly-gender” rather than “bi-gender”? 
                *   ![Image 36](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 10, 2012 at 5:59 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20570)

Yep.

It’s like learning an entirely new language… 🙂 Thanks for correcting me. 
                *   ![Image 37](https://secure.gravatar.com/avatar/d186cb31a38c2fc068b038e15314b5e7?s=48&d=mm&r=g)[Brin Convenient](http://www.bigender.net/)says

[April 10, 2012 at 10:56 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20627)

Yes, it would be, although, on bigender.net we’ve tended to say “multi-gender” … I suppose we prefer Latin to Greek prefixes. 😉

It seems rarer even than bigender, but, to be honest, I include it to be inclusive. We multigender folks need to stick together. 😉 
                *   ![Image 38](https://secure.gravatar.com/avatar/48282220f812b143e72cb6dd167a0499?s=48&d=mm&r=g)[Ace of Sevens](http://aceofsevens.wordpress.com/)says

[April 11, 2012 at 12:23 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20640)

Bigender parses ambiguously. 
                *   ![Image 39](https://secure.gravatar.com/avatar/d186cb31a38c2fc068b038e15314b5e7?s=48&d=mm&r=g)[Brin Convenient](http://www.bigender.net/)says

[April 11, 2012 at 12:28 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20773)

Ace of Sevens, how so? bi + gender = 2 genders.

If it’s due to potential confusion with bisexual (conjecture, not intended as straw man), well, that word actually parses ambiguously, too. It’s only through social convention that we take it to mean sexually attracted to both (sic) sexes. It could mean having two sexes (and is, in fact, used in this sense by McCoy in the “Trouble with Tribbles” episode of Star Trek). 
                *   ![Image 40](https://secure.gravatar.com/avatar/48282220f812b143e72cb6dd167a0499?s=48&d=mm&r=g)[Ace of Sevens](http://aceofsevens.wordpress.com/)says

[April 11, 2012 at 12:29 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20776)

I mean without the hyphen, it could also be parsed as “big ender” 
                *   ![Image 41](https://secure.gravatar.com/avatar/d186cb31a38c2fc068b038e15314b5e7?s=48&d=mm&r=g)[Brin Convenient](http://www.bigender.net/)says

[April 11, 2012 at 12:38 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-20777)

Oh, of course! I’ve seen it both hyphenated and non and that point has been made a time or two as well. In fact, when I was originally looking to purchase a domain to host a bigender resource site, I found that bigender.com was owned by a company then calling itself “Big Ender Clothing,” and I had to settle for bigender.net and bigender.org. They’ve since changed their company’s brand to BE4, but they still own the domain.

Also, I refer to the site as “BigEnder.net” to my host when speaking since it’s just easier to let them draw their own conclusions than have to explain what bigender is any time there’s an outage or change needs to be made. 

14.   ![Image 42](https://secure.gravatar.com/avatar/9fb115c7e581842b00ae0681882849f4?s=48&d=mm&r=g)Chirico says

[April 2, 2012 at 2:09 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18065)

You know, from the opening paragraph I expected this to be about the cotton ceiling/radfems. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18065#respond) 
15.   ![Image 43](https://secure.gravatar.com/avatar/48282220f812b143e72cb6dd167a0499?s=48&d=mm&r=g)[Ace of Sevens](http://aceofsevens.wordpress.com/)says

[April 2, 2012 at 2:39 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18073)

Most systemic oppression works by enlisting the help of the oppressed group by giving them privileges. See also narcs, overseers, etc. You also will have people trying to kick out anyone with insufficient purity. See: radfems, bi erasure. Sometimes these overlap, as with HBS. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18073#respond) 
16.   ![Image 44](https://secure.gravatar.com/avatar/19e7d631f4b375010445b9ba1dae1426?s=48&d=mm&r=g)Kate S says

[April 2, 2012 at 6:13 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18135)

“Concepts such as “The Transgender Community” or “LGBT”/”The Queer Community” are not meant to be overarching ideas of who and what we are. It isn’t meant to blur distinctions. The Transgender Umbrella doesn’t mean we don’t acknowledge that cross-dresser is different from transsexual is different from drag queen is different from genderqueer, no more than using “Queer” is to imagine that gay men and trans women are the same thing. These are political coalitions.”

Yes yes yes yes yes!

 Also, Libra tampon ad? [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18135#respond) 
    *   ![Image 45](https://secure.gravatar.com/avatar/64d3f4383309e377953a7eacd02a52b2?s=48&d=mm&r=g)Cara says

[April 2, 2012 at 9:55 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18196)

[http://jezebel.com/5872531/tampon-ad-called-transphobic-for-claiming-real-women-menstruate](https://jezebel.com/5872531/tampon-ad-called-transphobic-for-claiming-real-women-menstruate)

This. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18196#respond) 

17.   ![Image 46](https://secure.gravatar.com/avatar/4a3bd3a0f8d8c38412d82ae2787b525e?s=48&d=mm&r=g)[scazon](https://twitter.com/scazon)says

[April 2, 2012 at 10:55 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18218)

Hell. Yes.

 Thank you. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18218#respond) 
18.   ![Image 47](https://secure.gravatar.com/avatar/82a472825d33d210c652492ccff3e1af?s=48&d=mm&r=g)Anders says

[April 3, 2012 at 5:56 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18291)

Someone should stage “The Merchant in Venice” with a trans man as Shylock and a HBS woman as his daughter. Could be an interesting production. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18291#respond) 
19.   ![Image 48](https://secure.gravatar.com/avatar/b00c887a6961e32111be51cd68fde9ce?s=48&d=mm&r=g)[WilloNyx](http://idioprag.com/)says

[April 3, 2012 at 10:20 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18570)

I am so behind on my reading. It will take me forever to catch up.

Short comment, I think of this like what I call the “Welcome to the Dollhouse” phenomenon. Everyone looking for the pond scum they consider to be beneath them and then acting like the bullies they themselves wish to escape.

In my brutally honest opinion, it is difficult not to berate people sometimes. There are tropes your mind has been conditioned into partially believing just so you can survive this world. However, “good people” imo are the ones who never stop trying to tear down those false walls our brain has built to make us comfortable with reality. “Good people” hunt them out take a sledge happier to them and open new pathways to inclusiveness in the end.

Not saying I am a “good person” only that I am trying to be one. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18570#respond) 
20.   ![Image 49](https://secure.gravatar.com/avatar/c6ae64e38245c2ccb4831b6b62fdcbab?s=48&d=mm&r=g)Rasmus says

[April 4, 2012 at 1:13 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-18770)

So I guess these people are analogous to people of color who say things like _“I’m not a [N-word], I’m a responsible educated intelligent person who happens to have been born with a different skin color than you. I dislike the loser [N-word] idiots as much as you do!”_.

Like a bullied kid who bullies another bullied kid in the hope of putting one more body between him and the bottom of the schoolyard pecking order.

This sort of behavior is sad and pathetic, but I think we have to understand it as a social survival strategy. As a relatively privileged person I can’t really hold it against them… Although I wouldn’t want to be friends with a person who embraces that strategy and who doesn’t stop when called out on it. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=18770#respond) 
21.   ![Image 50](https://secure.gravatar.com/avatar/17a5c4599c4470cf636c76a736a7c2ad?s=48&d=mm&r=g)daiyuhurst says

[April 5, 2012 at 4:33 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-19078)

Great article! [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=19078#respond) 
22.   ![Image 51](https://secure.gravatar.com/avatar/403f60e7f2f2dd6f1a5a644c75ef2806?s=48&d=mm&r=g)Penny Posh says

[December 31, 2012 at 2:41 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-77475)

Late to the party here, but wanted to say thanks for a really well-written and thought-provoking piece. Although I have little to no experience in much of the trans community, I think what you’ve said here definitely applies in broader strokes to many other “alternative” or “non-normative” communities out there. (I use those terms loosely and with the greatest respect.)

I think that it just goes to show: no matter what part of the heap you got thrown into, there is always someone farther towards the top and someone farther towards the bottom. The solution is not to look up and aspire to be on top of the heap; nor is it to look down and sneer because at least you’re not at the bottom. The solution is to climb out of the damn heap and stand on your own two feet… and then maybe find a compassionate and accepting way to help others get out of the heap, too.

Anyhoo, thanks for the writing – I’m a fan. 🙂 [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=77475#respond) 
23.   ![Image 52](https://secure.gravatar.com/avatar/5922105c215d4418d3bb0e2d5527006f?s=48&d=mm&r=g)Jaycey Cleland says

[February 20, 2013 at 2:27 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-84772)

No trans* person would want to keep their assigned genitals. Surgery is a must!

Well I’m a trans* person, they don’t bother me THAT much…

Well you aren’t a TRUE trans person.

Oh wait, I meant Scotsman 🙂

Thanks for the read. Shared on my facebook and Tumblr. I’ve read your work before, it’s wonderful 🙂 [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=84772#respond) 
24.   ![Image 53](https://secure.gravatar.com/avatar/7e2a69932e297f30d9d5b43542ffbddb?s=48&d=mm&r=g)Lisa K.says

[July 25, 2013 at 5:43 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-96181)

Hmm I have never heard of this HBS(S) before…you wrote an interesting and thought-provoking article.

I mostly understand that perspective though, having personally been an early transitioner (starting as a teenager). I was born with various feminine physical attributes that my biological brothers don’t have (5’5″, small hands and feet, big hips, “gynecomastia”, “micropenis”, late puberty). My brothers have big torsos, are at least a foot taller than me, and have relatively large hands and feet.

So on the occasions when this stuff pops up (generally some medical thing where they’re asking a lot of menstruation-related questions), I generally identify myself as intersexed. This is not to put myself on a pedestal, but rather because I feel like it describes my particular situation better. I’ve never actually been tested for intersexed conditions because I don’t feel like my identity needs to be medically validated. I also never really felt attached to transgender or transsexual, because my identity is female, not trans*.

When I transitioned in the mid-late 90’s, I found it really hard to relate with the trans* community. I found it very hard to connect with people who had half a clue what I was going through. Most of the information I got was online…but the internet was still a novelty at the time. There wasn’t a Jazz or Kim Petras out there telling their stories to big media outlets. All the people I met locally were at least 15 years older and most of them had been married or looked/acted completely masculine, so there was a huge disconnect.

I guess what really turned me off the most from the trans community were my interactions with this crazy narcissist, Donna Rose, who appeared to only be transitioning for attention and seemed to really relish in this idea of assuming a transsexual identity and trying to be some kind of trans* celebrity. She really rubbed me the wrong way and I didn’t want to be associated with the type of community she was representing.

So yeah I can totally understand the perspective of someone identifying as HBS(S) to distance their particular situation from the situation of some of the creepier members of the trans* community.

But on the flip side I really understand and agree with a lot of what you said. I especially don’t understand why hetero cis men are given liberties to pathologize the issues of gender-variant women (or men, GQ’s), any more than they are given liberties to legislates women’s reproductive rights.

I’m also bisexual, which I feel also gets stigmatized quite a bit. And I’m poly-curious. And I tend to be in interracial relationships. So I get annoyed with things the LGBT community does, like turning the rainbow flag into an LGBT icon instead of a humanist icon celebrating all different kinds of diversity including racial and religious diversity.

So perhaps for me the phrase “most people are only exactly as tolerant as is required to accept themselves” was true to an extent, at least when I was in transition and for the first couple years when I was more or less assimilated into the cisgender binary system….but I found myself becoming more uncomfortable with the heteronormativity that I was getting sucked into. But overcoming religious dogma, having a friend of mine come out as FTM, watching all the re-enactment videos of the prop 8 trial, dealing with racial issues, etc, has really changed my perspective on things, so I feel a lot more inclusive of others.

So while I don’t feel like I need to throw myself under some umbrella label, I do agree that we need to band together to bring about more change and try to end discrimination wherever possible. I get frustrated when LG throws the B and/or T under the bus. When the oppressed become the oppressors.

I wish we wouldn’t judge each other so much. I really do understand how messed up various caste systems are, but having personally experienced life from many different angles (even from an economical standpoint) it’s hard for me to really judge people too harshly for finding a comfortable conformity and distancing themselves from communities and ideas and past experiences that are stressful to them.

Progress takes time, but at least society seems to be moving in a better direction. [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=96181#respond) 

### Trackbacks

1.   **[Loving my own narrative « Planting Rainbows](http://plantingrainbows.wordpress.com/2012/06/11/loving-my-own-narrative/)**says: [June 11, 2012 at 12:48 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-37290) […] Not from an external gatekeeper who told me I must behave in a certain way, not really from any HBSer who poisons trans women by telling us not to transition if you have any doubts, not from any source […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=37290#respond) 
2.   **[An interesting MRA argument « Jadehawk's Blog](http://jadehawks.wordpress.com/2012/08/25/an-interesting-mra-argument/)**says: [August 25, 2012 at 1:14 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-52917) […] on how closely someone manages to conform to cisnormative and heteronormative rules is called the Harry Benjamin Syndrome. And exactly the same happens to gender-roles. Because men are higher in the hierarchy, masculine […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=52917#respond) 
3.   **[Trans-On-Trans Oppression Is Still A Cis Problem | Sincerely, Natalie Reed](https://freethoughtblogs.com/nataliereed/2012/10/27/trans-on-trans-oppression-is-still-a-cis-problem/)**says: [October 27, 2012 at 8:51 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-64098) […] oppressive, kyrarchal behaviour by trans people, such as those who rally under the banner of “Harry Benjamin Syndrome“. Nor to say anything of the actual acts of violence committed towards trans women at the […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=64098#respond) 
4.   **[Certain Propositions Concerning Callout Culture, Part Two – Ozy Frantz's Blog](http://ozyfrantz.com/2012/12/30/certain-propositions-concerning-callout-culture-part-two/)**says: [December 30, 2012 at 12:34 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-77329) […] who do oppressive things are privileged.See also:Michelle Malkin. Trans women who believe in Harry Benjamin Syndrome. Misogynistic women from Phyllis Schalfly to Suzanne Venker. “Ex-gays.” Et cetera, […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=77329#respond) 
5.   **[Question Eight: Why are people trans, and what does it really mean? | a gentleman and a scholar](http://cnlester.wordpress.com/2013/04/01/question-eight-why-are-people-trans-and-what-does-it-really-mean/)**says: [April 1, 2013 at 3:27 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-89634) […] between people with different opinions, and different ways of living their lives – from the HBSers who don’t want to be associated with the awful genderqueers, to militant non-interventionists who […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=89634#respond) 
6.   **[Pomosexuals and the “Classic Trans Story” | TransFinite](http://transfinite.me/2013/05/20/pomosexuals-and-the-classic-trans-story/)**says: [June 3, 2013 at 3:08 am](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-94380) […] [UPDATE: It seems that many trans people refer to what I call "The Classic Trans Story" as "Harry Benjamin Syndrome"] […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=94380#respond) 
7.   **[The New Trans Separatism is the same old White Supremacy | fakecisgirl](http://fakecisgirl.wordpress.com/2013/07/25/the-new-trans-separatism-is-the-same-old-white-supremacy/)**says: [July 24, 2013 at 9:48 pm](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#comment-96168) […] divisions come hand in hand with this New Separatism, and the end result becomes much like the old-school HBSer separatism: you end up with a bunch of white people of a specific set of experiences, almost all of whom are […] [Reply](https://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/?replytocom=96168#respond) 

### Leave a Reply [Cancel reply](http://freethoughtblogs.com/nataliereed/2012/04/02/harry-benjamin-syndrome-syndrome/#respond)

Connect with

[![Image 54: Google+](https://freethoughtblogs.com/nataliereed/wp-content/plugins/social-connect/media/img/google_plus_32.png)](javascript:void(0); "Google+")[![Image 55: Google](https://freethoughtblogs.com/nataliereed/wp-content/plugins/social-connect/media/img/google_32.png)](javascript:void(0); "Google")[![Image 56: Yahoo](https://freethoughtblogs.com/nataliereed/wp-content/plugins/social-connect/media/img/yahoo_32.png)](javascript:void(0); "Yahoo")[![Image 57: WordPress.com](https://freethoughtblogs.com/nataliereed/wp-content/plugins/social-connect/media/img/wordpress_32.png)](javascript:void(0); "WordPress.com")

Enter your WordPress.com blog URL

http://.wordpress.com

[Proceed](javascript:void(0);)

Your email address will not be published. Required fields are marked *

Comment

Name *

Email *

Website

- [x] Notify me of follow-up comments by email.

- [x] Notify me of new posts by email.

- [x]  Notify me of followup comments via e-mail. You can also [subscribe](https://freethoughtblogs.com/nataliereed/comment-subscriptions?srp=952&srk=054391e58698b1ac19f612dfb7c7dfb5&sra=s&srsrc=f) without commenting.

© 2014 - FreethoughtBlogs.com
]]></description>
</item>
<item>
<title><![CDATA[Reality has a surprising amount of detail]]></title>
<link>http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail</link>
<pubDate>Sat, 18 Oct 2025 05:55:58 -0300</pubDate>
<description><![CDATA[Title: Reality has a surprising amount of detail

URL Source: http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail

Markdown Content:
I.
--

My dad emigrated from Colombia to North America when he was 18 looking looking for a better life. For my brother and I that meant a lot of standing outside in the cold. My dad’s preferred method of improving his lot was improving lots, and my brother and I were “voluntarily” recruited to help working on the buildings we owned.

That’s how I came to spend a substantial part of my teenage years replacing fences, digging trenches, and building flooring and sheds. And if there’s one thing I’ve learned from all this building, it’s that reality has a surprising amount of detail.

This turns out to explain why its so easy for people to end up intellectually stuck. Even when they’re literally the best in the world in their field.

Consider building some basement stairs for a moment. Stairs seem pretty simple at first, and at a high level they are simple, just two long, wide parallel boards (2” x 12” x 16’), some boards for the stairs and an angle bracket on each side to hold up each stair. But as you actually start building you’ll find there’s a surprising amount of nuance.

The first thing you’ll notice is that there are actually quite a few subtasks. Even at a high level, you have to cut both ends of the 2x12s at the correct angles; then screw in some u-brackets to the main floor to hold the stairs in place; then screw in the 2x12s into the u-brackets; then attach the angle brackets for the stairs; then screw in the stairs.

Those goddamn stairs.![Image 1: Those goddamn stairs.](http://johnsalvatier.org/assets/stairs-diagram.jpg)

Next you’ll notice that each of those steps above decomposes into several steps, some of which have some tricky details to them due to the properties of the materials and task and the limitations of yourself and your tools.

The first problem you’ll encounter is that cutting your 2x12s to the right angle is a bit complicated because there’s no obvious way to trace the correct angles. You can either get creative (there _is_ a way to trace it), or you can bust out your trig book and figure out how to calculate the angle and position of the cuts.

You’ll probably also want to look up what are reasonable angles for stairs. What looks reasonable when you’re cutting and what feels safe can be different. Also, you’re probably going to want to attach a guide for your circular saw when cutting the angle on the 2x12s because the cut has to be pretty straight.

When you’re ready to you will quickly find that getting the stair boards at all the same angle is non-trivial. You’re going to need something that can give you an angle to the main board very consistently. Once you have that, and you’ve drawn your lines, you may be dismayed to discover that your straight looking board is not _that_ straight. Lumber warps after it’s made because it was cut when it was new and wet and now it’s dryer, so no lumber is perfectly straight.

Once you’ve gone back to the lumber store and gotten some straighter 2x12s and redrawn your lines, you can start screwing in your brackets. Now you’ll learn that despite _starting_ aligned with the lines you drew, after screwing them in, your angle brackets are no longer quite straight because the screws didn’t go in quite straight and now they tightly secure the bracket at the wrong angle. You can fix that by drilling guide holes first. Also you’ll have to move them an inch or so because it’s more or less impossible to get a screw to go in differently than it did the first time in the same hole.

Now you’re finally ready to screw in the stair boards. If your screws are longer than 2”, you’ll need different ones, otherwise they will poke out the top of the board and stab you in the foot.

At every step and every level there’s an abundance of detail with material consequences.

It’s tempting to think ‘So what?’ and dismiss these details as incidental or specific to stair carpentry. And they **are** specific to stair carpentry; that’s what makes them details. But the existence of a surprising number of meaningful details is _not_ specific to stairs. Surprising detail is a near universal property of getting up close and personal with reality.

You can see this everywhere if you look. For example, you’ve probably had the experience of doing something for the first time, maybe growing vegetables or using a Haskell package for the first time, and being frustrated by how many annoying snags there were. Then you got more practice and then you told yourself ‘man, it was so simple all along, I don’t know why I had so much trouble’. We run into a fundamental property of the universe and mistake it for a personal failing.

If you’re a programmer, you might think that the fiddliness of programming is a special feature of programming, but really it’s that everything is fiddly, but you only notice the fiddliness when you’re new, and in programming you do new things more often.

You might think the fiddly detailiness of things is limited to human centric domains, and that physics itself is simple and elegant. That’s true in some sense – the physical laws themselves tend to be quite simple – but the manifestation of those laws is often complex and counterintuitive.

II. Boiling A Watched Pot
-------------------------

Consider the boiling of water. That’s straightforward, water boils at 100 °C, right?

Well the stairs seemed simple too, so let’s double check.

Put yourself in the shoes of someone at the start of the 1800’s, with only a crude, unmarked mercury thermometer, trying to figure the physics of temperature.

Go to your stove, put some water in a pot, start heating some water, and pay attention as it heats.

_(I suggest actually doing this)_

The first thing you’ll probably notice is a lot of small bubbles gathering on the surface of the pot. Is that boiling? The water’s not that hot yet; you can still even stick your finger in. Then the bubbles will appear faster and start rising, but they somehow seem ‘unboiling’. Then you’ll start to see little bubble storms in patches, and you start to hear a hissing noise. Is that Boiling? Sort of? It doesn’t really _look_ like boiling. The bubble storms grow larger and start releasing bigger bubbles. Eventually the bubbles get big and the surface of the water grows turbulent as the bubbles begin to make it to the surface. Finally we seem to have reached real boiling. I guess this is the boiling point? That seems kind of weird, what were the things that happened earlier if not boiling.

To make matters worse, if you’d used a glass pot instead of a metal one, the water would boil at a higher temperature. If you cleaned the glass vessel with sulfuric acid, to remove any residue, you’d find that you can heat water substantially more before it boils and when it does boil it boils in little explosions of boiling and the temperature fluctuates unstably.

Worse still, if you trap a drop of water between two other liquids and heat it, you can raise the temperature to at least 300 °C with nothing happening. That kind of makes a mockery of the statement ‘water boils at 100 °C’.

It turns out that ‘boiling’ is a lot more complicated than you thought.

This surprising amount of detail is is not limited to “human” or “complicated” domains, it is a near universal property of everything from space travel to sewing, to your internal experience of your own mind.

III. Invisible vs. Transparent Detail And Getting Intellectually Stuck
----------------------------------------------------------------------

Again, you might think ‘So what? I guess things are complicated but I can just notice the details as I run into them; no need to think specifically about this’. And if you are doing things that are relatively simple, things that humanity has been doing for a long time, this is often true. But if you’re trying to do difficult things, things which are not known to be possible, it is not true.

The more difficult your mission, the more details there will be that are critical to understand for success.

You might hope that these surprising details are irrelevant to your mission, but not so. Some of them will end up being key. Wood’s tendency to warp means it’s more accurate to trace a cut than to calculate its length and angle. The possibility of superheating liquids means it’s important to use a [packed bed](https://en.wikipedia.org/wiki/Packed_bed) when boiling liquids in industrial processes lest your process be highly inefficient and unpredictable. The massive difference in weight between a rocket _full_ of fuel and an empty one means that a reusable rocket can’t hover if it can’t throttle down to a very small fraction of its original thrust, which in turn means it must plan its trajectory very precisely to achieve 0 velocity at exactly the moment it reaches the ground.

Some important details for colonizing the universe.![Image 2: Some important details for colonizing the universe.](http://johnsalvatier.org/assets/colonizing-the-universe.png)

You might also hope that the important details will be obvious when you run into them, but not so. Such details aren’t _automatically_ visible, even when you’re directly running up against them. Things can just seem messy and noisy instead. ‘Spirit’ thermometers, made using brandy and other liquors, were in common use in the early days of thermometry. They were even considered as a potential standard fluid for thermometers. It wasn’t until the careful work of Swiss physicist Jean-André De Luc in the 18th century that physicists realized that alcohol thermometers are highly nonlinear and highly variable depending on concentration, which is in turn hard to measure.

You’ve probably also had experiences where you were trying to do something and growing increasingly frustrated because it wasn’t working, and then finally, after some time you realize that your solution method can’t possibly work.

Another way to see that noticing the right details is hard, is that different people end up noticing _different_ details. My brother and I once built a set of stairs for the garage with my dad, and we ran into the problem of determining where to cut the long boards so they lie at the correct angle. After struggling with the problem for a while (and I do mean struggling, a 16’ long board is heavy), we got to arguing. I remembered from trig that we could figure out angle so I wanted to go dig up my textbook and think about it. My dad said, ‘no, no, no, let’s just trace it’, insisting that we could figure out how to do it.

I kept arguing because I thought I was right. I felt really annoyed with him and he was annoyed with me. In retrospect, I think I saw the fundamental difficulty in what we were doing and I don’t think he appreciated it (look at the stairs picture and see if you can figure it out), he just heard ‘let’s draw some diagrams and compute the angle’ and didn’t think that was the solution, and if he had appreciated the thing that I saw I think he would have been more open to drawing some diagrams. But at the same time, he also understood that diagrams and math don’t account for the shape of the wood, which I did not appreciate. If we had been able to get these points across, we could have come to consensus. Drawing a diagram was probably a good idea, but computing the angle was probably not. Instead we stayed annoyed at each other for the next 3 hours.

Before you’ve noticed important details they are, of course, basically invisible. It’s hard to put your attention on them because you don’t even know what you’re looking for. But _after_ you see them they quickly become so integrated into your intuitive models of the world that they become essentially transparent. Do you remember the insights that were crucial in learning to ride a bike or drive? How about the details and insights you have that led you to be good at the things you’re good at?

This means it’s really easy to get _stuck_. Stuck in your current way of seeing and thinking about things. Frames are made out of the details that seem important to you. The important details you haven’t noticed are invisible to you, and the details you _have_ noticed seem completely obvious and you see right through them. This all makes makes it difficult to imagine how you could be missing something important.

That’s why if you ask an anti-climate change person (or a climate scientist) “what could convince you you were wrong?” you’ll likely get back an answer like “if it turned out all the data on my side was faked” or some other extremely strong requirement for evidence rather than “I would start doubting if I noticed numerous important mistakes in the details my side’s data and my colleagues didn’t want to talk about it”. The second case is much more likely than the first, but you’ll never see it if you’re not paying close attention.

If you’re trying to do impossible things, this effect should _chill you to your bones_. It means you could be intellectually stuck right at this very moment, with the evidence right in front of your face and you just can’t see it.

This problem is not easy to fix, but it’s not impossible either. I’ve mostly fixed it for myself. The direction for improvement is clear: seek detail you would not normally notice about the world. When you go for a walk, notice the unexpected detail in a flower or what the seams in the road imply about how the road was built. When you talk to someone who is smart but just seems _so wrong_, figure out what details seem important to them and why. In your work, notice how that meeting actually wouldn’t have accomplished much if Sarah hadn’t pointed out that one thing. As you learn, notice which details actually change how you think.

If you wish to not get stuck, seek to perceive what you have not yet perceived.

[Comments](http://lesswrong.com/r/discussion/lw/p0a/reality_has_a_surprising_amount_of_detail/)
]]></description>
</item>
<item>
<title><![CDATA[The Matrix as Metaphysics]]></title>
<link>https://consc.net/papers/matrix.html</link>
<pubDate>Mon, 20 Oct 2025 05:14:28 -0300</pubDate>
<description><![CDATA[Title: The Matrix as Metaphysics

URL Source: http://consc.net/papers/matrix.html

Markdown Content:
### [David J. Chalmers](https://consc.net/)

*[[This paper was originally written for the philosophy section of the official _The Matrix_ website (2003) and was subsequently published in (Christopher Grau, ed.) _Philosophers Explore the Matrix_ (Oxford University Press, 2005). The bulk of the paper is written to be accessible for an audience without a background in philosophy. At the same time, this paper is intended as a serious work of philosophy, with relevance for central issues in epistemology, metaphysics, and the philosophy of mind and language. A section of "philosophical notes" at the end of the article draws out some of these connections explicitly.]]

### 1 Brains in Vats

_The Matrix_ presents a version of an old philosophical fable: the brain in a vat. A disembodied brain is floating in a vat, inside a scientist's laboratory. The scientist has arranged that the brain will be stimulated with the same sort of inputs that a normal embodied brain receives. To do this, the brain is connected to a giant computer simulation of a world. The simulation determines which inputs the brain receives. When the brain produces outputs, these are fed back into the simulation. The internal state of the brain is just like that of a normal brain, despite the fact that it lacks a body. From the brain's point of view, things seem very much as they seem to you and me.

![Image 1](https://consc.net/pics/@@/matrix1.jpg)
The brain is massively deluded, it seems. It has all sorts of false beliefs about the world. It believes that it has a body, but it has no body. It believes that it is walking outside in the sunlight, but in fact it is inside a dark lab. It believes it is one place, when in fact it may be somewhere quite different. Perhaps it thinks it is in Tucson, when it is actually in Australia, or even in outer space.

Neo's situation at the beginning of _The Matrix_ is something like this. He thinks that he lives in a city, he thinks that he has hair, he thinks it is 1999, and he thinks that it is sunny outside. In reality, he is floating in space, he has no hair, the year is around 2199, and the world has been darkened by war. There are a few small differences from the vat scenario above: Neo's brain is located in a body, and the computer simulation is controlled by machines rather than by a scientist. But the essential details are much the same. In effect, Neo is a brain in a vat.

Let's say that a _matrix_ (lower-case "m") is an artificially-designed computer simulation of a world. So the Matrix in the movie is one example of a matrix. And let's say that someone is _envatted_, or that they are _in a matrix_, if they have a cognitive system which receives its inputs from and sends its outputs to a matrix. Then the brain at the beginning is envatted, and so is Neo.

We can imagine that a matrix simulates the entire physics of a world, keeping track of every last particle throughout space and time. (Later, we will look at ways in which this set-up might be varied.) An envatted being will be associated with a particular simulated body. A connection is arranged so that whenever this body receives sensory inputs inside the simulation, the envatted cognitive system will receive sensory inputs of the same sort. When the envatted cognitive system produces motor outputs, corresponding outputs will be fed to the motor organs of the simulated body.

When the possibility of a matrix is raised, a question immediately follows. How do I know that I am not in a matrix? After all, there could be a brain in a vat structured exactly like my brain, hooked up to a matrix, with experiences indistinguishable from those I am having now. From the inside, there is no way to tell for sure that I am not in the situation of the brain in a vat. So it seems that there is no way to know for sure that I am not in a matrix.

Let us call the hypothesis that I am in a matrix and have always been in a matrix the _Matrix Hypothesis_. Equivalently, the Matrix Hypothesis says that I am envatted and have always been envatted. This is not quite equivalent to the hypothesis that I am in the Matrix, as the Matrix is just one specific version of a matrix. For now, I will ignore the some complications that are specific to the Matrix in the movie, such as the fact that people sometimes travel back and forth between the Matrix and the external world. These issues aside, we can think of the Matrix Hypothesis informally as saying that I am in the same sort of situation as people who have always been in the Matrix.

The Matrix Hypothesis is one that we should take seriously. As Nick Bostrom has suggested, it is not out of the question that in the history of the universe, technology will evolve that will allow beings to create computer simulations of entire worlds. There may well be vast numbers of such computer simulations, compared to just one real world. If so, there may well be many more beings who are in a matrix than beings who are not. Given all this, one might even infer that it is more likely that we are in a matrix than that we are not. Whether this is right or not, it certainly seems that we cannot be _certain_ that we are not in a matrix.

Serious consequences seem to follow. My envatted counterpart seems to be massively deluded. It thinks it is in Tucson; it thinks it is sitting at a desk writing an article; it thinks it has a body. But on the face of it, all of these beliefs are false. Likewise, it seems that if _I_ am envatted, my own corresponding beliefs are false. If I am envatted, I am not really in Tucson, I am not really sitting at a desk, and I may not even have a body. So if I don't know that I am not envatted, then I don't know that I am in Tucson, I don't know that I am sitting at a desk, and I don't know that I have a body.

The Matrix Hypothesis threatens to undercut almost everything I know. It seems to be a _skeptical hypothesis_: a hypothesis that I cannot rule out, and one that would falsify most of my beliefs if it were true. Where there is a skeptical hypothesis, it looks like none of these beliefs count as genuine knowledge. Of course the beliefs _might_ be true — I might be lucky, and not be envatted — but I can't rule out the possibility that they are false. So a skeptical hypothesis leads to _skepticism_ about these beliefs: I believe these things, but I do not know them.

To sum up the reasoning: I don't know that I'm not in a matrix. If I'm in a matrix, I'm probably not in Tucson. So if I don't know that I'm not in a matrix, then I don't know that I'm in Tucson. The same goes for almost everything else I think I know about the external world.

### 2 Envatment Reconsidered

This is a standard way of thinking about the vat scenario. It seems that this view is also endorsed by the people who created _The Matrix_. On the DVD case for the movie, one sees the following:

> **Perception**: Our day-in, day-out world is real. 
> **Reality**: That world is a hoax, an elaborate deception spun by all-powerful machines that control us. Whoa.

I think this view is not quite right. I think that even if I am in a matrix, my world is perfectly real. A brain in a vat is not massively deluded (at least if it has always been in the vat). Neo does not have massively false beliefs about the external world. Instead, envatted beings have largely _correct_ beliefs about their world. If so, the Matrix Hypothesis is not a skeptical hypothesis, and its possibility does not undercut everything that I think I know.

Philosophers have held this sort of view before. The 18th-century philosopher George Berkeley held, in effect, that appearance is reality. (Recall Morpheus: "What is real? How do you define real? If you're talking about what you can feel, what you can smell, what you can taste and see, then real is simply electrical signals interpreted by your brain.") If this is right, then the world perceived by envatted beings is perfectly real: they have all the right appearances, and appearance is reality. So on this view, even envatted beings have true beliefs about the world.

I have recently found myself embracing a similar conclusion, though for quite different reasons. I don't find the view that appearance is reality plausible, so I don't endorse Berkeley's reasoning. And until recently, it has seemed quite obvious to me that brains in vats would have massively false beliefs. But I now think there is a line of reasoning that shows that this is wrong.

I still think I cannot rule out the hypothesis that I am in a matrix. But I think that even I am in a matrix, I am still in Tucson, I am still sitting at my desk, and so on. So the hypothesis that I am in a matrix is not a skeptical hypothesis. The same goes for Neo. At the beginning of the film, if he thinks "I have hair", he is correct. If he thinks "It is sunny outside", he is correct. And the same goes, of course, for the original brain in a vat. When it thinks "I have a body", it is correct. When it thinks "I am walking", it is correct.

This view may seem very counterintuitive at first. Initially, it seemed quite counterintuitive to me. So I'll now present the line of reasoning that has convinced me that it is correct.

### 3 The Metaphysical Hypothesis

I will argue that the hypothesis that I am envatted is not a skeptical hypothesis, but a _metaphysical hypothesis_. That is, it is a hypothesis about the underlying nature of reality.

Where physics is concerned with the microscopic processes that underlie macroscopic reality, metaphysics is concerned with the fundamental nature of reality. A metaphysical hypothesis might make a claim about the reality that underlies physics itself. Alternatively, it might say something about the nature of our minds, or the creation of our world.

I think the Matrix Hypothesis should be regarded as a metaphysical hypothesis with all three of these elements. It makes a claim about the reality underlying physics, about the nature of our minds, and about the creation of the world.

In particular, I think the Matrix Hypothesis is equivalent to a version of the following three-part Metaphysical Hypothesis. First, physical processes are fundamentally computational. Second, our cognitive systems are separate from physical processes, but interact with these processes. Third, physical reality was created by beings outside physical space-time.

Importantly, nothing about this Metaphysical Hypothesis is skeptical. The Metaphysical Hypothesis here tells us about the processes underlying our ordinary reality, but it does not entail that this reality does not exist. We still have bodies, and there are still chairs and tables: it's just that their fundamental nature is a bit different from what we may have thought. In this manner, the Metaphysical Hypothesis is analogous to a physical hypotheses, such as one involving quantum mechanics. Both the physical hypothesis and the Metaphysical Hypothesis tells us about the processes underlying chairs. They do not entail that there are no chairs. Rather, they tell us what chairs are really like.

I will make the case by introducing each of the three parts of the Metaphysical Hypothesis separately. I will suggest that each of them is coherent, and cannot be conclusively ruled out. And I will suggest that none of them is a skeptical hypothesis: even if they are true, most of our ordinary beliefs are still correct. The same goes for a combination of all three hypothesis. I will then argue that the Matrix Hypothesis hypothesis is equivalent to this combination.

#### (1) The Computational Hypothesis

The Computational Hypothesis says: Microphysical processes throughout space-time are constituted by underlying computational processes.

![Image 2](https://consc.net/pics/@@/matrix3.jpg)
The Computational Hypothesis says that physics as we know it not the fundamental level of reality. Just as chemical processes underlie biological processes, and microphysical processes underlie chemical processes, something underlies microphysical processes. Underneath the level of quarks and electrons and photons is a further level: the level of bits. These bits are governed by a computational algorithm, which at a higher-level produces the processes that we think of as fundamental particles, forces, and so on.

Some people take the Computational Hypothesis it seriously. Most famously, Edward Fredkin has postulated that the universe is at bottom some sort of computer. More recently, Stephen Wolfram has taken up the idea in his book _A New Kind of Science_, suggesting that at the fundamental level, physical reality may be a sort of cellular automata, with interacting bits governed by simple rules. And some physicists have looked into the possibility that the laws of physics might be formulated computationally, or could be seen as the consequence of certain computational principles.

One might worry that pure bits could not be the fundamental level of reality: a bit is just a 0 or a 1, and reality can't really be zeroes and ones. Or perhaps a bit is just a "pure difference" between two basic states, and there can't be a reality made up of pure differences. Rather, bits always have to be implemented by more basic states, such as voltages in a normal computer.

I don't know whether this objection is right. I don't think it's completely out of the question that there could be a universe of "pure bits". But this doesn't matter for present purposes. We can suppose that the computational level is itself constituted by an even more fundamental level, at which the computational processes are implemented. It doesn't matter for present purposes what that more fundamental level is. All that matters is that microphysical processes are constituted by computational processes, which are themselves constituted by more basic processes. From now on I will regard the Computational Hypothesis as saying this.

I don't know whether the Computational Hypothesis is correct. But again, I don't know that it is false. The hypothesis is coherent, if speculative, and I cannot conclusively rule it out.

The Computational Hypothesis is not a skeptical hypothesis. If it is true, there are still electrons and protons. On this picture, electrons and protons will be analogous to molecules: they are made up of something more basic, but they still exist. Similarly, if the Computational Hypothesis is true, there are still tables and chairs, and macroscopic reality still exists. It just turns out that their fundamental reality is a little different from what we thought.

The situation here is analogous to that with quantum mechanics or relativity. These may lead us to revise a few "metaphysical" beliefs about the external world: that the world is made of classical particles, or that there is absolute time. But most of our ordinary beliefs are left intact. Likewise, accepting the Computational Hypothesis may lead us to revise a few metaphysical beliefs: that electrons and protons are fundamental, for example. But most of our ordinary beliefs are unaffected.

#### (2) The Creation Hypothesis

The Creation Hypothesis says: Physical space-time and its contents were created by beings outside physical space-time.

![Image 3](https://consc.net/pics/@@/matrix2.jpg)
This is a familiar hypothesis. A version of it is believed by many people in our society, and perhaps by the majority of the people in the world. If one believes that God created the world, and if one believes that God is outside physical space-time, then one believes the Creation Hypothesis. One needn't believe in God to believe the Creation Hypothesis, though. Perhaps our world was created by a relatively ordinary being in the "next universe up", using the latest world-making technology in that universe. If so, the Creation Hypothesis is true.

I don't know whether the Creation Hypothesis is true. But I don't know for certain that it is false. The hypothesis is clearly coherent, and I cannot conclusively rule it out.

The Creation Hypothesis is not a skeptical hypothesis. Even if it is true, most of my ordinary beliefs are still true. I still have hands, I am still in Tucson, and so on. Perhaps a few of my beliefs will turn out false: if I am an atheist, for example, or if I believe all reality started with the Big Bang. But most of my everyday beliefs about the external world will remain intact.

#### (3) The Mind-Body Hypothesis

The Mind-Body Hypothesis says: My mind is (and has always been) constituted by processes outside physical space-time, and receives its perceptual inputs from and sends its outputs to processes in physical space-time.

![Image 4](https://consc.net/pics/@@/matrix4.jpg)
The Mind-Body Hypothesis is also quite familiar, and quite widely believed. Descartes believed something like this: on his view, we have nonphysical minds that interact with our physical bodies. The hypothesis is less widely believed today than in Descartes' time, but there are still many people who accept the Mind-Body Hypothesis.

Whether or not the Mind-Body Hypothesis is true, it is certainly coherent. Even if contemporary science tends to suggest that the hypothesis is false, we cannot rule it out conclusively.

The Mind-Body Hypothesis is not a skeptical hypothesis. Even if my mind is outside physical space-time, I still have a body, I am still in Tucson, and so on. At most, accepting this hypothesis would make us revise a few metaphysical belies about our minds. Our ordinary beliefs about external reality will remain largely intact.

#### (4) The Metaphysical Hypothesis

We can now put these hypotheses together. First we can consider the Combination Hypothesis, which combines all three. It says that physical space-time and its contents were created by beings outside physical space-time, that microphysical processes are constituted by computational processes, and that our minds are outside physical space-time but interact with it.

As with the hypotheses taken individually, the Combination Hypothesis is coherent, and we cannot conclusively rule it out. And like the hypotheses taken individually, it is not a skeptical hypothesis. Accepting it might lead us to revise a few of our beliefs, but it would leave most of them intact.

Finally, we can consider the Metaphysical Hypothesis (with a capital M). Like the Combination Hypothesis, this combines the Creation Hypothesis, the Computational Hypothesis, and the Mind-Body Hypothesis. It also adds the following more specific claim: the computational processes underlying physical space-time were designed by the creators as a computer simulation of a world.

(It may also be useful to think of the Metaphysical Hypothesis as saying that the computational processes constituting physical space-time are part of a broader domain, and that the creators and my cognitive system are also located within this domain. This addition is not strictly necessary for what follows, but it matches up with the most common way of thinking about the Matrix Hypothesis.)

![Image 5](https://consc.net/pics/@@/matrix5.jpg)
The Metaphysical Hypothesis is a slightly more specific version of the Combination Hypothesis, in that in specifies some relations between the various parts of the hypothesis. Again, the Metaphysical Hypothesis is a coherent hypothesis, and we cannot conclusively rule it out. And again, it is not a skeptical hypothesis. Even if we accept it, most of our ordinary beliefs about the external world will be left intact.

### 4 The Matrix Hypothesis as a Metaphysical Hypothesis

Recall that the Matrix Hypothesis says: I have (and have always had) a cognitive system that receives its inputs from and sends its outputs to an artificially-designed computer simulation of a world.

I will argue that the Matrix Hypothesis is equivalent to the Metaphysical Hypothesis, in the following sense: if I accept the Metaphysical Hypothesis, I should accept the Matrix Hypothesis, and if I accept the Matrix Hypothesis, I should accept the Metaphysical Hypothesis. That is, the two hypotheses _imply_ each other, where this means that if one accepts the one, one should accept the other.

Take the first direction first, from the Metaphysical Hypothesis to the Matrix Hypothesis. The Mind-Body Hypothesis implies that I have (and have always had) an isolated cognitive system which receives its inputs from and sends its outputs to processes in physical space-time. In conjunction with the Computational Hypothesis, this implies that my cognitive system receives inputs from and sends outputs to the computational processes that constitute physical space-time. The Creation Hypothesis (along with the rest of the Metaphysical Hypothesis) implies that these processes were artificially designed to simulate a world. It follows that I have (and have always had) an isolated cognitive system that receives its inputs from and sends its outputs to an artificially-designed computer simulation of a world. This is just the Matrix Hypothesis. So the Metaphysical Hypothesis implies the Matrix Hypothesis.

The other direction is closely related. To put it informally: If I accept the Matrix Hypothesis, I accept that what underlies apparent reality is just as the Metaphysical Hypothesis specifies. There is a domain containing my cognitive system, causally interacting with a computer simulation of physical-space time, which was created by other beings in that domain. This just what has to obtain in order for the Metaphysical Hypothesis to obtain. If one accepts this, one should accept the Creation Hypothesis, the Computational Hypothesis, the Mind-Body Hypothesis, and the relevant relations among these.

This may be a little clearer through a picture. Here is the shape of the world according to the Matrix Hypothesis.

![Image 6](https://consc.net/pics/@@/matrix6.jpg)
At the fundamental level, this picture of the shape of the world is exactly the same as the picture of the Metaphysical Hypothesis given above. So if one accepts that the world is as it is according to the Matrix Hypothesis, one should accept that it is as it is according to the Metaphysical Hypothesis.

One might make various objections. For example, one might object that the Matrix Hypothesis implies that a computer simulation of physical processes exists, but (unlike the Metaphysical Hypothesis) it does not imply that the physical processes themselves exist. I will discuss this objection in section 6, and other objections in section 7. For now, though, I take it that there is a strong case that the Matrix Hypothesis implies the Metaphysical Hypothesis, and vice versa.

### 5 Life in the Matrix

If this is right, it follows that the Matrix Hypothesis is not a skeptical hypothesis. If I accept it, I should not infer that the external world does not exist, or that I have no body, or that there are no tables and chairs, or that I am not in Tucson. Rather, I should infer that the physical world is constituted by computations beneath the microphysical level. There are still tables, chairs, and bodies: these are made up fundamentally of bits, and of whatever constitutes these bits. This world was created by other beings, but is still perfectly real. My mind is separate from physical processes, and interacts with them. My mind may not have been created by these beings, and it may not be made up of bits, but it still interacts with these bits.

The result is a complex picture of the fundamental nature of reality. The picture is strange and surprising, perhaps, but it is a picture of a full-blooded external world. If we are in a matrix, this is simply the way that the world is.

We can think of the Matrix Hypothesis as a creation myth for the information age. If it is correct, then the physical world was created, not necessarily by gods. Underlying the physical world is a giant computation, and creators created this world by implementing this computation. And our minds lie outside this physical structure, with an independent nature that interacts with this structure.

Many of the same issues that arise with standard creation myths arise here. When was the world created? Strictly speaking, it was not created within _our_ time at all. When did history begin? The creators might have started the simulation in 4004 BC (or in 1999) with the fossil record intact, but it would have been much easier for them to start the simulation at the Big Bang and let things run their course from there.

(In the movie Matrix, of course, the creators are machines. This gives an interesting twist on common theological readings of the movie. It is often held that Neo is the Christ figure in the movie, with Morpheus corresponding to John the Baptist, Cypher to Judas Iscariot, and so on. But on the reading I have given, the gods of the Matrix are the machines. Who, then, is the Christ figure? Agent Smith, of course! After all, he is the gods' offspring, sent down to save the Matrix world from those who wish to destroy it. And in the second movie, he is even resurrected.)

Many of the same issues that arise on the standard Mind-Body Hypothesis also arise here. When do our nonphysical minds start to exist? It depends on just when new envatted cognitive systems are attached to the simulation (perhaps at the time of conception within the matrix, or perhaps at time of birth?). Is there life after death? It depends on just what happens to the envatted systems once their simulated bodies die. How do mind and body interact? By causal links that are outside physical space and time.

Even if we not in a matrix, we can extend a version of this reasoning to other beings who are in a matrix. If they discover their situation, and come to accept that they are in a matrix, they should not reject their ordinary beliefs about the external world. At most, they should come to revise their beliefs about the underlying nature of their world: they should come to accept that external objects are made of bits, and so on. These beings are not massively deluded: most of their ordinary beliefs about their world are correct.

There are a few qualifications here. One may worry about beliefs about other people's minds. I believe that my friends are conscious. If I am in a matrix, is this correct? In the Matrix depicted in the movie, these beliefs are mostly fine. This is a multi-vat matrix: for each of my perceived friends, there is an envatted being in the external reality, who is presumably conscious like me. The exception might be beings such as Agent Smith, who is not envatted, but is entirely computational. Whether these beings are conscious depends on whether computation is enough for consciousness. I will remain neutral on that issue here. We could circumvent this issue by building into the Matrix Hypothesis the requirement that all the beings we perceive are envatted. But even if we do not build in this requirement, we are not much worse off than in the actual world, where there is a legitimate issue about whether other beings are conscious, quite independently of whether we are in a matrix.

One might also worry about beliefs about the distant past, and about the far future. These will be unthreatened as long as the computer simulation covers all of space-time, from the Big Bang until the end of the universe. This is built into the Metaphysical Hypothesis, and we can stipulate that it is built into the Matrix Hypothesis too, by requiring that the computer simulation be a simulation of an entire world. There may be other simulations that start in the recent past (perhaps the Matrix in the movie is like this), and there may be others that only last for a short while. In these cases, the envatted beings will have false beliefs about the past and/or the future in their worlds. But as long as the simulation covers the lifespan of these beings, it is plausible that they will have mostly correct beliefs about the current state of their environment.

There may be some respects in which the beings in a matrix are deceived. It may be that the creators of the matrix control and interfere with much of what happens in the simulated world. (The Matrix in the movie may be like this, though the extent of the creators' control is not quite clear.) If so, then these beings may have much less control over what happens than they think. But the same goes if there is an interfering god in a non-matrix world. And the Matrix Hypothesis does not imply that the creators interfere with the world, though it leaves the possibility open. At worst, the Matrix Hypothesis is no more skeptical in this respect than the Creation Hypothesis in a non-matrix world.

The inhabitants of a matrix may also be deceived in that reality is much bigger than they think. They might think their physical universe is all there is, when in fact there is much more in the world, including beings and objects that they can never possibly see. But again, this sort of worry can arise equally in a non-matrix world. For example, cosmologists seriously entertain the hypothesis that our universe may stem from a black hole in the "next universe up", and that in reality there may be a whole tree of universes. If so, the world is also much bigger than we think, and there may be beings and objects that we can never possibly see. But either way, the world that we see is perfectly real.

Importantly, none of these sources of skepticism — about other minds, the past and the future, about our control over the world, and about the extent of the world — casts doubt on our belief in the reality of the world that we perceive. None of them leads us to doubt the existence of external objects such as tables and chairs, in the way that the vat hypothesis is supposed to do. And none of these worries is especially tied to the matrix scenario. One can raise doubts about whether other minds exist, whether the past and the future exist, and whether we have control over our worlds quite independently of whether we are in a matrix. If this is right, then the Matrix Hypothesis does not raise the distinctive skeptical issues that it is often taken to raise.

I suggested before that it is not out of the question that we really are in a matrix. One might have thought that this is a worrying conclusion. But if I am right, it is not nearly as worrying as one might have thought. Even if we are in such a matrix, our world is no less real than we thought it was. It just has a surprising fundamental nature.

### 6 Objection: Simulation is not Reality

(This slightly technical section can be skipped without too much loss.)

A common line of objection is that a simulation is not the same as reality. The Matrix Hypothesis implies only that a simulation of physical processes exists. By contrast, the Metaphysical Hypothesis implies that physical processes really exist (they are explicitly mentioned in the Computational Hypothesis and elsewhere). If so, then the Matrix Hypothesis cannot imply the Metaphysical Hypothesis. On this view, if I am in a matrix, then physical processes do not really exist.

In response: My argument does not require the general assumption that simulation is the same as reality. The argument works quite differently. But the objection helps us to flesh out the informal argument that the Matrix Hypothesis implies the Metaphysical Hypothesis.

Because the Computational Hypothesis is coherent, it is clearly _possible_ that a computational level underlies real physical processes, and it is possible that the computations here are implemented by further processes in turn. So there is _some_ sort of computational system that could yield reality here. But here, the objector will hold that not all computational systems are created equal. To say that some computational systems will yield real physical processes in this role is not to say that they all do. Perhaps some of them are merely simulations. If so, then the Matrix Hypothesis may not yield reality.

To rebut this objection, we can appeal to two principles. First principle: any abstract computation that could be used to simulate physical space-time is such that it _could_ turn out to underlie real physical processes. Second principle: given an abstract computation that _could_ underlie physical processes, the precise way in which it is implemented is irrelevant to whether it _does_ underlie physical processes. In particular, the fact that the implementation was designed as a simulation is irrelevant. The conclusion then follows directly.

On the first principle: let us think of abstract computations in purely formal terms, abstracting away from their manner of implementation. For an abstract computation to qualify as a simulation of physical reality, it must have computational elements that correspond to every particle in reality (likewise for fields, waves, or whatever is fundamental), dynamically evolving in a way that corresponds to the particle's evolution. But then, it is guaranteed that the computation will have a rich enough causal structure that it _could_ in principle underlie physics in our world. Any computation will do, as long as it has enough detail to correspond to the fine details of physical processes.

On the second principle: given an abstract computation that could underlie physical reality, it does not matter how the computation is implemented. We can imagine discovering that some computational level underlies the level of atoms and electrons. Once we have discovered this, it is possible that this computational level is implemented by more basic processes. There are many hypotheses about what the underlying processes could be, but none of them is especially privileged, and none of them would lead us to reject the hypothesis that the computational level constitutes physical processes. That is, the Computational Hypothesis is _implementation-independent_: as long as we have the right sort of abstract computation, the manner of implementation does not matter.

In particular, it is irrelevant whether or not these implementing processes were artificially created, and it is irrelevant whether they were intended as a simulation. What matters is the intrinsic nature of the processes, not their origin. And what matters about this intrinsic nature is simply that they are arranged in such a way to implement the right sort of computation. If so, the fact that the implementation originated as a simulation is irrelevant to whether it can constitute physical reality.

There is one further constraint on the implementing processes: they must be connected to our experiences in the right sort of way. That is when we have an experience of an object, the processes underlying the simulation of that object must be causally connected in the right sort of way to our experiences. If this is not the case, then there will be no reason to think that these computational processes underlie the physical processes that we perceive. If there is an isolated computer simulation to which nobody is connected in this way, we should say that it is simply a simulation. But an appropriate hook-up to our perceptual experiences is built into the Matrix Hypothesis, on the most natural understanding of that hypothesis. So the Matrix Hypothesis has no problems here.

Overall, then, we have seen that a computational processes _could_ underlie physical reality, that any abstract computation that qualifies as a simulation of physical reality could play this role, and that any implementation of this computation could constitute physical reality, as long as it is hooked up to our experiences in the relevant way. The Matrix Hypothesis guarantees that we have an abstract computation of the right sort, and it guarantees that it is hooked up to our experiences in the relevant way. So the Matrix Hypothesis implies that the Computational Hypothesis is correct, and that the computer simulation constitutes genuine physical processes.

### 7 Other Objections

When we look at a brain in a vat from the outside, it is hard to avoid the sense that it is deluded. This sense manifests itself in a number of related objections. These are not direct objections to the argument above, but they are objections to its conclusion.

![Image 7](https://consc.net/pics/@@/matrix1.jpg)
**Objection 1**: A brain in a vat may think it is outside walking in the sun, when in fact it is alone in a dark room. Surely it is deluded!

Response: The _brain_ is alone in a dark room. But this does not imply that the _person_ is alone in a dark room. By analogy, just say Descartes is right that we have disembodied minds outside space-time, made of ectoplasm. When I think "I am outside in the sun", an angel might look at my ectoplasmic mind and note that in fact it is not exposed to any sun at all. Does it follow that my thought is incorrect? Presumably not: I can be outside in the sun, even if my ectoplasmic mind is not. The angel would be wrong to infer that I have an incorrect belief. Likewise, we should not infer that envatted being has an incorrect belief. At least, it is no more deluded than a Cartesian mind.

The moral is that the immediate surroundings of our minds may well be irrelevant to the truth of most of our beliefs. What matters is the processes that our minds are connected to, by perceptual inputs and motor outputs. Once we recognize this, the objection falls away.

**Objection 2**: An envatted being may believe that it is in Tucson, when in fact it is in New York, and has never been anywhere near Tucson. Surely this belief is deluded.

Response: The envatted being's concept of "Tucson" does not refer to what we call Tucson. Rather, it refers to something else entirely: call this Tucson*, or "virtual Tucson". We might think of this as a "virtual location" (more on this in a moment). When the being says to itself "I am in Tucson", it really is thinking that it is in Tucson*, and it may well in fact be in Tucson*. Because Tucson is not Tucson*, the fact that the being has never been in Tucson is irrelevant to whether its belief is true.

A rough analogy: I look at my colleague Terry, and think "that's Terry". Elsewhere in the world, a duplicate of me looks at a duplicate of Terry. It thinks "that's Terry", but it is not looking at the real Terry. Is its belief false? It seems not: my duplicate's "Terry" concept refers not to Terry, but to his duplicate Terry*. My duplicate really is looking at Terry*, so its belief is true. The same sort of thing is happening in the case above.

**Objection 3**: Before he leaves the Matrix, Neo believes that he has hair. But in reality he has no hair (the body in the vat is bald). Surely this belief is deluded.

Response: This case is like the last one. Neo's concept of "hair" does not refer to real hair, but to something else that we might call hair* ("virtual hair"). So the fact that Neo does not have real hair is irrelevant to whether his belief is true. Neo really does has virtual hair, so he is correct. Likewise, when a child in the movie tells Neo "There is no spoon", his concept refers to a virtual spoon, and there really is a virtual spoon. So the child is wrong.

**Objection 4**: What _sort_ of objects does an envatted being refer to. What _is_ virtual hair, virtual Tucson, and so on?

Response: These are all entities constituted by computational processes. If I am envatted, then the objects that I refer to (hair, Tucson, and so on) are all made of bits. And if another being is envatted, the objects that it refers to (hair*, Tucson*, and so on) are likewise made of bits. If the envatted being is hooked up to a simulation in my computer, then the objects it refers to are constituted by patterns of bits inside my computer. We might call these things _virtual objects_. Virtual hands are not hands (assuming I am not envatted), but they exist inside the computer all the same. Virtual Tucson is not Tucson, but it exists inside the computer all the same.

**Objection 5**: You just said that virtual hands are not real hands. Does this mean that if we are in the matrix, we don't have real hands?

Response: No. If we are _not_ in the matrix, but someone else is, we should say that their term "hand" refers to virtual hands, but our term does not. So in this case, our hands aren't virtual hands. But if we _are_ in the matrix, then our term "hand" refers to something that's made of bits: virtual hands, or at least something that would be regarded as virtual hands by people in the next world up. That is, if we _are_ in the matrix, real hands are made of bits. Things look quite different, and our words refer to different things, depending on whether our perspective is inside or outside the matrix.

This sort of perspective shift is common in thinking about the matrix scenario. From the first-person perspective, we suppose that _we_ are in a matrix. Here, real things in our world are made of bits, though the "next world up" might not be made of bits. From the third-person perspective, we suppose that someone _else_ is in a matrix but we are not. Here, real things in our world are not made of bits, but the "next world down" is made of bits. On the first way of doing things, our words refer to computational entities. On the second way of doing things, the envatted beings' words refer to computational entities, but our words do not.

**Objection 6**: Just which pattern of bits is a given virtual object? Surely it will be impossible to pick out a precise set.

Response: This question is like asking: just which part of the quantum wavefunction is this chair, or is the University of Arizona? These objects are all ultimately constituted by an underlying quantum wavefunction, but there may be no precise part of the micro-level wavefunction that we can say "is" the chair or the university. The chair and the university exist at a higher level. Likewise, if we are envatted, there may be no precise set of bits in the micro-level computational process that is the chair or the university. These exist at a higher level. And if someone else is envatted, there may be no precise sets of bits in the computer simulation that "are" the objects they refer to. But just as a chair exists without being any precise part of the wavefunction, a virtual chair may exist without being any precise set of bits.

**Objection 7**: An envatted being thinks it performs actions, and it thinks it has friends. Are these beliefs correct?

Response: One might try to say that the being performs actions* and that it has friends*. But for various reason I think it is not plausible that words like "action" and "friend" can shift their meanings as easily as words like like "Tucson" and "hair". Instead, I think one can say truthfully (in our own language) that the envatted being performs actions, and that it has friends. To be sure, it performs actions in _its_ environment, and its environment is not our environment but the virtual environment. And its friends likewise inhabit the virtual environment (assuming that we have a multi-vat matrix, or that computation suffices for consciousness). But the envatted being is not incorrect in this respect.

**Objection 8**: Set these technical points aside. Surely, if we are in a matrix, the world is nothing like we think it is!

Response: I deny this. Even if we are in a matrix, there are still people, football games, and particles, arranged in space-time just as we think they are. It is just that the world has a _further_ nature that goes beyond our initial conception. In particular, things in the world are realized computationally in a way that we might not have originally imagined. But this does not contradict any of our ordinary beliefs. At most, it will contradict a few of our more abstract metaphysical beliefs. But exactly the same goes for quantum mechanics, relativity theory, and so on.

If we are in a matrix, we may not have many false beliefs, but there is much knowledge that we lack. For example, we do not know that the universe is realized computationally. But this is just what one should expect. Even if we are not in a matrix, there may well be much about the fundamental nature of reality that we do not know. We are not omniscient creatures, and our knowledge of the world is at best partial. This is simply the condition of a creature living in a world.

### 8 Other Skeptical Hypothesis

The Matrix Hypothesis is one example of a traditional "skeptical" hypothesis, but it is not the only example. Other skeptical hypotheses are not quite as straightforward as the Matrix Hypothesis. Still, I think that for many of them, a similar line of reasoning applies. In particular, one can argue that most of these are not global skeptical hypothesis: that is, their truth would not undercut all of our empirical beliefs about the physical world. At worst, most of them are _partial_ skeptical hypotheses, undercutting some of our empirical beliefs, but leaving many of these beliefs intact.

**New Matrix Hypothesis**: I was recently created, along with all my memories, and was put in a newly-created matrix.

What if both the matrix and I have existed for only a short time? This hypothesis is a computational version of Bertrand Russell's Recent Creation Hypothesis: the physical world was created only recently (with fossil record intact), and so was I (with memories intact). On that hypothesis, the external world that I perceive really exists, and most of my beliefs about its current states are plausibly true, but I have many false beliefs about the past. I think the same should be said of the New Matrix Hypothesis. One can argue, along the lines presented earlier, that the New Matrix Hypothesis is equivalent to a combination of the Metaphysical Hypothesis with the Recent Creation Hypothesis. This combination is not a global skeptical hypothesis (though it is a partial skeptical hypothesis, where beliefs about the past are concerned). So the same goes for the New Matrix Hypothesis.

**Recent Matrix Hypothesis**: For most of my life I have not been envatted, but I was recently hooked up to a matrix.

If I was recently put in a matrix without realizing it, it seems that many of my beliefs about my current environment are false. Let's say that just yesterday someone put me into a simulation, in which I fly to Las Vegas and gamble at a casino. Then I may believe that I am in Las Vegas now, and that I am in a casino, but these beliefs at false: I am really in a laboratory in Tucson.

This result is quite different from the long-term matrix. The difference lies in the fact that my conception of external reality is anchored to the reality in which I have lived most of my life. If I have been envatted all my life, my conception is anchored to the computationally constituted reality. But if I was just envatted yesterday, my conception is anchored to the external reality. So when I think that I am in Las Vegas, I am thinking that I am in the external Las Vegas, and this thought is false.

Still, this does not undercut all of my beliefs about the external world. I believe that I was born in Sydney, that there is water in the oceans, and so on, and all of these beliefs are correct. It is only my recently acquired beliefs, stemming from perception of the simulated environment, that will be false. So this is only a partial skeptical hypothesis: its possibility casts doubt on a subset of our empirical beliefs, but it does not cast doubt on all of them.

Interestingly, the Recent Matrix and the New Matrix hypothesis give opposite results, despite their similar nature: the Recent Matrix Hypothesis yields true beliefs about the past but false beliefs about the present, while the New Matrix Hypothesis yields false beliefs about the past and true beliefs about the present. The differences are tied to the fact that in Recent Matrix Hypothesis, I really have a past existence for my beliefs to be about, and that past reality has played a role in anchoring the contents of my thoughts that has no parallel under the New Matrix Hypothesis.

**Local Matrix Hypothesis**: I am hooked up to a computer simulation of a fixed local environment in a world.

On one way of doing this, a computer simulates a small fixed environment in a world, and the subjects in the simulation encounter some sort of barrier when they try to leave that area. For example, in the movie _The Thirteenth Floor_, just California is simulated, and when the subject tries to drive to Nevada, the road says "Closed for Repair" (with faint green electronic mountains in the distance!). Of course this is not the best way to create a matrix, as subjects are likely to discover the limits to their world.

This hypothesis is analogous to a Local Creation Hypothesis, on which creators just created a local part of the physical world. Under this hypothesis, we will have true beliefs about nearby matters, but false beliefs about matters further from home. By the usual sort of reasoning, the Local Matrix Hypothesis can be seen as a combination of the Metaphysical Hypothesis with the Local Creation Hypothesis. So we should say the same thing about this.

**Extendible Local Matrix Hypothesis**: I am hooked up to a computer simulation of a local environment in a world, extended when necessary depending on subject's movements.

This hypothesis avoids the obvious difficulties with a fixed local matrix. Here the creators simulate a local environment and extend it when necessary. For example, they might right now be concentrating on simulating a room in my house in Tucson. If I walk into another room, or fly to another city, they will simulate those. Of course they need to make sure that when I go to these places, they match my memories and beliefs reasonably well, with allowance for evolution in the meantime. The same goes for when I encounter familiar people, or people I have only heard about. Presumably the simulators keep up a database of the information about the world that has been settled so far, updating this information whenever necessary as time goes along, and making up new details when they need them.

This sort of simulation is quite unlike simulation in an ordinary matrix. In a matrix, the whole world is simulated at once. There are high start-up costs, but once the simulation is up and running, it will take care of itself. By contrast, the extendible local matrix involves "just-in-time" simulation. This has much lower start-up costs, but it requires much more work and creativity as the simulation evolves.

This hypothesis is analogous to an Extendible Local Creation Hypothesis about ordinary reality, under which creators create just a local physical environment, and extend it when necessary. Here, external reality exists and many local beliefs are true, but again beliefs about matters further from home are false. If we combine that hypothesis with the Metaphysical Hypothesis, the result is the Extendible Local Matrix Hypothesis. So if we are in an extendible local matrix, external reality still exists, but there is not as much of it as we thought. Of course if I travel in the right direction, more of it may come into existence!

The situation is reminiscent of _The Truman Show_. Truman lives in an artificial environment made up of actors and props, which behave appropriately when he is around, but which may be completely different when he is absent. Truman has many true beliefs about his current environment: there really are tables and chairs in front of him, and so on. But he is deeply mistaken about things outside his current environment, and further from home.

It is common to think that while _The Truman Show_ poses a disturbing skeptical scenario, _The Matrix_ is much worse. But if I am right, things are reversed. If I am in a matrix, then most of my beliefs about the external world are true. If I am in something like _The Truman Show_, then a great number of my beliefs are false. On reflection, it seems to me that this is the right conclusion. If we were to discover that we were (and always had been) in a matrix, this would be surprising, but we would quickly get used to it. If we were to discover that we were (and always had been) in the Truman Show, we might well go insane.

**Macroscopic Matrix Hypothesis**: I am hooked up to a computer simulation of macroscopic physical processes without microphysical detail.

One can imagine that for ease of simulation, the makers of a matrix might not both to simulate low-level physics. Instead, they might just represent macroscopic objects in the world and their properties: e.g. that there is a table with such-and-such shape, position, and color, with a book on top of it with certain properties, and so on. They will need to make some effort to make sure that these objects behave in a physically reasonable way, and they will have to make special provisions for handling microphysical measurements, but one can imagine that at least a reasonable simulation could be created this way.

I think this hypothesis is analogous to a Macroscopic World Hypothesis: there are no microphysical processes, and instead macroscopic physical objects exist as fundamental objects in the world, with properties of shape, color, position, and so on. This is a coherent way our world could be, and it is not a global skeptical hypothesis, though it may lead to false scientific beliefs about lower levels of reality. The Macroscopic Matrix Hypothesis can be seen as a combination of this hypothesis with a version of the Metaphysical Hypothesis. As such, it is not a global skeptical hypothesis either.

One can also combine the various hypothesis above in various ways, yielding hypotheses such as a New Local Macroscopic Matrix Hypothesis. For the usual reasons, all of these can be seen as analogs of corresponding hypotheses about the physical world. So all of them are compatible with the existence of physical reality, and none is a global skeptical hypothesis.

**God Hypothesis**: Physical reality is represented in the mind of God, and our own thoughts and perceptions depend on God's mind.

A hypothesis like this was put forward by George Berkeley as a view about how our world might really be. Berkeley intended this as a sort of metaphysical hypothesis about the nature of reality. Most other philosophers have differed from Berkeley in regarding this as a sort of skeptical hypothesis. If I am right, Berkeley is closer to the truth. The God Hypothesis can be seen as a version of the Matrix Hypothesis, on which the simulation of the world is implemented in the mind of God. If this is right, we should say that physical processes really exist: it's just that at the most fundamental level, they are constituted by processes in the mind of God.

**Evil Genius Hypothesis**: I have a disembodied mind, and an evil genius is feeding me sensory inputs to give the appearance of an external world.

This is Rene Descartes's classical skeptical hypothesis. What should we say about it? This depends on just how the evil genius works. If the evil genius simulates an entire world in his head in order to determine what inputs I should receive, then we have a version of the God Hypothesis. Here we should say that physical reality exists and is constituted by processes within the genius. If the evil genius is simulating only a small part of the physical world, just enough to give me reasonably consistent inputs, then we have an analog of the Local Matrix Hypothesis (in either its fixed or flexible versions). Here we should say that just a local part of external reality exists. If the evil genius is not bothering to simulate the microphysical level, but just the macroscopic level, then we have an analog of the Macroscopic Matrix Hypothesis. Here we should say that local external macroscopic objects exist, but our beliefs about their microphysical nature are incorrect.

The evil genius hypothesis is often taken to be a global skeptical hypothesis. But if the reasoning above is right, this is incorrect. Even if the Evil Genius Hypothesis is correct, some of the external reality that we apparently perceive really exists, though we may have some false beliefs about it, depending on details. It is just that this external reality has an underlying nature that is quite different from what we may have thought.

**Dream Hypothesis**: I am now and have always been dreaming.

Descartes raised the question: how do you know that you are not currently dreaming? Morpheus raises a similar question:

> Have you ever had a dream, Neo, that you were so sure was real. What if you were unable to wake from that dream? How would you know the difference between the dream world and the real world?

The hypothesis that I am _currently_ dreaming is analogous to a version of the Recent Matrix Hypothesis. I cannot rule it out conclusively, and if it is correct, then many of my beliefs about my current environment are incorrect. But presumably I still have many true beliefs about the external world, anchored in the past.

What if I have always been dreaming? That is, what if all of my apparent perceptual inputs have been generated by my own cognitive system, without my realizing this? I think this case is analogous to the Evil Genius Hypothesis: it's just that the role of the "evil genius" is played by a part of my own cognitive system! If my dream-generating system simulates all of space-time, we have something like the original Matrix Hypothesis. If it models just my local environment, or just some macroscopic processes, we have analogs of the more local versions of the Evil Genius Hypothesis above. In any of these cases, we should say that the objects that I am currently perceiving really exist (although objects farther from home may not). It is just that some of them are constituted by my own cognitive processes.

**Chaos Hypothesis**: I do not receive inputs from anywhere in the world. Instead, I have random uncaused experiences. Through a huge coincidence, they are exactly the sort of regular, structured experiences with which I am familiar.

The Chaos Hypothesis is an extraordinarily unlikely hypothesis, much more unlikely than anything considered above. But it is still one that could in principle obtain, even if it has miniscule probability. If I am chaotically envatted, do physical processes in the external world exist? I think we should say that they do not. My experiences of external objects are caused by nothing, and the set of experiences associated with my conception of a given object will have no common source. Indeed, my experiences are not caused by any reality external to them at all. So this is a genuine skeptical hypothesis: if accepted, it would cause us to reject most of our beliefs about the external world.

So far, the only clear case of a global skeptical hypothesis is the Chaos Hypothesis. Unlike the previous hypothesis, accepting this hypothesis would undercut all of our substantive beliefs about the external world. Where does the difference come from?

Arguably, what is crucial is that on the Chaos Hypothesis, there is no causal explanation of our experiences at all, and there is no explanation for the regularities in our experience. In all the previous cases, there is some explanation for these regularities, though perhaps not the explanation that we expect. One might suggest that as long as a hypothesis involves _some_ reasonable explanation for the regularities in our experience, then it will not be a global skeptical hypothesis.

If so, then if we are granted the assumption that there is some explanation for the regularities in our experience, then it is safe to say that some of our beliefs about the external world are correct. This is not much, but it is something!

### 9 Philosophical Notes

The material above was written to be accessible to a wide audience, so it deliberately omits technical philosophical details, connections to the literature, and so on. Here I will try to remedy this omission. Readers without a background in philosophy should probably skip or skim this section.

**Note 1**: Hilary Putnam (1981) has argued that the hypothesis that I am (and have always been) a brain in a vat can be ruled out a priori. In effect, this is because my word "brain" refers to objects in my perceived world, and it cannot refer to objects in an "outer" world in which the vat would have to exist. For my hypothesis "I am a brain in a vat" to be true, I would have to be a brain of the sort that exists in the perceived world, but that cannot be the case. So the hypothesis must be false.

An analogy: I can arguably rule out the hypothesis that I am in the Matrix (capital M). My term "the Matrix" refers to a specific system that I have seen in a movie in my perceived world. I could not be in that very system, as the system exists within the world that I perceive. So my hypothesis "I am in the Matrix" must be false.

This conclusion about the Matrix seems reasonable, but there is a natural response. Perhaps this argument rules out the hypothesis that I am in the Matrix, but I cannot rule out the hypothesis that I am in a matrix, where a matrix is a generic term for a computer simulation of a world. The term "Matrix" may be anchored to the specific system in the movie, but the generic term "matrix" is not.

Likewise, it is arguable that I can rule out the hypothesis that I am a brain in a vat (if "brain" is anchored to a specific sort of biological system in my perceived world). But I cannot rule out the hypothesis that I am envatted, where this simply says that I have a cognitive system that receives input from and sends outputs to a computer simulation of a world. The term "envatted" (and the terms used in its definition) are generic terms, not anchored to specific systems in perceived reality. By using this slightly different language, we can restate the skeptical hypothesis in a way that is invulnerable to Putnam's reasoning.

More technically: Putnam's argument may work for "brain" and "Matrix" because one is a natural kind term and the other is a name. These terms are subject to "Twin Earth" thought experiments (Putnam 1975), where duplicates can use corresponding terms with different referents. On Earth, Oscar's term "water" refers to H 2 O; but on Twin Earth (which contains the superficially identical XYZ in its oceans and lakes), Twin Oscar's term "water" refers to XYZ. Likewise, perhaps my term "brain" refers to biological brains, while an envatted being's term "brain" refers to virtual brains. If so, when an envatted being says "I am a brain in a vat", it is not referring to its biological brain, and its claim is false.

But not all terms are subject to Twin Earth thought experiments. In particular, _semantically neutral_ terms are not (at least when used without semantic deference): such terms plausibly include "philosopher", "friend", and many others. Other such terms include "matrix" and "envatted", as defined in this article. If we work with hypotheses such as "I am in a matrix" and "I am envatted", rather than "I am in the Matrix" or "I am a brain in a vat", then Putnam's argument does not apply. Even if a brain in a vat could not truly think "I am a brain in a vat", it could truly think "I am envatted". So I think that Putnam's line of reasoning is ultimately a red herring.

**Note 2**: Despite this disagreement, the conclusion of this article is closely related to another suggestion of Putnam's. This is the suggestion that a brain in a vat may have true beliefs, because it will refer to chemical processes or processes inside a computer. However, I reach this conclusion by a quite different route. Putnam argues by an appeal to the causal theory of reference: thoughts refer to what they are causally connected to, and the thoughts of an envatted being are causally connected to processes in a computer. This argument is clearly inconclusive, as the causal theory of reference is so unconstrained. To say that a causal connection is required for reference is not to say what sort of causal connection suffices. There are many cases (like "phlogiston") where terms fail to refer despite rich causal connections. Intuitively, it is natural to think that the brain in a vat is a case like this, so an appeal to the causal theory of reference does not seem to help.

The argument I have given presupposes nothing about the theory of reference. Instead, it proceeds directly by considering first-order hypotheses about the world, the connections between these, and what we should say if they are true. In answering objections, I have made some claims about reference, and these claims are broadly compatible with a causal theory of reference. But importantly, these claims are very much consequences of the first-order argument rather than presuppositions of it. In general, I think that claims in the theory of reference are beholden to first-order judgments about cases, rather than vice versa.

**Note 3**: I use "skeptical hypothesis" in this article in a certain technical sense. A skeptical hypothesis (relative to a belief that P) is a hypothesis such that (i) we cannot rule it out with certainty; (ii) were we to accept it, we would reject the belief that P. A skeptical hypothesis with respect to a class of beliefs is one that is a skeptical hypothesis with respect to most or all the beliefs in that class. A global skeptical hypothesis is a skeptical hypothesis with respect to all our empirical beliefs.

The existence of a skeptical hypothesis (with respect to a belief) casts doubt on the relevant belief, in the following sense. Because we cannot rule out the hypothesis with certainty, and because the hypothesis implies the negation of these beliefs, it seems (given a plausible closure principle about certainty) that our knowledge of these beliefs is not certain. If it is also the case that we do not _know_ that the skeptical hypothesis does not obtain (as I think is the case for most of the hypotheses in this article), then it follows from an analogous closure principle that the beliefs in the class do not constitute knowledge.

Some use "skeptical hypothesis" in a broader sense, to apply to any hypothesis such that if it obtains, I do not know that P. (A hypothesis under which I have accidentally true beliefs is a skeptical hypothesis in this sense but not in the previous sense.) I have not argued here that the Matrix Hypothesis is not a skeptical hypothesis in this sense. I have argued that if the hypothesis obtains, our beliefs are true, but I have not argued that if it obtains, our beliefs constitute knowledge. Nevertheless, I am inclined to think that if we have knowledge in an ordinary non-matrix world, we would also have knowledge in a matrix.

**Note 4**: What is the relevant class of beliefs? Of course there are some beliefs that even a no-external-world skeptical hypothesis might not undercut: the belief that I exist, or the belief that 2+2=4, or the belief that there are no unicorns. Because of this, it is best to restrict attention to beliefs that (i) are about the external world, (ii) are not justifiable a priori, and (iii) make a positive claim about the world (they could not be true in an empty world). For the purposes of this article we can think of these beliefs as our "empirical beliefs". Claims about skeptical hypotheses undercutting beliefs should generally be understood as restricted to beliefs in this class.

**Note 5**: On the Computational Hypothesis: It is coherent to suppose that there is a computational level underneath physics, but it is not clear whether it is coherent to suppose that this level is fundamental. If it is, then we have a world of "pure bits". Such a world would be a world of pure differences: there are two basic states that differ from one another, without this difference being a difference in some deeper nature. Whether one thinks this is coherent or not is connected to whether one thinks that all differences must be grounded in some basic intrinsic nature, on whether one thinks that all dispositions must have a categorical bases, and so on. For the purposes of this paper, however, the issue can be set aside. Under the Matrix Hypothesis, the computation itself is _implemented_ by processes in the world of the creator. As such, there will be a more basic level of intrinsic properties that serves as the basis for the differences between bits.

**Note 6**: On the Mind-Body Hypothesis: It is interesting to note that the Matrix Hypothesis shows a concrete way in which Cartesian substance dualism might have turned out to be true. It is sometimes held that the idea of physical processes interacting with a nonphysical mind is not just implausible but incoherent. The Matrix Hypothesis suggests fairly straightforwardly that this is wrong. Under this hypothesis, our cognitive system involves processes quite distinct from the processes in the physical world, but there is a straightforward causal story about how they interact.

Some questions arise. For example, if the envatted cognitive system is producing a body's motor outputs, what role does the simulated brain play? Perhaps one could do without it, but this will cause all sorts of awkward results, not least when doctors in the matrix open the skull. It is more natural to think that the envatted brain and the simulated brain will always be in isomorphic states, receiving the same inputs and producing the same outputs. If the two systems start in isomorphic states and always receive the same inputs, then (setting aside indeterminism) they will always stay in isomorphic states. As a bonus, this may explain why death in the Matrix leads to death in the outer world!

Which of these actually controls the body? This depends on how things are set up. Things might be set up so the envatted system's outputs are not fed back to the simulation; in this case a version of epiphenomenalism will be true. Things might be set up so that motor impulses in the simulated body depend on the envatted system's outputs with the simulated brain's outputs being ignored; in this case a version of interactionism will be true. Interestingly, this last might be a version of interactionism that is compatible with causal closure of the physical! A third possibility is that the mechanisms takes both sets of outputs into account (perhaps averaging the two?). This could yield a sort of redundancy in the causation. Perhaps the controllers of the matrix might even sometimes switch between the two. In any of these cases, as long as the two systems stay in isomorphic states, the behavioral results will be the same.

One might worry that there will be two conscious minds here, in a fashion reminiscent of Daniel Dennett's story "Where am I"? This depends on whether computation in the matrix is enough to support a mind. If anti-computationalists about the mind (such as John Searle) are right, there will be just one mind. If computationalists about the mind are right, there may well be two synchronized minds (which then raises the question: if I am in the matrix, which of the two minds is mine?). The one-mind view is certainly closer to the ordinary conception of reality, but the two-mind view is not out of the question.

One bonus of the computationalist view is that it allows us to entertain the hypothesis that we are in a computer simulation _without_ a separate cognitive system attached. Instead, the creators just run the simulation, including a simulation of brains, and minds emerge within it. This is presumably much easier for the creators, as it removes any worries tied to creation and upkeep of the attached cognitive systems. Because of this, it seems quite plausible that there will be many simulations of this sort in the future, whereas it is unclear that there will be many of the more cumbersome Matrix-style simulations. (Because of this, Bostrom's argument that we may well be in a simulation applies more directly to this sort of simulation than to Matrix-style simulations.) The hypothesis that we are in this sort of computer simulation corresponds to a slimmed-down version of the Metaphysical Hypothesis, on which the Mind-Body Hypothesis is unnecessary. As before, this is a non-skeptical hypothesis: if we are in such a simulation (and if computationalism about the mind is true), then most of our beliefs about the external world are still correct.

There are also other possibilities. One intriguing possibility (discussed in Chalmers 1990) is suggested by contemporary work in artificial life which involves relatively simple simulated environments, and complex rules by which simulated creatures interact with these environments. Here the algorithms responsible for the creatures "mental" processes are quite distinct from those governing the "physics" of the environment. In this sort of simulation, creatures will presumably never find underpinnings for their cognitive processes in their perceived world. If these creatures become scientists, they will be Cartesian dualists, holding (correctly!) that their cognitive processes lie outside their physical world. It seems that this is another coherent way that Cartesian dualism might have turned out to be true.

**Note 7**: I have argued that the Matrix Hypothesis implies the Metaphysical Hypothesis and vice versa. Here, "implies" is an epistemic relation: if one accepts the first, one should accept the second. I do not claim that the Matrix Hypothesis _entails_ the Metaphysical Hypothesis, in the sense that in any counterfactual world in which the Matrix Hypothesis holds, the Metaphysical Hypothesis holds. That claim seems false. For example, there are counterfactual worlds in which physical space-time is created by nobody (so the Metaphysical Hypothesis is false), in which I am hooked up to an artificially-designed computer simulation located within physical space-time (so the Matrix Hypothesis is true). And if physics is not computational in the actual world, then physics in this world is not computational either. One might say that the two hypothesis are _a priori_ equivalent, but not necessarily equivalent.

(Of course the term "physics" as used by my envatted self in the counterfactual world will refer to something that is both computational and created. But "physics" as used by my current envatted self picks out the outer non-computational physics of that world, not the computational processes.)

The difference arises from two different ways of considering the Matrix Hypothesis: as a hypothesis about what might actually be the case, or as a hypothesis about what might have been the case but is not. The first hypothesis is reflected in indicative conditionals: if I am actually in a matrix, then I have hands, atoms are made of bits, and the Metaphysical Hypothesis is true. The second version is reflected in subjunctive conditionals: if I had been in a matrix, I would not have had hands, and atoms would not have been made of bits, and the Metaphysical Hypothesis would not have been true.

This is analogous to the different ways of thinking about Putnam's Twin Earth scenario, common in discussions of two-dimensional semantics. If I am actually in the XYZ-world, then XYZ is water; but if I had been in the XYZ-world, XYZ would not have been water (water would still have been H 2 O). On the first way of doing things, we consider a Twin Earth world _as actual_. On the second way of doing things, we consider a Twin Earth world _as counterfactual_. We can say that the Twin Earth world _verifies_ "water is XYZ", but that it _satisfies_ "water is not XYZ", where verification and satisfaction correspond to considering as actual and as counterfactual.

Likewise, we can say that a matrix world verifies the Metaphysical Hypothesis, but it does not satisfy the Metaphysical Hypothesis. The reason is that the Metaphysical Hypothesis makes claims about physics and the physical world. And what counts as "physics" differs depending on whether the matrix world is considered as actual or counterfactual. If I am in a matrix, physics is computational. But if I _had been_ in a matrix, physics would not have been computational (the matrix would have been computational, but the computer and my brain would all have been made from computation-independent physics). In this way, claims about physics and physical processes in the matrix world are analogous to claims about "water" in the Twin Earth world.

**Note 8**: The responses to the first few objections in section 7 are clearly congenial to a causal account of reference. I said that the truth of an envatted being's thoughts depends not on its immediate environment but on what it is causally connected to: that is, on the computational processes to which it is hooked up. As noted earlier, I did not need to assume the causal theory of reference to get to this conclusion, but instead got there through a first-order argument. But once the conclusion is reached, there are many interesting points of contact.

For example, the idea that my term "hair" refers to hair while my envatted counterpart's term refers to virtual hair has a familiar structure. It is structurally analogous to a Twin Earth case, in which Oscar (on Earth) refers to water (H 2 O) while his counterpart Twin Oscar (on Twin Earth) refers to twin water (XYZ). In both cases, terms refer to what they are causally connected to. These natural-kind terms function by picking out a certain kind in the subject's environment, and the precise nature of that kind depends on nature of the environment. Something similar applies to names for specific entities, such as "Tucson".

The behavior of these terms can be modeled using the two-dimensional semantic framework. As before, when we consider a Twin Earth world as actual, it verifies "water is XYZ", and when we consider it as counterfactual, it satisfies "water is not XYZ". Likewise, when we consider a matrix world as actual, it verifies "hair is made of bits", and when we consider it as counterfactual, it satisfies "hair is not made of bits".

The difference between considering as actual and counterfactual yields a perspective shift like the one in the response to objection 5. If the matrix world is considered as merely counterfactual, we should say that the beings in the matrix don't have hair (they only have virtual hair). But if the matrix world is considered as actual (that is, if we hypothetically accept that we are in a matrix), we should say that the beings in the matrix have hair, and that hair is itself a sort of virtual hair.

The twin-earth analogy may suggest that the meanings of our terms such as "hair" and the contents of our corresponding thoughts depends on our environment. But the two-dimensional approach also suggests that there is an internal aspect of content that is shared between twins, and that does not depend on the environment. The _primary_ intension of a sentence is true at a world if the world verifies the sentence, while its _secondary intension_ is true at a world if the world satisfies the sentence. Then Oscar and Twin Oscar's sentence's "water is wet" have different secondary intensions (roughly, true when H 2 O is wet or when XYZ is wet respectively), but they have the same primary intension (roughly, true at worlds where the watery-looking stuff is wet). Likewise, "I have hair" as used me and my envatted counterpart has different secondary intensions (roughly, true at worlds where we have biological hair or computational hair respectively), but they have the same primary intension (roughly, true at worlds where we have hair-looking stuff). The primary intensions of our thought and our language represents a significant shared dimension of content.

**Note 9**: Why the different response to objection 7, on "action" and "friend"? We noted earlier (note 1) that not all terms function like "water" and "hair". There are numerous _semantically neutral_ terms that are not subject to Twin Earth thought-experiments: any two twins using these terms on different environments will use them with the same meaning (at least if they are using the terms without semantic deference). These terms arguably include "and", "friend", "philosopher", "action", "experience", and "envatted". So while an envatted beings' term "hand" or "hair" or "Tucson" may mean something different from our corresponding term, an envatted beings' term "friend" or "philosopher" or "action" will arguably mean the same as ours.

It follows that if we are concerned with an envatted being's belief "I have friends", or "I perform actions", we cannot use the Twin-Earth response. These beliefs will be true if and only if the envatted being has friends and performs actions. Fortunately, it seems quite reasonable to say that the envatted being _does_ have friends (in its environment, not in ours), and that it does perform actions (in its environment, not in ours). The same goes for other semantically neutral terms: it is for precisely this class of expressions that this response is reasonable.

**Note 10**: What is the ontology of virtual objects? This is a hard question, but it is no harder than the question of the ontology of ordinary macroscopic objects in a quantum-mechanical world. The response to objection 6 suggests that in both cases, we should reject claims of token identity between microscopic and macroscopic levels. Tables are not identical to any object characterized purely in terms of quantum-mechanics; likewise, virtual tables are not identical to any objects characterized purely in terms of bits. But nevertheless, facts about tables supervene on quantum-mechanical facts, and facts about virtual tables supervene on computational facts. So it seems reasonable to say that tables are constituted by quantum processes, and that virtual tables are constituted by computational processes. Further specificity in either case depends on delicate questions of metaphysics.

Reflecting on the third-person case, in which we are looking at a brain in a vat in our world, one might object that virtual objects don't really exist: there aren't real _objects_ corresponding to tables anywhere inside a computer. If one says this, though, one may be forced by parity into the view that tables do not truly exist in our quantum-mechanical world. If one adopts a restricted ontology of objects in one case, one should adopt it in the other; if one adopts a liberal ontology in one case, one should adopt it in the other. The only reasonable way to treat the cases differently is to adopt a sort of contextualism about what counts as an "object" (or about what falls within the domain of a quantifier such as "everything"), depending on the context of the speaker. But this will just reflect a parochial fact about our language, rather than any deep fact about the world. In the deep respects, virtual objects are no less real than ordinary objects.

**Note 11**: The response to objection 8 is reminiscent of the familiar point, associated with Russell and Kant, that we do not know the intrinsic nature of entities in the external world. When it comes to physical entities, perception and science may tell us how these entities affect us, and how they relate to each other, but these methods tell us little about what the fundamental physical entities are like in themselves. That is, these methods reveal the causal structure of the external world, but they leave its intrinsic nature open.

The Metaphysical Hypothesis is in part as a hypothesis about what underlies this microphysical causal structure: microphysical entities are made of bits. The same goes for the Matrix Hypothesis. One might say that if we are in a matrix, the Kantian ding-an-sich (thing in itself) is part of a computer-an-sich! This hypothesis supplements our ordinary conception of the external world, but it does not really contradict it, as this ordinary conception is silent on the world's intrinsic nature.

**Note 12**: One general moral is that the "manifest image" is _robust_: our ordinary conception of the macroscopic world is not easily falsified by discoveries in science and metaphysics. As long as the physical world contains processes with the right sort of causal and counterfactual structure, then it will be compatible with the manifest image. Even a computer simulation has the relevant causal and counterfactual structure, as does a process in the mind of God: this is why they can support a robust external reality, despite their surprising nature.

This sort of flexibility in our conception of the world is closely tied to the semantic non-neutrality of many of our concepts. Those concepts, such as "water", "hair", and "electron", leave some flexibility in what their referent might turn out to be. We conceive of their referents roughly as whatever actual entity plays a certain causal role, or has a certain appearance, while leaving open their intrinsic nature. One can likewise argue that the strongest constraints imposed by our conception of the world are plausibly those associated with semantically neutral concepts, which do not yield this sort of flexibility. These concepts plausibly include many of our causal (and nomic) concepts, as well as many of our mental concepts. In these cases, we have a sort of "direct" grasp of how the world must be in order to satisfy the concepts. If so, then our causal and mental beliefs impose strong constraints on the way the actual world must be.

One can argue that our fundamental semantically neutral concepts are mental concepts ("experience", "belief"), causal concepts ("cause", "law"), logical and mathematical concepts ("and", "two"), and categorical concepts ("object", "property"). There are also many semantically neutral concepts that involve more than one of these elements: "friend", "action", and "computer" are examples. If this is right, then the fundamental constraints that our beliefs impose on the external world is that it contain relevant mental states (in ourselves and in others), and that it contain objects and properties that stand in relevant causal relations to each other and to the mental states. This sort of conception is weak enough that it can be satisfied by a matrix (at least if it is a multi-vat matrix, or if computationalism about the mind is true).

In my opinion, this issue about the fundamental constraints that our beliefs impose on the world is the deepest philosophical issue that arises from thinking about the matrix. If what I have said in this article is right, it is precisely because these constraints are relatively weak that many hypotheses that one might have thought of as "skeptical" turn out to be compatible with our beliefs. And it is this that enables us to mount some sort of response to the skeptical challenge. A little paradoxically, one might say that it is because we demand so little that we know so much.

**Note 13**: Why does a computer simulation of a world satisfy these constraints? The reason is tied to the nature of computation and implementation. Any formal computation can be regarded as giving a specification of (abstract) _causal structure_, specifying the precise manner of interaction between some set of formal states. To implement such a formal computation, it is required that the implementation have concrete states that map directly onto these formal states, where the pattern of (causal and counterfactual) interaction between these states precisely mirrors the pattern of interaction between the formal states (see Chalmers 1994). So any two implementations of the computation will share a certain specific causal structure. A computational description of the physical world will be required to mirror its causal structure down to the level of fundmental objects and properties. So any implementation of this computation will embody this causal structure (in transitions between implementing states, whether these be voltages, circuits, or something quite different). So insofar as our conception of the external world imposes constraints on causal structure that a real physical world can satisfy, these constraints will also be satisfied by a computer simulation.

(This relates to a point made by Hubert Dreyfus in his article in this collection. Like me, Dreyfus takes the view that most of the beliefs of inhabitants of a matrix will be true, not false. But Dreyfus suggests that many of their causal beliefs will be false: e.g. their general belief that "a physical universe with causal powers that makes things happen in our world", and perhaps their specific beliefs that germs cause disease, that the sun causes things to get warm, and so on. On my view, this suggestion is incorrect. On my view, the world of someone living in a matrix has real causation going on everywhere within it, grounded in the real causation going on in the computer. Virtual germs in the computer really do cause virtual disease in the computer. So when a matrix inhabitants say "germs cause disease", what they say is true.)

Of course the mental constraints also need to be satisfied. In particular, it is important that the causal structure stand in the right sort of relation to our experiences. But this constraint will also be satisfied when we are hooked up to a matrix. Constraints regarding other minds will be satisfied as long as we are in a multi-vat matrix, or if computationalism about the mind is true. In this way, a matrix has everything that is required to satisfy the crucial causal and mental constraints on our conception of the world.

**Note 14**: A possible line of objection to the argument in this paper is to argue somehow that there are _further constraints_ that our beliefs impose on the world that the Matrix Hypothesis does not satisfy. One could argue that a mere match in mental and causal structure is not enough. For example, one might argue that the world needs to have the right _spatial_ properties, where we have some sort of direct grip on what spatial properties are (perhaps because spatial concepts are semantically neutral). And one could suggest that the problem with the matrix is that its spatial properties are all wrong. We believe that external entities are arranged in a certain spatial pattern, but no such spatial pattern exists inside the computer.

In response, one can argue that these further constraints do not exist. It can be argued that spatial concepts are not semantically neutral, but instead are subject to Twin Earth thought-experiments. My student Brad Thompson has developed thought-experiments of this sort (Thompson 2003), involving a Doubled Earth where "one meter" refers to (what we call) two meters, an El Greco World where "square" refers to (what we call) rectangles, and so on. On this view, our spatial concepts pick out whatever manifold of properties and relations in the external world is causally responsible for our corresponding manifold of spatial experiences: in this respect, spatial concepts are analogous to color concepts. Here we do not have any "direct" grip on the basic nature of spatial properties. Instead, once again, the basic constraints are mental and causal.

This line of objection is tacitly engaged in section 9 of the paper, where I suggest that if there is a computational level underneath physics, then any implementation of the relevant formal computation could serve in principle as a realization of that level, without compromising physical reality. Perhaps an opponent might deny that there could be a computational level underneath physics, or at least might hold that there are constraints on what sort of implementation can serve. For example, they might hold that the implementing level itself must have an appropriate spatial arrangement.

I think that this line of response runs counter to the spirit of contemporary physics, however. Physicists have seriously entertained the idea that space as we understand it is not fundamental, but that there is an underlying level, not described in terms of ordinary spatial notions, from which space emerges. The cellular automaton hypothesis is just one such proposal. Here, what is crucial is simply a pattern of causal interaction. If physicists discover that this pattern is realized in turn by an entirely different sort of level with very different properties, they will not conclude that ordinary physical space does not exist. Rather, they will conclude that space is itself constituted by something nonspatial. This sort of discovery might be surprising and revisionary, but again no more so than quantum mechanics. And as with quantum mechanics, we would almost certainly not regard it as a skeptical hypothesis about the macroscopic external world. If this is right, then our conception of the macroscopic world does not impose essentially spatial constraints on the fundamental level of reality.

Similar issues arise with respect to time. In one respect time poses fewer problems than space, as the computer simulation in a matrix unfolds in time, in the same temporal order as time in the simulated world. So one cannot object that the relevant temporal arrangements are not present in the matrix, in the way that one could object that the relevant spatial arrangements are not present. So even if temporal concepts were semantically neutral, the Matrix Hypothesis could still vindicate our temporal beliefs. Still, I think one can make a case that our concept of external time is not semantically neutral (it is notable that physicists have entertained hypotheses on which temporal notions play no role at the fundamental level). Rather, it picks out that external manifold of properties and relations that is responsible for our corresponding manifold of temporal experiences. If so, then any computer simulation with the right causal structure and the right relation to our experience will vindicate our temporal beliefs, regardless of its intrinsic temporal nature.

**Note 15**: The reasoning in this paper does not offer a knockdown refutation of skepticism, as several skeptical hypotheses are left open. But I think it significantly strengthens one of the standard responses to skepticism. It is often held that although various skeptical hypotheses are compatible with our experiences, the hypothesis that there is a real physical world provides a simpler or better explanation of the regularities in our experiences than these skeptical hypotheses. If so, then we may be justified in believing in the real physical world, by an inference to the best explanation.

At this point is often objected that some skeptical hypotheses seem just as simple as the standard explanation: for example, the hypothesis that all our experiences are caused by a computer simulation, or by God. If so, this response to skepticism fails. But if I am right, then these "equally simple" hypotheses are not skeptical hypotheses at all. If so, then inference to the best explanation may work after all: all of these "simple" hypotheses yield mostly true beliefs about an external world.

The residual issue concerns the various remaining skeptical hypotheses on the table, such as the Recent Matrix Hypothesis, the Local Matrix Hypothesis, and so on. It seems reasonable to hold that these are significantly less simple than the hypotheses above, however. All of them involve a non-uniform explanation of the regularities in our experiences. In the Recent Matrix Hypothesis, present regularities and past regularities have very different explanations. In the Local Matrix Hypothesis, beliefs about matters close to home and far from home have very different explanations. These hypotheses as a whole have a sort of dual-mechanism structure that seems considerably more complex than the uniform-mechanism structures above. If this is right, one can argue that inference to the best explanation justifies us in ruling out these hypotheses, and in accepting the non-skeptical hypotheses above.

Even one thinks that some of these skeptical hypotheses offer reasonably good explanations of our experience, there is still a promising argument against global external-world skepticism in the vicinity. If I am right, all of these skeptical hypotheses are at worst _partial_ skeptical hypotheses: if they are correct, then a good many of our empirical beliefs will still be true, and there will still be an external world. To obtain a _global_ skeptical hypothesis, we have to go all the way to the Chaos Hypothesis. But this is a hypothesis on which the regularities in our experience have no explanation at all. Even an extremely weak version of inference to the best explanation justifies us in ruling out this sort of hypothesis. If so, then this sort of reasoning may justify our belief in the existence of the external world.

### References

Bostrom, N. 2003. Are you living in a computer simulation? _Philosophical Quarterly_ 53:243-55. http://www.simulation-argument.com.

Chalmers, D.J. 1990. How Cartesian dualism might have been true. http://consc.net/notes/dualism.html.

Chalmers, D.J. 1994. A computational foundation for the study of cognition. http://consc.net/papers/computation.html.

Dennett, D.C. 1978. Brainstorms. In _Where am I?_ MIT Press, 1978.

Putnam, H. 1975. The meaning of "meaning". In _Mind, Language, and Reality_. Cambridge University Press.

Putnam, H. 1981. _Reason, Truth, and History_. Cambridge University Press.

Searle, J.R. 1984. Can computers think? In _Minds, Brains, and Science_. Harvard University Press.

Thompson, B. 2003. _The Nature of Phenomenal Content_. Ph.D. dissertation, University of Arizona.

Wolfram, S. 2002. _A New Kind of Science_. Wolfram Media.
]]></description>
</item>
<item>
<title><![CDATA[Happiness Is Bullshit - by David Pinsof]]></title>
<link>https://www.everythingisbullshit.blog/p/happiness-is-bullshit</link>
<pubDate>Mon, 20 Oct 2025 05:15:02 -0300</pubDate>
<description><![CDATA[Title: Happiness Is Bullshit

URL Source: http://www.everythingisbullshit.blog/p/happiness-is-bullshit

Published Time: 2023-03-14T16:44:31+00:00

Markdown Content:
[![Image 1](https://substackcdn.com/image/fetch/$s_!unwg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03387551-d2c7-42d8-aba2-4b9a924a37cf_2500x1667.jpeg)](https://substackcdn.com/image/fetch/$s_!unwg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F03387551-d2c7-42d8-aba2-4b9a924a37cf_2500x1667.jpeg)

You might think you want to be happy. You get out of bed and go to work because it makes you happy. Or maybe your job sucks, and you wish you worked somewhere else—somewhere you’d be happier. Or maybe your job isn’t that important to you, it’s just a way to pay the bills, and the thing that really makes you happy is staring off into the distance and holding your arms out like the idiot in the photo.

Whatever it is you’re doing, your goal is to be happy. Right?

Wrong. You don’t want to be happy. Nobody wants to be happy. The idea that any of us are pursuing happiness, that it’s our most fundamental goal in life, is [bullshit](https://everythingisbullshit.substack.com/about). It’s contradicted by almost everything we do.

For example, here’s a list of problems with the idea that humans want to be happy:

1.   We know that if we savor every moment—every smile, every meal, every ray of sunshine—we will be happy. Yet we savor maybe 1% of our moments.

2.   We know that if we appreciate what we have, from the roof over our heads to the clothes on our backs, we will be happy. Yet we appreciate maybe 1% of what we have.

3.   Good news makes us happier than bad news. Yet we consume way more bad news than good news, even though we can’t do anything about the bad news, and even though there is [plenty of good news](https://www.amazon.com/Enlightenment-Now-Science-Humanism-Progress/dp/0525427570) available.

4.   Anger feels bad. Yet when we’re angry with our loved ones, we think about all the times they made us angry, which just makes us angrier. Why don’t we think about all the times they made us happy?

5.   We can delude ourselves into believing pretty much anything: the earth is flat, the world is run by a cabal of satanic pedophiles, etc. Yet we never delude ourselves into believing that everything is perfect and wonderful as it is.

6.   If we were actually pursuing happiness, we’d be very good at it by now, given our many years of practice. Yet [studies show](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.832.7041&rep=rep1&type=pdf) that we suck at it. We’re incredibly bad at predicting how happy things will make us or how long our happiness will last.

7.   There are vast bodies of scientific research that could help us stop sucking at happiness, like Positive Psychology, the science of happiness. Yet most people aren’t very interested in this research. It’s kind of boring.

8.   We work too much, and some of us [literally work ourselves to death](https://en.wikipedia.org/wiki/Karoshi), even though we’re well-aware that this makes us unhappy.

9.   Having a child [makes us less happy](https://oda.oslomet.no/oda-xmlui/bitstream/handle/10642/2428/995951post.pdf?sequence=1&isAllowed=y) and more stressed, and we know this, yet we do it anyways, often multiple times.

10.   We maintain relationships with assholes, even though it’s clear we’d be happier without those assholes in our lives.

11.   We constantly beat ourselves up, but we almost never give ourselves compliments.

12.   We complain about Twitter _on Twitter._

“But David,” you object, “I really do want to be happy. I might be bad at it, but I still want it!”

Sorry, that’s bullshit. To “want” something is to learn how to get it and take it when it’s available. But you don’t learn how to get happiness. You repeatedly do things that make you miserable. Happiness is available for the taking—just savor the moment or appreciate what you have—but you never take it. So in what sense do you really “want” happiness?

“But David,” you say, “being happy is hard. It takes a lot of work _._ I want to be happy, but I sometimes lack the _self-control_.”

Sorry, that’s bullshit too. The whole point of self-control is to help you tolerate short-term discomfort to achieve a long-term goal. But happiness is the _opposite_ of discomfort, and it _is_ your long-term goal (according to you). So why do you need self-control to tolerate being happy in order to achieve your long-term goal of being happy?

“But David,” you say, “what if human beings want deeper forms of happiness, like eudaimonia or self-actualization?”

Yea, that’s bullshit again. It’s not like being mad at our loved ones, ignoring good news about humanity’s progress, working ourselves to death, beating ourselves up, spending time with assholes, sleepwalking through life, and never appreciating what we have is all part of our master plan to achieve self-actualization.

The truth is, we’re animals—specifically, apes. Our brains are the product of evolution. It would be very strange if evolution made us want _happiness_ as our number one goal. Happiness is inside our heads—it’s not out there in the world. It has no connection to survival or reproduction, which kind of has to exist if we evolved to want it. Eudamonia and self-actualization make even less sense as evolved goals.

What we want, as apes, is much more straightforward.

We want sex. We want to be sexy. We want tasty yum yums for our face-holes. We want to [establish dominance](https://static.poder360.com.br/2022/11/Status-seeking-and-discontent-Petersen-et-al-2020.pdf), or we want to display submission. We want to stay warm, [avoid snakes](https://www.apa.org/pubs/journals/releases/xge-1303466.pdf), use tools, [support our tribes](https://bpb-us-e2.wpmucdn.com/sites.uci.edu/dist/1/863/files/2019/10/Clark-et-al-2019.pdf), not be on fire, [ascend social hierarchies](https://labs.la.utexas.edu/buss/files/2019/08/pride-and-shame-EHB-2019.pdf), form alliances, [show off our health and virtue](https://static1.squarespace.com/static/58e2a71bf7e0ab3ba886cea3/t/58ebb8a4db29d654dc9e80c6/1491843238863/2007+moral+virtues.pdf), nurture cute babies (preferably ones that share our DNA), and make people feel indebted to us ([so they’ll help us in the future when we’re sick or injured](https://www.sciencedirect.com/science/article/abs/pii/S1090513800000325)).

_These_ are the sorts of things we want—the things that helped our ancestors survive and reproduce. Not happiness.

Once we accept this fact, everything starts to make sense. Why do we read so much bad news? Because scary stuff can kill us and happy stuff can’t. Why are we bored by Positive Psychology? No sex or death in it. Why do we work too much? [Status anxiety](https://www.amazon.com/Status-Game-Position-Governs-Everything-ebook/dp/B08H7Y414K). Why do we simmer in anger and shitpost on Twitter? Dominance. Why do we beat ourselves up and stay friends with assholes? Submission. Why do we have kids, even though they make us miserable? Come on.

The actual motives of human primates are pretty unflattering, and we would prefer not to talk about them. That’s why we pretend that happiness (or [self-actualization](https://www.researchgate.net/profile/Jaimie-Krems/publication/317804884_Individual_Perceptions_of_Self-Actualization_What_Functional_Motives_Are_Linked_to_Fulfilling_One%27s_Full_Potential/links/59dfedd7aca272386b633f93/Individual-Perceptions-of-Self-Actualization-What-Functional-Motives-Are-Linked-to-Fulfilling-Ones-Full-Potential.pdf) or whatever) is the reason for everything we do. It’s the perfect PR story. We run cancer marathons not to show off our health and virtue, but because we find it “rewarding.” We help our friends not to make them feel indebted to us, but because we’re “happy” to do it. “So glad you could make it,” we say to the asshole. “Happy to take care of it,” we say to our boss. We tell people we want to be happy because it sounds good. Or at least, it sounds better than the truth.

“Okay David,” you say. “Let's assume you’re right, and I don’t want to be happy. Everything is bullshit, haha, I get it. There’s still this _feeling_ I have called happiness. I feel it when I look at a sunset or eat a delicious meal. That feeling is real, and it’s an important part of my life. How do you explain that feeling? And why does it _seem_ like I want it?”

Great questions! Now we’re getting somewhere.

First, we need to make a distinction between _happiness_ (enjoying stuff) and _motivation_ (wanting stuff). These are different things that live in[different parts of the brain](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2813042/). You can enjoy something without wanting it, and you can want something without enjoying it. For example, I enjoy meditating, but I never want to do it. Doomscrolling upsets me, but I often want to do it.

The big mistake we make is lumping happiness and motivation together. We assume that happiness is what _causes us_ to be motivated, and that without happiness, we’d just sit around all day doing nothing. This is wrong. Most of what we do doesn’t make us happy, but we do it anyways. We shlep, small-talk, run errands, and go through the motions, without a scintilla of enjoyment required. We don’t need happiness to motivate us, any more than a thermostat needs happiness to perform its function of keeping our homes at the right temperature.

So then what _do_ we need happiness for? Why does it exist? What is its job, exactly? The answer is complicated, [1] so we’ll need to use an analogy: a guessing game.

Your life is a guessing game that you play with the world around you. You’re constantly guessing how things will turn out for you: “Will they laugh at my joke?” “Will my paella taste good?” When you guess correctly, and things go as expected, you’re blasé—"nothing to see here, moving right along.” When you guess _in_ correctly, and things are _un_ expected, your brain starts firing on all cylinders. Emotions kick in.

Happiness is when you guess wrong, but in a good way. You thought people would roll their eyes at your dumb joke, but they’re howling with laughter. You thought the paella would taste like shit, but it’s a culinary miracle. Happiness rewires your brain so that you tell more jokes, cook more Spanish cuisine, or subscribe to this surprisingly insightful substack. Happiness is like your brain saying, “getting warmer.”

But that doesn’t mean you want to be happy. When you play a guessing game, your goal is not to maximize the number of times you hear the words “getting warmer,” is it? No, your goal is to guess the thing. That’s why it’s called a guessing game. If you can guess the thing on the first try, without any “getting warmers,” that’s a good thing. That’s what you’re going for.

So too with the guessing game of life. If you can guess how everything is going to turn out—jokes, paellas, whatever—you’re doing great. The more often people laugh at your jokes, the better you get at predicting what they will laugh at, and the better you get at telling jokes. But eventually, you stop needing the “getting warmers,” and you stop relishing the sweet sound of laughter. Joke-telling becomes rote and mechanical. You become the comic relief character, and that’s like your job now.

That’s why it _seems_ like you want to be happy. You’re chasing the sort of thing that made you happy _in the_ _past,_ when you first got the “getting warmer” signal, even if it no longer makes you happy now. All of the objects of your desire are associated with happy _memories,_ which creates the illusion that happiness is what all your desires have in common. But it’s not. The more you get what you want, the more predictable it becomes, and the less you enjoy it when you get it. You’re not pursuing happiness so much as chasing it away.

Now don’t get me wrong. Happiness is great. It serves a vital function. But it’s not what you think it is. It’s not a substance you’re directly pursuing, like food or water. It’s not the purpose of life, or even something you’re particularly interested in. You don’t want it, and even if you did want it, you couldn’t pursue it, because it’s unpredictable, and you can’t pursue something if you can’t predict it.

Happiness is an excuse, a placeholder, an illusion, a story we tell ourselves.

In other words, it’s bullshit.

(Still not convinced? Check out my follow-up post [here](https://www.everythingisbullshit.blog/p/happiness-is-bullshit-revisited).)

[1] Here’s a technical description of the model I’m imagining. The brain computes, using evolved and learned priors, which of various outcomes have the highest expected value ([in terms of fitness proxies](https://psyarxiv.com/mkde7/)). The higher the expected value of an outcome, the greater the motivation—i.e. the amount of attention and energy mobilized—to pursue it. “Happiness” is triggered by a positive prediction error. We feel happy when the actual value of an outcome turns out to be greater than its expected value. This error causes us to rapidly mobilize energy (if more energy is needed), rapidly relax (if energy is no longer needed), attend to (i.e. “savor”) the outcome, simulate it in working memory, determine which features were counterfactually unique to it, upweight those features’ expected value, and encode them in long-term memory. As a result, those unique features will appear more valuable to us (i.e. more energizing, more attention-grabbing) the next time we encounter them. This is just another way of saying that we are “positively reinforced”—i.e. the features that were counterfactually unique to the outcome now have a higher expected value than they did before. The more frequently we experience the outcome, the better we get at predicting its value based on its unique features (i.e. the prediction error decreases), and the less “happy” we feel when we experience it (i.e. the less attention and reinforcement is needed). Eventually, after many repetitions of this process, we stop “liking” the outcome while still continuing to “want” it: that is, we continue to value and pursue it but are no longer surprised by it, attentive to it, or further reinforced by it. This model is an amalgam of [the prediction error theory of dopamine](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/) and the [internal regulatory variable theory of motivation](https://www.researchgate.net/publication/237312482_15_Internal_Regulatory_Variables_and_the_Design_of_Human_Motivation_A_Computational_and_Evolutionary_Approach).
]]></description>
</item>
<item>
<title><![CDATA[]]></title>
<link>https://desystemize.substack.com/p/representation-and-uncertainty</link>
<pubDate>Mon, 20 Oct 2025 05:15:56 -0300</pubDate>
<description><![CDATA[Title: Representation and Uncertainty

URL Source: http://desystemize.substack.com/p/representation-and-uncertainty

Published Time: 2022-03-19T17:10:38+00:00

Markdown Content:
I.

> _As always when something is a prerequisite for itself, you have to proceed in a spiral. An approximate understanding of a small part of the subject makes it possible to grasp more of it, and thereby to revise your understanding of the initial beachhead. You need repeated passes over the topic, in increasing breadth and depth, to master it._
> 
> 
> -David Chapman, [Ontological Remodeling](https://metarationality.com/remodeling)

I want to talk about the modern crisis of meaning. With our powerful computers and modern scientific techniques and access to all sorts of media, why is it so hard to figure out what’s actually _true_? I think a major reason is a lack of emphasis on **representation**: that is, how we choose to describe the world in the first place. We evaluate effective representations and ineffective representations side-by-side without distinguishing between them, hoping that truthfulness for one maps to the other, and instead are left only with confusion.

This is a hard thing to talk about, because a “representation” is a concept that I must represent effectively to you. The whole problem is that we’re not used to talking about representational issues, but talking about representational issues is an example of a representational issue. So I can’t describe the problem to you without solving it; it’s a prerequisite for itself. As such, we’ll take Chapman’s advice and proceed in a spiral, insinuating our way towards the subject rather than rushing it head-on. (I’ll also have to gently mislead you for a while, though I promise to fix it before the end.)

We’ll start with just a single word:

> _Hrair: A great many; an uncountable number; any number over four._

It’s a word in Lapine, the language of the rabbits from Richard Adams’ _Watership Down_. Rabbits, Adams tells us, can’t count higher than four. It’s not that they only have memory for four things; Hazel, the leader of the novel’s band of rabbits, has more than four followers, and he knows all of their names. But rabbits never _represent_ things in groups higher than four. Anything more than four is _hrair_, a lot. For example, when Hazel and another rabbit, Blackberry, are discussing a diplomatic mission to another warren, Hazel says:

> “We’re agreed, then, that we ought to send an expedition to this warren and there’s a good chance of being successful without fighting. Do you want everyone to go?”
> 
> 
> “I’d say not,” said Blackberry. “Two or three days journey; and we’re all in danger, both going and coming. It would be less dangerous for three or four rabbits than for _hrair_. Three or four can travel quickly and aren’t conspicuous: and the Chief Rabbit of this warren would be less likely to object to a few strangers coming with a civil request.”

“Everyone” is a concept Hazel understands just fine, even though more than four rabbits are part of the “everyone” that lives in his warren. But if Hazel was asked exactly how many rabbits went into this “everyone”, he couldn’t say. What matters to him here is that four rabbits can travel more carefully than _hrair_ rabbits, whether _hrair_ ends up being five or ten or twenty. For the case of “how many rabbits ought to visit the other warren?”, there’s no need to count higher than four.

We can imagine cases in rabbit-world where _hrair_ isn’t sufficient. Suppose there’s a log that could be used like a see-saw to open up a new feeding ground, but requires at least eight rabbits sitting on one end to make it move. We tell Hazel to have his rabbits sit on one end to see what happens, and he responds “I’ve already tried having _hrair_ rabbits sitting on one end, and nothing happened.'' We ask him to follow a certain instruction:

> Get a group of _hrair_ rabbits. Have each of them choose a different rabbit not already in the group. This is two-_hrair_.

Two-_hrair_ ends up meaning “at least eight”. If Hazel’s band tries this and discovers that two-_hrair_ rabbits are enough to move the log, he may well decide that two-_hrair_ is a concept worth remembering. Does this mean Hazel learned to count to eight? Not really. He can’t tell in advance whether he has two-_hrair_ worth of rabbits, and he can’t reach the intermediate states of five to seven. But clearly, if Hazel remembers the trick of “when _hrair_ isn’t enough, try two-_hrair_”, he’s got something he didn’t have before. If it’s not the process of counting that’s changed for him, what did?

The word we’re reaching for is **ontology**, a jargony philosophy term that can be more or less understood as “the list of things in a category” or “the list of answers to a question.” Before, Hazel’s list of options for “how many of a certain thing is there?” was this: {one, two, three, four, _hrair_.} Now, it’s this: {one, two, three, four, _hrair_, two-_hrair_.} This isn’t the same thing as a list of _numbers_: numbers are distinct, whereas a _hrair_ group of rabbits might also have two-_hrair_’s worth of rabbits without anyone knowing it, because it wasn’t assembled through the pairing algorithm. In fact, two-_hrair_ is a lot less general than the other entries on the list, because it can only apply to rabbits that are working together and following the same rule. One, two, three, and four are numbers, _hrair_ is a numeric range, and two-_hrair_ is a numeric range that can only apply to rabbits.

The entries are conceptually quite different – but they’re _ontologically_ similar, because they’re used the same way. Two-_hrair_ is just a new answer that’s potentially available for questions of the form “how many—?”. Nothing says it has to behave like the other answers, or be available for all potential “how many—?” questions that come up. Take note of that asymmetry before continuing on: all numbers are answers to “how many—?” questions, but new answers to “how many—” questions don’t need to be numbers.

Speaking of “how many—?” questions, let’s ask two:

> Game A: Would you trade away four value-units for a 25% chance of having five value-units?
> 
> 
> Game B: Would you trade away four value-units for a 25% chance of having one thousand value-units?

A lot of modern discussion of uncertainty works by asking these sorts of questions and finding answers that are as objectively defensible as possible. I don’t want to get into that, so I deliberately chose payoffs extreme enough that the answers are pretty obvious. Game A stinks, whether the value units are dollars or candy bars; Game B is incredible unless you only have a few value-units and will instantly die without them (vials of insulin, for example). Imagine we’re all sitting around a picnic table, coming to a quick consensus, when a couple of rabbits hop nearby. We want to get their input, so we translate our questions into Lapine:

> Game A: Would you trade away four value-units for a 25% chance of having _hrair_ value-units?
> 
> 
> Game B: Would you trade away four value-units for a 25% chance of having _hrair_ value-units?

They look at us with their confused little bunny eyes and ask, “Sorry, why did you describe the same game twice?” Lapine cannot _represent_ the difference between Game A and Game B. Our work with two-_hrair_ won’t help: metaphysical value-units aren’t the same thing as conscious and cooperating rabbits, so we can’t run the process to get to two-_hrair_. And anyway, Game B would still stink if it ends up only being an eight value-unit payoff.

If we want the rabbits to understand our question, we’ve got to teach them our sort of counting, an algorithm that can be continually re-executed to produce an infinite ontology: {1,2, 3….1000…}. What’s the incentive we can give them for learning our method of counting—the equivalent of the log and the new feeding ground we used to teach them two-_hrair_? Can rabbits get any use out of playing these games? In what situations would they actually be offered the chance to trade away four value-units to get either five or one thousand? What are the value units in question? Do Game A and Game B show up in their lives via sufficiently different contexts that we can just refer to those contexts without teaching counting at all? Maybe something like an aphorism: “bargain a sure thing for _hrair_ with your friends, but never strangers.”

We can see that formal mathematical methods aren’t the right tool to fix the rabbit's understanding. Their difficulty is _ontological_, not logical: since Game A and B look the same to them, the application of any rabbit-scale formal method would yield the same answer. And given how different the two games are, a method that gives the same answer for both of them can’t be all that useful. Formal methods pre-suppose that nebulous reality has been described at the level of detail the method requires. It doesn’t matter how good your math is if you’re telling it to a rabbit.

If, for an audience of humans, I had gotten into the math of Game A vs. Game B, made their payoffs a little closer, used phrases like “expected value”, and maybe threw in an integral sign somewhere, it would have been a lot of work. So much work, in fact, that it’d be easy to imagine that pushing those numbers around is just a conscious representation of what our brains are doing subconsciously when we make decisions. But hopefully I’ve shown how a precise-enough understanding of the situation has to come first, before any sort of math. Formally solving uncertainty on _what to do_ only works if you can sensibly describe _what there is._

There’s another important point here, one that you might have started thinking about a couple of paragraphs back. I claimed that, in order to teach the rabbits our sort of counting, we’d have to ground it in their local context. But how did _we_ learn our sort of counting? Many people are comfortable reading Game A and Game B as they are, without relating them to a local context. You don’t _have_ to imagine dollars, or candy bars, or vials of insulin. The number “1000” feels meaningful even if it’s not 1000 of anything in particular. So saying “humans know how to count infinitely and rabbits don’t” is just kicking the can down the road as an explanation. The real difference is that humans are able to learn context-free information. Why is that?

_[Ignorance, A Skilled Practice](https://carcinisation.com/2020/01/27/ignorance-a-skilled-practice/)_, an essay written by [a literal banana](https://twitter.com/literalbanana), offers us the frame we need to explore this further. It’s an essay concerning **indexicality**, a word that, like ontology, sounds awfully jargony but isn’t so bad once you get to know it. Indexicality is essentially the degree to which local context matters for a given concept, though I’ll let the banana describe in more detail:

> “Indexical” is a word almost perfectly calculated to sap the morale of the reader and annihilate interest. I have seriously considered replacing it with the word “pointing,” used as a descriptor. Indexical statements are pointing statements: “_I_ prefer _this_ one,” “don’t do _that_,” “I made _it_ for _you_.” These sentences have no particular meaning without reference to the situation in which they are produced. Physical pointing, as with an index finger or the lips or chin, may or may not accompany an indexical expression, but there is a sort of _pointing-to-the-situation_ that occurs in all cases. I’ve decided to keep “indexical” for clarity, but keep in mind that indexical means pointing, in a literal and then in an extended, figurative way.
> 
> 
> In the linguistic sense, an expression is indexical if it refers by necessity to some particular state of affairs. “_This_ guy arrived just _now_” depends on the person indicated and the time of speaking; it is highly indexical. Compare “The Prime Minister arrived at 5:15 p.m.” This is less indexical, but notice that the identity of the Prime Minister depends on the country, and of course we don’t know anything about the circumstances or place of arrival from the text: 5:15 p.m., but in what time zone?
> 
> 
> Extremely non-indexical expressions often appear as health or science headlines. These are pretty much the opposite of indexicality:
> 
> 
> Stanford Researchers: Average Human Body Temperature Dropping
> 
> 
> How Puberty, Pregnancy And Perimenopause Impact Women’s Mental Health
> 
> 
> Why is air pollution so harmful? DNA may hold the answer
> 
> 
> Predatory-journal papers have little scientific impact
> 
> 
> Can a healthy diet reduce your risk of hearing loss? Here’s what the research says
> 
> 
> Notice that these refer to people in general, and vague concepts in general. They take the form of objective knowledge that is true in general, for all cases, globally, universally. They “see through” to the ultimate truth of matters, unsullied by the messy realities of particular people and situations. The kind of knowledge that _non-indexical_ statements presume to convey is timeless, and describes all of humanity or the world in general. _Indexical_ knowledge, on the other hand, refers to specific situations, times, people, and interactions. It does not purport to apply timelessly, in general, or to all people.

Indexical statements point at specifics; non-indexical statements describe generalities. “The number 3 is larger than the number 2” is non-indexical, and true in a general sense. “My two cats put together are heavier than your three cats put together” is highly indexical, and true for specific values of “my two cats” and “your three cats,” overriding the general “truth” that 3 is more than 2. “Average body temperature” is a non-indexical concept; but to guess at it, researchers can only measure the indexical body temperatures of certain people at certain times. Rabbits stay in the realm of the indexical, while humans are able to trade in non-indexical statements. Or, at least, some humans. Back to the banana:

> To illustrate that global knowledge is a game, consider a story about Alexander Luria, who studied illiterate Russian peasants and their semi-literate children. Consider especially[this version](http://lchc.ucsd.edu/mca/Mail/xmcamail.2014-12.dir/pdfYCNJw48XtW.pdf) of the story, prepared in the 1970s to provide morale and context to reading teachers (John Guthrie, 1977). Essentially, Luria discovered that the illiterate, unschooled peasants were highly resistant to syllogisms and word games. The adult peasants would only answer questions based on their own knowledge, and stubbornly refused to make deductions from given premises. “All bears are white where it is snowy. It is snowy in Nova Zembla. What color are the bears in Nova Zembla?” “I don’t know, I have never been to Nova Zembla.” Children with only a year or two of education, however, were easily able to engage in such abstract reasoning. They quickly answered the syllogisms and drew inferences from hypothetical facts outside of their own observation.
> 
> 
> In this story, I argue, Luria’s peasants are _indexical geniuses_, who refuse to engage in unproven syllogistic games. They are not interested in a global, universal game. Their children, however, are easily introduced to this game by the process of schooling and literacy.

The Russian peasants, like the rabbits, want to keep their observations grounded in context. Whether they’re worried about a trick, too proud to risk giving a wrong answer, or just plain suspicious of Luria, they don’t want to suppose the existence of global, non-indexical concepts like “all bears are white where it is snowy” (never mind things as abstract as Game A and Game B!) I’m not quite as adamant as them—I think there can be a lot of value in drawing inferences from unobserved information. But it’s true that both human beings and rabbits are highly indexical beings, who perceive _this_, do _that_, _here_ and _now_. If you want to use non-indexical findings in your indexical life, you have to make sure they actually fit your context.

From our perspective, rabbits and peasants have some extra work they need to do before they can talk about these formal games like we do; they need to be able to become more comfortable with abstractions and language that doesn’t refer to concrete things out in the world. If you ask the rabbits and the peasants, though, we have an extra step we need to do _after describing_ our formal games. Because we let ourselves play around with concepts that we couldn’t actually point to, we have no guarantee that our findings will actually come up in our lives like they do for rabbits and peasants. Non-indexicality lets us take a sort of loan of meaning, playing with tools that aren’t available in the here and now to broaden the ways we can think about things. But that loan has to be paid off eventually through **correspondence** work showing that the abstract objects you were acting on are similar enough to what actually exists in a particular situation for the finding to be valid. Otherwise, you’ve just been playing a meaningless game that has no bearing on actual reality.

I would argue that rabbits and Russian peasants are not indexical geniuses but indexical _misers_, unwilling to take on any sort of meaning-debt. To speak of the white bears in Nova Zembla is to become beholden to two abstracts—“All bears are white where it is snowy” and “it is snowy in Nova Zembla.” How would you pay down that debt? Bears are real animals, snow is real, and Nova Zembla is a real place: they aren’t just counters in a logic puzzle. It’d be a big trip to go to Nova Zembla, and maybe it’s only snowy part of the year. What if you go at the wrong time? Who can prove anything about “all bears where it is snowy”, anyway? Has someone been to every snowy place and met every bear? What if the non-white bears were asleep? Do they have a checklist that gets updated every time a new bear is born? Why deal with any of this shit when you could just say “I don’t know, I have never been to Nova Zembla” and get on with your life?

Just like monetary debt, allowing yourself to take on meaning-debt temporarily can let you access new heights and then pay the debt down and end up somewhere better. Every time a novel theory in physics is confirmed by experiment, meaning-debt proves its worth. But also like monetary debt, meaning-debt can ruin your life if you’re not careful, and you’re not exactly _wrong_ to decide it’s not worth the risk. The peasants may be constraining their range of possible thoughts by focusing solely on the here and now, but they’re also guaranteeing that the things they think about will have an impact on their actual lives. If you develop formal theories without checking for _heres and nows_ that behave in the way your theory describes, you may be throwing more and more of your time into a compounding interest hole of meaninglessness.

Statements about value-units are non-indexical, which just means that we’re not pointing at anything in particular when we talk about them. By contrast, if I was deciding whether to trade four french fries now for a 25% chance to get one thousand french fries for lunch tomorrow, that would be a highly indexical decision, because it’s drenched in my local context. It would also be a highly indexical decision to trade four grand pianos now for a 25% chance to get one thousand grand pianos tomorrow. But maybe my answers for those two are different—I’ll take the gamble on the fries because I’m not hungry now anyhow, but I hardly have anywhere to put the four grand pianos while I sell them, never mind one thousand.

This difference shows us the meaning-debt that we incur from non-indexical phrases like “value-units”. If we want to use our findings from Game A and Game B in our lives, we first need to do correspondence work to find whether french fries behave enough like value-units that the findings are applicable, and the same for grand pianos, and the same for anything else. In one sentence: there are possibilities we can conceive of solely because our ontologies can include things we can’t directly point to, but this power comes with the debt to make them point to something later.

II.

Our next step is to see the meaning-debt the peasants were afraid of. What do problems of representation look like? We’ll turn to humorism as an example. Some ancient medical theorists thought that most illnesses could be explained by an excess or deficit of the four humors: {blood, phlegm, yellow bile, black bile}. We’ll imagine a Hippocratic hardliner who thinks this explains everything. That is, every single illness is caused by either too little or too much blood, phlegm, yellow bile, or black bile. (I don’t know how many historical physicians actually believed in humorism this strongly, so don’t treat this illustrative example as an especially accurate historical recounting. Also, it’s going to get worse.)

We know now that humorism isn’t true. Illnesses can be caused by viruses or bacteria or environmental contamination or all manner of other things. But the “humors” aren’t entirely arbitrary concepts, either. The illness is caused by whatever it’s caused by, different illnesses cause different symptoms, and if the humorist diagnostic criteria consistently classifies the same symptoms the same way, the humors “listen to” the true causes in a partial, indirect way.

Suppose a patient named Artemis has some set of symptoms—maybe a deep cough and a splitting headache, or whatever. All of the ancient physicians she runs into agree that she must have an excess of phlegm with the other humors in balance (“phlegmatic” for short). What does the statement “Artemis is phlegmatic'' actually mean, knowing what we know now about medicine? It’s not pointing at Artemis’s excess of phlegm, because we know now that bodies don’t work this way and there’s no actual excess of phlegm to point to. But it’s not exactly _false_ to say “Artemis is phlegmatic”, because it has a meaning to the people who say it and Artemis is a patient they all agree qualifies. It’s _indexical_, because it’s pointing to a real thing, but that doesn’t mean it’s _true_. We’ll need to understand this fussy-sounding distinction to go farther, so we’ll inject enough context that the difference becomes clear.

Let's say that modern medical historians have determined that just two diseases caused people to be phlegmatic in the ancient world: city cough (caused by the bacterium _c. urbanicus)_ and country cough (caused by the bacterium _c. pastorilus_). You catch city cough in close proximity to other people, and it’s cured by simply increasing intake of sugars and meat—the traditional cure was drinking mulled wine and eating bull testicles—but gets dramatically worse if you have any contaminated food or drink. Country cough gets in your lungs from disturbed soil, and the solution is to beef up your microbiome—traditionally done by drinking brackish water and eating a handful of grave dirt—but it spirals out of control if you eat and drink normally, and god help you if you eat some bull testicles.

Remember that these (imagined) Hippocratic hardliners don’t think of “city cough” or “country cough” as ailments. They think that a phlegmatic patient has an excess of phlegm and that’s the sole reason for their problems. It just so happens, though, that doctors tend to either be city doctors or country doctors, and tend to see cases of city cough or country cough but not both. The city doctors have their regular hookups for bull testicles, country doctors know the perfect graves to skim dirt off of, and the literature tactfully equivocates with “Some doctors recommend mulled wine and bull testicles to cure an excess of phlegm, while others prescribe a course of brackish water and grave dirt.”

Artemis, though, is a bit of an interesting case. She lives on the outskirts of town, spending a fair amount of time in the field but also making frequent trips to the city. So when she wanted to get multiple opinions, she ended up asking one doctor who works in the city—Dr. House—and one who works out in the country—Dr. Field. Dr. House naturally suggests the wine and ball combo, to which Dr. Field indignantly replies, hey, I agree that she’s phlegmatic, but that’s precisely WHY the extra food and drink is a huge problem—we need to get her on brackish water and grave dirt, stat.

When Dr. House says “Artemis is phlegmatic,” he’s relating her to the patients he’s seen previously that got better when they drank mulled wine and ate bull testicles. Why did they drink mulled wine and eat bull testicles? Because he told them to. Why did he tell them to? Because they seemed a certain way. Artemis also seems that certain way, and so Dr. House wants to treat her the same way he treated the other patients, by giving her mulled wine and bull’s testicles. If Artemis seemed a different way, he wouldn’t expect mulled wine and bull testicles to help.

When we ask if something is true or not, this is ultimately what we want to get to: the _difference in outcomes for an intervention_. Mulled wine and bull testicles work great for some patients and do nothing or are actively harmful for others. Dr. House wants to say “Give mulled wine and bull testicles to the patients for whom they will help, and don’t give them to the patients for whom they will not help.” If he had never met another doctor in his life, and felt no need to justify himself to any patients, he could hold this idea in his head without needing explicit concepts. His personal experience would be enough to have an intuition of “the sort of patient” to give mulled wine and bull testicles to, and he could use that as his guide. This is a normal and very human thing to do.

But that doesn’t cut it when you want to socialize this difference, whether it’s for formal diagnostic rules or just idle banter with colleagues. Dr. House wants to _compare_ his findings with his peers. He wants to _explain_ his reasoning to his patients. He wants to _document_ his actions for future reference. To do any of these, he needs to be able to _point at the difference in interventions_. But how can he do that? He can’t describe every single thing he noticed in each patient he’s seen. And he can’t point at _c.urbiancius_ itself, because he doesn’t know what that is. He needs a named concept he can point to when he _means_“look at this difference between patients who got better with mulled wine and bull testicles and those who didn’t.”

This is where the tangle of meaning happened. Dr. House and Dr. Field are trying to point to two separate differences—the difference in outcomes for mulled wine and bull testicles vs. the difference in outcomes for brackish water and grave dirt. They each needed a way to describe that, and were used to the background framework of humorism saying that symptom profiles are all you need to describe the differences in interventions. So they both pointed to “phlegmatic”, without adding in the additional context of city vs. country. In the act of formalizing _how_ one points to phlegmatic, they inadvertently destroyed the _why_ of pointing to phlegmatic. It’s not that they were wrong to try, since the differences they were pointing to can be used to improve human health when used correctly. But their framework of “what constitutes an explanation for a difference?” was too rigid, and so patients that look the same in their framework may not respond the same way to a given intervention.

Let’s repeat our summary of part I:

> There are possibilities we can conceive of solely because our ontologies can include things we can’t directly point to, but this power comes with the debt to make them point to something later.

Now, we’ll reframe it:

> There are _differences_ we can only point to because our ontologies can hold abstract concepts, but pointing to these concepts comes with the obligation to make sure these differences are really there when we point at the concept.

This is the meaning-debt the indexical misers were desperate to avoid. In formalizing the idea of “phlegmatic” enough that the two doctors agree that Artemis is phlegmatic, it melded together the differences that each doctor imagines they’re pointing to. “Artemis is phlegmatic” is indexical in the sense that “How do you point to the concept ‘phlegmatic’?” has a shared understanding among physicians. But while it’s indexical, it’s not completely _meaningful_, because not all uses of the word are pointing at the same difference.

If their language had been refined enough to say “city phlegmatic” and “country phlegmatic”, then the meaning-debt could potentially be paid off, since “city phlegmatic” would be pointing at _c. urbanicus_ and “country phlegmatic” would be pointing at _c. pastorilus_. Alternatively, if each doctor had stuck squarely to their own terrain and never interacted with an in-betweener like Artemis, it also would have worked out fine. “Phlegmatic” would be pointing to separate differences in the minds of Dr. House and Dr. Field, but each individual use of the word “phlegmatic” would be pointing to what it means to point to.

So it’s not the word “phlegmatic” itself that goes into meaning-debt or not. Instead, it’s the _difference being pointed to_ that incurs the debt when you conceptualize it and try to make something in the world point at it. You pay this debt off when your conceptualization successfully points back to your difference, and the payoff is being able to use that difference in your real, indexical life. If Dr. House had demurred and said “I don’t know, I’ve never treated a patient outside the city center”, then “phlegmatic” would be simultaneously a meaningful word for him (because it always points to a specific difference, the difference in outcomes of interventions for patients with _c. urbanicus_, when he uses it) while being a bankrupt word for Dr. Field, who overstepped his boundaries too far by presuming the lived experiences of his previous patients applied to Artemis.

In other words, representations are inevitable, and the challenge is to make sure the representations are meaningful with respect to the differences in the world you’re trying to interact with. “Phlegmatic” as a representation carries with it some degree of unrepresented baggage that Artemis won’t be aware of when she hears “you’re phlegmatic”. The doctors who are trying to explain real differences have the job of trying to hold that unrepresented baggage constant enough that their past experience of exploiting those differences applies the same way to the same representation. Since words are just tools that one can use well or poorly, different people may incur different levels of meaning-debt when using the same representation. Once you get practice thinking this way, you’re able to be much more precise about what’s actually going wrong when looking at failures of representation.

Practice! That’s what we need. Here, I’ll send you back to the ancient world using my time machine. Plus side: I’ve also given you a solar-powered laptop capable of running modern machine learning models, so you have raw computational power on your side. Minus side: they think you’re a god of healing and believe they’ll be destroyed if they ever see you or hear you speak, so they’ve locked you in a room. They slide a clay tablet under the door that includes the patient’s humors and a list of possible interventions—mulled wine and bull testicles, brackish water and grave dirt, and many others besides. You mark the tablet by the intervention you want them to do and send it back. Later, they send an offering and another tablet showing how the patient ended up faring.

As you get more data to train your machine learning model, you’ll be able to improve outcomes and eventually choose the “best” outcome for each humor state. But it’d fall way short of modern medicine, because even with modern computational power, you wouldn’t have modern _ontological_ power. You don’t know whether these patients live in the city or the country, because your worshipers think the humors explain everything and don’t put other details on the tablet. And your model will be brittle, because it doesn’t have any theory to inform it when conditions change. If cities expand their borders, so that more patients get city cough and fewer patients get country cough, you won’t be able to _predict_ that in advance. You'll just notice that brackish water and grave dirt start doing worse and worse for phlegmatic patients and phase it out, chasing the trend after the fact.

How would this look from the perspective of the ancient doctors who are tracking the success rate of their god? They probably don’t know that they’re being roadblocked on their representational vagueness. Ontological difficulties are pretty subtle, especially in systems as complex as the human body. It’s extremely easy to be satisfied with a probabilistic conclusion like “if the patient is phlegmatic, then mulled wine and bull testicles will save them 75% of the time” and assume that’s the _whole_ answer, even if they could save _everybody_ by distinguishing city cough from country cough.

What if I had sent a Russian peasant through my time machine instead of you? What does an indexical miser do when they see a tablet come under that door? “I don’t know, I’ve never met this person,” and slide the tablet back without a mark. Eventually the doctors assume that their god is displeased and stop sending the tablets. Was this the responsible thing to do? Probably not. After all, the humors at least _partially_ point to something real. Even if you can’t get to 100% by distinguishing between city cough and country cough, it’s at least better than random chance, right?

This argument is a common one when people are faced with representational issues: you can only do the best you can with the data you have. I want to push back strongly against that framing. Because in order to make the indexical miser look unreasonable, I had to create a completely locked door, a strictly one-way flow of information, a representation of a patient you can take or leave but never change or look at in more detail. In real life, of course, you can open the door.

That’s the moral of the story. I’ll repeat it.

_In real life, you can open the door._

Whenever you’re given a word you think isn’t pointing to a difference, you can ask: what will you do differently depending on whether this patient is phlegmatic or not? You can ask people to give you stories instead of data. You can try recording things in different ways. If a modern epidemiologist was sent back, but allowed to open the door, their most powerful technology would be their _checklists_, asking more relevant questions than anyone back then would have thought to ask. Do you use a wood stove? Do your children spend significant amounts of time in the basement? Do you use earthen-ware pottery? And eventually, they’d get to: do you live in the city, or the country? When you see the relative impact of mulled wine and bull testicles vs brackish water and grave dirt, _split out by city vs. country_, you simply don’t need modern computing power to figure out what’s happening. It’s plain as day, right in front of you.

Let me pull you back to the present day and show you something. {Four, _hrair_, two-_hrair_} – remember how these were different conceptual things that were only similar ontologically? Well, here’s two words from our modern ontology of diseases. One is cholera, here defined from the[World Health Organization](https://www.who.int/news-room/fact-sheets/detail/cholera):

> Cholera is an acute diarrhoeal infection caused by ingestion of food or water contaminated with the bacterium Vibrio cholerae…The majority of people can be treated successfully through prompt administration of oral rehydration solution (ORS)… Severely dehydrated patients are at risk of shock and require the rapid administration of intravenous fluids.”

The second is fibromyalgia, here defined by the[National Institutes of Health](https://www.niams.nih.gov/health-topics/fibromyalgia):

> Fibromyalgia is a long-lasting disorder that causes pain and tenderness throughout the body. It also can cause you to feel overly tired (fatigue) and have trouble sleeping. Doctors do not fully understand what causes fibromyalgia, but people with the disorder are more sensitive to pain… Treatment may include exercise or other movement therapies, mental health and behavioral therapy, and medications.

Cholera and fibromyalgia are similar ontologically, in that a doctor might say “you have {cholera/fibromyalgia} and I’m going to prescribe a treatment based on that.” They’re very different conceptually, though. Cholera is caused by a specific bacterium, _vibrio cholerae_. It leads to consistent symptoms that clear up with consistent treatment. We’re pointing at the difference between people who immediately get better when given fluids and people who don’t, and saying that one way you could name that difference is “cholera.” How do we make that indexical? We have microscopes now. We can _literally point at vibrio cholerae_. The word “cholera” pays off its meaning-debt when we point and say “_this_ _vibrio cholerae, here and now_.”

But what is “fibromyalgia” pointing at? An understanding that many people are experiencing similar symptoms. It behaves more like “phlegmatic” did, where patients described in the same way might respond dramatically differently to the same treatment. It’s more useful than not having a word, because patients with fibromyalgia are more similar to each other than they are to people without fibromyalgia. It’s a hook we can use to begin to investigate a difference. “Fibromyalgia” _describes_ uncertainty, but doesn’t _terminate_ it in the way that “cholera” does.Could the word “fibromyalgia” be made more useful? How much is studying the impact of various treatments on “fibromyalgia” going to serve us until we clarify our understanding of “fibromyalgia”? Can you truly compare the outcomes of two studies on “fibromyalgia” if one is city fibromyalgia and one is country fibromyalgia?

Imagine future scholars looking back at you. What issues are we trying to fix with our current verbiage that will have people from the future thinking, “Well, if I traveled back to their time, I wouldn’t show them our superior computational ability—I’d show them our superior ontology”? Will people in the year 2100 use the word fibromyalgia at all? Or will “fibromyalgia” be replaced by a number of words for different causes of pain and fatigue, each with their own corresponding treatment?

And when you do have a word that seems like it’s not pointing properly—how should you think about it in the meantime? How do you make your strategies for uncertainty account for the fact that even your representations are uncertain?

III.

What we need now is an example of effective decision-making that avoids our pointing problems. If you want to investigate decision-making in areas of high uncertainty and urgency, it’s hard to beat talking to firefighters. In _Sources of Power, 20th Anniversary Edition: How People Make Decisions,_ researcher Gary Klein and his team recount the surprising conclusions they came to after studying firefighters:

> We thought this hypothesis—that instead of considering lots of options they would consider only two—was daring. Actually, it was conservative. The commanders did not consider two. In fact, they did not seem to be comparing any options at all. This was disconcerting, and we discovered it at the first background discussion we had with a fireground commander, even before the real interviews. We asked the commander to tell us about some difficult decisions he had made.
> 
> 
> **“I don't make decisions,” he announced to his startled listeners. "I don't remember when I’ve ever made a decision.”**
> 
> 
> For researchers starting a study of decision making, this was unhappy news. Even worse, he insisted that fireground commanders never make decisions. We pressed him further. Surely there are decisions during a fire—decisions about whether to call a second alarm, where to send his crews, how to contain the fire.
> 
> 
> **He agreed that there were options, yet it was usually obvious what to do in any given situation.** We soon realized that he was defining the making of a decision in the same way as Soelberg’s students—generating a set of options and evaluating them to find the best one. We call this strategy of examining two or more options at the same time, usually by comparing the strengths and weaknesses of each, comparative evaluation. He insisted that he never did it. There just was no time. The structure would burn down by the time he finished listing all the options, let alone evaluating them. [Emphasis mine.]

Not making any decisions about how to fight fires is something that me and this fireground commander have in common. But if I was in charge of leading a fire response, the outcome would be a lot worse. The fireground commander is the highest ranking person on the scene of the fire, and must have been chosen to do _something_ relating to fires better than I would. If it’s not decision-making, what is it?

Let’s imagine that there’s a flowchart in the fireground commander's head declaring exactly what to do in any circumstance. “If it’s a big fire, only attack it from outside with hoses. If it’s medium size, go in and evacuate people, but only if you can do it in five minutes” —those sorts of rules. When the fireground commander says “he doesn’t make decisions,” he’s saying that the flowchart never invokes “decide between these options.” You always just follow what the chart does. If the fireground commander managed to get the flowchart out of his head and onto paper, would I then be able to follow it and fight fires as well as he does?

Let’s try. When does a fire go from “medium” to “big”? I have no clue. I can observe a _here_ and a _now_, and I can have a completely well-defined flowchart of decision-making, but in order to make that _here_ and _now_ talk to the flowchart, I have to do correspondence work to make sure I’m mapping the world to the right part of the flowchart. This is the exact inverse of the problem that Drs. House and Field struggled with. They had a systemic, well-agreed upon method of determining which patients were phlegmatic, but they had two different flowcharts in their heads that were thinking of two differences in interventions when they said “phlegmatic”. The fireground commander’s representations are meaningful with respect to the differences: _big_ fires are the ones you don’t get in the house for. Instead, the problem is looking at the real world with its infinite supply of detail and knowing which concept to point to.

In some domains, this isn’t such a big deal. In a chess game, for example, the rules _assert_ that the detail of the world can be abstracted away, that a king piece made of young wood is the same as a king piece made of old wood. In fires, it’s entirely possible that the age of this particular wood is going to matter a great deal, as will the moisture in the air, the ambient temperature, the construction of the floor—you get the idea.

Still, it feels like we should be able to get the best of both worlds here. Let’s figure out an objective, agreed-upon way to pick a state for a fire, just like Drs. House and Field had an agreed-upon way to pick a humor for a patient. And we’ll make sure those states map to the fireground commander’s decision-free flowchart. As long as you have those two guarantees, you don’t need the fireground commander at all. In fact, you could fight the fire with your eyes closed! Just have someone describe the fire to you in the agreed-upon way, run through the flowchart in your head, and tell them the answer.

Fighting fires with your eyes closed sure would be nice. We should probably get a more concrete example of how fireground commanders point to see how we’d go about doing it. This time I don’t even have to make up the scenario! Let’s look at this full-length anecdote from _Sources of Power:_

> Example 4.1 The Sixth Sense
> 
> 
> It is a simple house fire in a one-story house in a residential neighborhood. The fire is in the back, in the kitchen area. The lieutenant leads his hose crew into the building, to the back, to spray water on the fire, but the fire just roars back at them.
> 
> 
> “Odd,” he thinks. The water should have more of an impact. They try dousing it again, and get the same results. They retreat a few steps to regroup.
> 
> 
> Then the lieutenant starts to feel as if something is not right.
> 
> 
> He doesn’t have any clues; he just doesn't feel right about being in that house, so he orders his men out of the building—a perfectly standard building with nothing out of the ordinary.
> 
> 
> As soon as his men leave the building, the floor where they had been standing collapses. Had they still been inside, they would have plunged into the fire below.
> 
> 
> “A sixth sense,” he assured us, and part of the makeup of every skilled commander. Some close questioning revealed the following facts:
> 
> 
> • He had no suspicion that there was a basement in the house.
> 
> 
> • He did not suspect that the seat of the fire was in the basement, directly underneath the living room where he and his men were standing when he gave his order to evacuate.
> 
> 
> • But he was already wondering why the fire did not react as expected.
> 
> 
> • The living room was hotter than he would have expected for a small fire in the kitchen of a single-family home.
> 
> 
> • It was very quiet. Fires are noisy, and for a fire with this much heat, he would have expected a great deal of noise.
> 
> 
> The whole pattern did not fit right. His expectations were violated, and he realized he did not quite know what was going on. That was why he ordered his men out of the building. With hindsight, the reasons for the mismatch were clear. Because the fire was under him and not in the kitchen, it was not affected by his crew’s attack, the rising heat was much greater than he had expected, and the floor acted like a baffle to muffle the noise, resulting in a hot but quiet environment.
> 
> 
> This incident helped us understand how commanders make decisions by recognizing when a typical situation is developing. In this case, the events were not typical, and his reaction was to pull back, regroup, and try to get a better sense of what was going on. By showing us what happens when the cues do not fit together, this case clarified how much firefighters rely on a recognition of familiarity and prototypicality. By the end of the interview, the commander could see how he had used the available information to make his judgment.

This anecdote is often repeated outside the pages of _Sources of Power_ to describe the “power of intuition.” But what do we mean by intuition, anyway? When I walk into a room and notice that it’s quiet, that’s not intuition, just observation. The impressive part is that the fireground commander recognized the situation was atypical without knowing why, which allowed him to act on a fact (the room was too quiet for how hot the fire was) without actually being able to describe the specific fact he was acting on. He didn’t point to “too quiet”; he pointed to “not normal,” and only figured out the “too quiet” part reflecting after the fact. This almost seems like cheating after all of our hard work. We’re trying to figure out the right way to call a fire “too quiet,” because in our flowchart, “too quiet” points to “leave the building,” and it’s extremely important to pay attention to that difference when it’s relevant. But this fireground commander jumped straight to the difference of “not normal, so leave the building” without mucking around with concepts at all. How the hell are we meant to learn from that?

Let’s turn our question the other way around. We want to understand what the fireground commander actually did in representational terms. What’s the simplest possible example that can give us a sense of that? Suppose I wrote a companion book to _Sources of Power_ called _Sources of Miniscule Amounts of Power_, and I opened with this case study:

> Example 1.1 The Wobbly Table
> 
> 
> Gregory puts his mug on the table and notices that the table wobbles when he does so, and his drink seems to be moving slightly away from him. He moves his drink to a different table nearby and then looks under the first table. The far opposite leg is a bit shorter than the others. Luckily, Gregory has a copy of _Sources of Power, 20th Anniversary Edition: How People Make Decisions_ on hand. He puts it under the short leg, then grabs his drink and places it back on the table. The table stops wobbling and his drink is still.

It’s not the sort of thing we’d call intuition, and it’s not the sort of thing that impresses us, but it _is_ the sort of thing that the fireground commander did. Gregory didn’t immediately know why the table was “wrong,” but his vast amounts of lived experience with flat tables let him recognize that the table wasn’t flat and act on it prior to having any particular concepts in mind. Gregory has a mental image of a “normal table” just like the fireground commander has one of a “normal fire,” and he’s attuned to that difference even when he can’t immediately state a cause.

So why is Gregory’s story less impressive than the fireground commander’s? Let’s ask ourselves: what factors can make a table violate our expectations of normality? Well, the legs could be different lengths, or the floor itself could be slanted, requiring an artificial lengthening of one or more legs. That’s basically it! Of course, the infinite detail of the world _could_ theoretically introduce another cause. Maybe the table actually is flat, and the wobbling and drink movement were due to a small earthquake in an area where they aren’t common. In practice, though, that sort of thing almost never happens. We’re comfortable holding an “idealized form” of a table in our heads that says “a non-normal table is non-normal because of irregularities in leg length, or a slant of the floor below.” Basically every person on planet Earth has a large body of lived experience telling us that this almost always works as an explanation. In the times when it doesn’t, we’ll be confused for a bit, hear about the earthquake later, and then have a fun story.

Both the fireground commander and Gregory noticed that something was wrong, but Gregory already had an idealized form telling him exactly what sort of table is “normal” and what sort of causes to look for if it’s non-normal. The infinite sources of detail in the world—the wood, the temperature, the moisture in the air—never came into the picture. The fireground commander doesn’t have that same guarantee. His idea of a “normal fire” is tentative, subject to any number of things that could violate it without him having a list of what those things are. The risk and ambiguity that the fireground commander must grapple with is what makes the first story so compelling and the second one so boring, and the fact that he can recognize a “normal fire” enough to perceive a deviant one is what he possesses that I don’t.

So, how do you fight a fire with your eyes closed? _You don’t_. Because instead of pointing at a particular fire and saying “medium” or “big,” you might need to say “not normal” and improvise. Going by a flowchart is only possible if you can explicitly list out every single factor that might be relevant ahead of time. For tables and other deliberately constructed things, you can have a small-world idealization that works so often that you can use the flowchart and basically never be punished for it. When you’re dealing with complex, interactive, dynamic sorts of phenomena (like fires), the real world is a lot more likely to intrude on your simplified model of how it works and force you to consider new details.

I mentioned at the start that I’d have to gently mislead you for a while, and now seems like the time to come clean. This is an essay about problems with representation, but throughout the first two sections, I made it seem like they were specifically problems with _words_. That’s not what’s happening here, though. Look at the word “quiet.” We all know what difference “quiet” is pointing to. In fact, we could exactly measure the volume of every fire if we liked. Firefighters don’t do that, because it doesn’t matter very much—a quiet fire is often a safer fire. The specific fire in The Sixth Sense was dangerous because it was _too quiet given the other factors_, and therefore _not normal_. But just as it required intuition to start with a fire and realize you needed to include the volume, it also requires intuition to start with the volume of a fire and figure out which other factors you need to determine whether the volume is too quiet _given those other factors._

It’s not just the _pointing of an individual concept_ we’re worried about, but also the _ensemble of concepts we’re choosing to consider_. The linguistic battles we were fighting in section II are only part of the story. It’s not enough to make sure an individual concept is well-defined, because we have an infinite number of concepts (well-defined or otherwise) we can choose to consider when evaluating any situation, and we need to use our finite brains to pick enough of them to make a good decision. To make this work, we also need to develop a sense of normality to recognize when the concepts we’re using aren’t enough to explain what’s happening. (Think of Gregory and his table, noticing “not-flat” before noticing why. The fireground commander’s sense of “normality” can be thought of as knowing which fires are “flat,” i.e. imitate the usual model, and which fires have a factor that’s out of balance with expectations.) You can’t list every potential factor ahead of time, so you just need to keep your eyes open and look for hints that it’s time to involve another concept in your representation.

In other words: don’t rely on a strictly one-way flow of information, a representation of a fire you can take or leave but never change. _I’m just talking about opening the door again_. The work to make “phlegmatic” point at a meaningful difference and the work to intuit that your model of a situation is missing a concept may seem completely different, but they’re both dealing with the same problem of fixed representation. The answer in either case is to allow your representation of what there is—what kind of patient? What kind of fire?—to change with interaction so it can capture the differences that matter.

_Don’t try to fight a fire with your eyes closed. Don’t try to diagnose the patient from behind the door._ The same moral to both stories, but they reveal different facets of the problem. When you imagine uncertainty like a fire, you see that adding in additional factors was an automatic, intuitive process that happened without conscious effort because it was needed to address an urgent break in normality. It’s important, though, for you to also keep thinking about the tablets coming under the door, because representational problems aren’t simply time and resource constraints forcing us to make approximations. Representations annihilate detail, with the city phlegmatic and country phlegmatic patients having identical tablets, and it’s not anything that you can fix with arbitrary computing power and arbitrary time to think. You need to be able to go back to the well of detail and gather the factors you need. Meaning is a product of _interaction_, not something that springs from a dead dataset.

To act on anything in the world, you have to represent it in a way where you can imagine which actions to take. We develop this capability _before_ language, as embodied cognition and intuition about physical objects. And part of this capability is the ability to notice when your representations break down and need to be amended. We do this all of the time without needing to consciously think about it. If you were in Gregory’s place for The Wobbly Table,you would have handled it just as well without needing to be taught.

That’s why I had to start with the door and not the fire. You need to see the door in your mind's eye, a great imposing thing between you and the phenomena. You need to appreciate how utterly impossible it is to reach true understanding without opening it. Only once you have that model should you think about uncertainty as a fire that you interact with to pull meaning from. We have tools to fix representational problems, but they’re local tools that have to touch the infinitely detailed world to work. You can’t use them on the tablets that get slid under the door.

More and more, though, we’re being asked to try. We’re assaulted by a flurry of charts and articles and studies and being asked to draw meaningful conclusions from them. (If we’re not just told to “trust science!”, as though there was a single correct way to interpret every finding.) That’s where this story has to end. We intuitively know how to open our eyes in our everyday lives, but how do we open the door between us and the myriad of static representations that modern life puts before us?

IV.

Throughout this essay, I’ve had to use strange words that most people aren’t used to seeing, contrived and specific examples, misdirection and repetition. The reason I’m using all of these tricks is because we don’t have well-known, socially negotiated ways to describe these representational problems. This is the first and most urgent lesson you need to come away with. This is happening everywhere, all of the time, and it’s happening largely because our concepts around indexicality and meaning are dramatically underdeveloped. No one is driving the bus and making sure meaning gets to where it’s going, and no institutional authority can be trusted to deliver these answers.

There’s no global answer to these questions because all meaning is interactive and contextual, but that’s not the same thing as saying all meaning is relative and personal. The world has real patterns waiting to be unearthed. But to use those real patterns to drive action, you need to create an abstract concept to hold the pattern, then make a real situation point at the abstract concept accurately enough.

We know meaning when we see it, and for most of human history, that worked well enough. Never mind if the actual mechanics of representation are awkward to discuss and difficult to understand—as long as we can stop the table from wobbling and get out of the building when the floor collapses, that has been enough. For much of human history, most of the data we acted upon was held in our heads. Things that were externally recorded were often simple representations that were maintained by the same person who used them to make decisions, like a merchant's inventory and receipts. Data couldn’t _help_ but be interactive and indexical, because it was bound up inextricably with human beings.

But the people involved wouldn’t think of it as “interactive” and “indexical” any more than the fireground commander thought he was making decisions. Figuring out the right way to represent something is an automatic human tool we use to get things done without worrying about theory. What counts as a chair in your house? Well, maybe an ottoman is good enough to perch on when you’re watching TV, but when the in-laws come around, only your _chair_-chairs count as chairs. A stump is a chair when you’re outside around the fire, but if your friend asked you to bring a chair to his housewarming party, he’d be pretty upset if you lugged a stump into his house. But your friend wouldn’t ask, “What are you pointing at when you say ‘chair’? Do you think your concept of chair is pointing meaningfully at the sort of things we’d like to sit on here? How much did you consider indexicality before coming to this party?” They’d just say “what the hell, man, you’re being ridiculous.”

There’s nothing wrong with just calling stump guy ridiculous! No one needs to draw on these deeper concepts of meaning to point out what went wrong here! We can all handle that problem just fine if we’re there to see it. But what about when we’re not? What about when we’re behind the door, and just given a static representation? _Jeremy’s house has six chairs in it._ But if he’s counting the ottoman, that’d better be for him and not the in-laws. And if one is a stump? That’d be ridiculous. It’s easy to give these proclamations from within Jeremy’s house, but annoying and high-effort to look at “HOUSE: Jeremy. CHAIRS: Six” and try to figure out from there whether there are actually six chairs or if some of the things being counted are ridiculous. So mostly, we just hope that the process of collecting the data doesn’t result in any ridiculous answers. But because data collection and analysis work can be made more and more automatic and scalable while the anti-ridiculousness work is much more manual (going to Jeremy’s house and seeing what the six chairs actually are), the balance is getting ever-more disturbed by modern norms of science.

Tal Yarkoni identifies this tension in his paper “[The Generalizability Crisis](https://psyarxiv.com/jqw35).” It tackles the scientific “replication crisis”, where many dramatic findings in many fields don’t seem to happen when other people run the same experiment. Yarkoni attributes this to the step where we trade verbal constructs for statistical operationalizations:

> Suppose I hypothesize that high social status makes people behave dishonestly. If I claim that I can test this hypothesis by randomly assigning people to either read a book or watch television for 10 minutes, and then measuring their performance on a speeded dishwashing task, nobody is going to take me very seriously. It doesn’t even matter how the results of my experiment turn out: there is no arrangement of numbers in a table, no p-value I could compute from my data, that could possibly turn my chosen experimental manipulation into a sensible proxy for social status. And the same goes for the rather questionable use of speeded dishwashing performance as a proxy for dishonesty.
> 
> 
> The absurdity of the preceding example exposes a critical assumption that often goes unnoticed: for an empirical result to have bearing on a verbal assertion, the measured variables must be suitable operationalizations of the verbal constructs of interest, and the relationships between the measured variables must parallel those implied by the logical structure of the verbal statements. Equating the broad construct of honesty with a measure of speeded dishwashing is so obviously nonsensical that we immediately reject such a move out of hand. What may be less obvious is that exactly the same logic implicitly applies in virtually every case where researchers lean on statistical quantities to justify their verbal claims. Statistics is not, as many psychologists appear to view it, a rote, mechanical procedure for turning data into conclusions. It is better understood as a parallel, and more precise, language in which one can express one’s hypotheses or beliefs. Every statistical model is a description of some real or hypothetical state of affairs in the world. If its mathematical expression fails to capture roughly the same state of affairs as the verbal hypothesis the researcher began with, then the statistical quantities produced by the model cannot serve as an adequate proxy for the verbal statements—and consequently, the former cannot be taken as support for the latter.

Yarkoni’s point about speeded dishwashing is similar to our pointing problem with “phlegmatic”. Dishwashing aptitude clearly doesn’t point to any difference caused by any concept of “dishonesty”, but even things that have some superficial relationship to our idea of “dishonesty”—amount of eye-contact, or heart rate on a polygraph, or whatever—could have the same danger of meaning-debt if they’re trying to proxy for the reasons we _care_ about “dishonesty” (can I trust them when they say how much my share of the bill was, or do I need to see a receipt?). Yarkoni calls this the “generalizability crisis”. We can view it as a subset of our representational crisis, since it’s the same problem of concepts failing to cleanly map to differences. Remember, though, that uncertainty is like a fire as well as like a door. The representational crisis is not just about individual low-validity concepts, but whether you’re looking at the proper ensemble of concepts.

Let’s suppose Dr. House and Dr. Field each performed studies on the efficacy of mulled wine and bull testicles for phlegmatic patients and published them in modern-style scientific journals. House went first, testing with the city patients and finding a dramatic impact. Field published after, looking at country patients and finding no impact. This might be called a failure of replication, but we know it was actually a failure of _representation_. Dr. House’s work wasn’t replicable because Dr. Field was testing a _different thing than Dr. House was_, even if they both called their patients “phlegmatic.”

Just like with the fireground commander, these are problems that humans have experience catching, but only when they’re able to interact with the world and not just with dead representations of things. [This story from Chemical & Engineering News](https://cen.acs.org/synthesis/catalysis/metal-free-mistake-chemists-doomed-repeat-impurities-contamination-Suzuki-coupling/100/i6) is a great case study. A chemist publishes a paper about a supposedly “metal-free” reaction. But other chemists reading it know that palladium is stubborn and hard to completely get rid of. So they replay the methods of the paper and replicate the original results, but then try different things that remove contaminating palladium and show that the reaction doesn’t work anymore. That’s how this sort of verification has to work. Textual or statistical analysis won’t get you anywhere, since the whole problem is that the original paper represents itself as “palladium-free” and you need to have the experience to say: “Well, I’m sure they didn’t _mean_ to have residual palladium, but that’s not the same as palladium-free.”

In chemistry, the objects you’re working with are precise down to the elemental level. Even that isn’t enough to stop the problem of uncertainty being like fire! What it does mean, however, is that one chemist generally has a very easy time replicating what another chemist did. The original paper didn’t contain an accurate description of what there was (trace palladium), but the language of chemistry permits very accurate descriptions of what was done. So even if the paper itself is a dead representation that lives behind the door, the methods section allows someone else to open the door for themselves, stand where the original chemists stood, and _try something new_.

The same doesn’t hold true for House and Field. Even if they had followed identical methods to the letter, they would still have gotten totally different results, because their base unit of “a phlegmatic patient” simply is not stable between experiments in the same way as a chemical compound. Field doesn’t open the door to the same place in which House stood: he opens the door to country patients and tries to replicate a finding from city patients. So of course subject areas that work with highly contextual objects, such as people and ecosystems and cities and ideas, will have problems with replication! And it’s not something that can be caught the same way that the chemists caught the palladium issue, because you can’t run an experiment on the same patients at the same moment in time. You can trust palladium _now_ to be like palladium _before_, and you can trust palladium _here_ to be the same as palladium _there_, but that’s obviously not the case for anything to do with human beings. So when an experiment doesn’t replicate, it doesn’t necessarily mean that the first scientist lied about their impact or the second scientist’s experiment contained methodological sloppiness. It could just mean that the two scientists were running entirely different experiments (the effect of a treatment on _c. urbanicus_ vs. _c. pastorilus),_ and only thought they were the same because they labeled their different patients the same way.

I’m not disputing that there’s plenty of methodological sloppiness and outright fraud in science. But I do genuinely think this is the most important frame to the replication crisis. After all, the labels are also how you’re going to end up _using_ the study. “Are you feeling phlegmatic? Well, there was this new study…” Meaningfully using a scientific finding in your indexical life has exactly the same issue with representation as trying to replicate that finding. A country physician needs to know that their phlegmatic patients are different from a city physician’s phlegmatic patients, while each individual patient needs to know _which paper to read_ when faced with the differing results.

When you think about it this way, it’s clear that many of our existing strategies for imbuing scientific papers with more meaning aren’t relevant here. Statistics? House sees a good result 100% of the time, and Field sees a bad result 100% of the time, so neither of them need any degree of statistical fluency to interpret the signals they’re seeing. Bigger sample sizes? Maybe they’ll get a hint of the real issue if the demand for more patients forces them out of their normal stomping grounds and increases sample diversity, but by and large House will just see more city patients and Field will see more country patients. Preregistration? This wasn’t a method-based problem at all, because House and Field did exactly the same thing.

What about a meta-analysis that looks at several different papers to try to figure out what’s really happening? Now we’re getting warmer, but there’s a critically important distinction here. Meta-analysis can clue you in that the difference exists, but it’s not a tool that lets you reach “the answer,” because the whole issue is that there _is no singular answer_. Doing a numerical meta-analysis is only going to mislead you by averaging together dramatically different studies, in the same way that no formal methods worked for the rabbits because _hrair_ could be 4 or 1000. We need a new kind of meta-analysis that lets us do what the chemists did and pick out details that the authors didn’t think to explicitly represent. But if two papers can follow identical methods and get different results, how can you read them both and tease apart the difference?

The antidote to representation issues is context. We need scientific papers to be more like murder mysteries, replete with “unnecessary” details that might include the crucial clue. By definition, the authors themselves won’t understand which detail they add that might prove crucial for understanding a representational problem—if they understood it, they’d represent it, and it wouldn’t be a problem. But the authors don’t _need_ to understand the importance of particular details. Let’s say that House and Field were both forced to add some set amount of narrative context to their paper. They’re hardliners who are convinced there’s nothing more to a patient than “phlegmatic” and resent the whole exercise. They agree to both use the space to complain about how annoying the required sample size was. House’s complaint is that he had a constant line of patients outside his door that disrupted his neighbors, while Field’s complaint is that he went through five horses because he had to travel to so many different farms to get to everyone.

What happens when those narrative studies are slipped under the door instead of just the tablets? House never explicitly says “I’m a city doctor working with city patients” in his paper, but now it can be _inferred by the reader._ You can’t directly recreate the original scenario like the chemists could, but you can at least see into the experiment beyond just the results. In a situation where the same methods led to different outcomes, the papers themselves will now be different in a way that can help you tease out why. You’re not completely helpless like you were up there in section II.

Phrased like this, it’s almost insultingly straightforward. Of course adding more stuff to a paper makes it easier to figure out! Maybe because representational issues are _so_ obvious when you’re face to face with them, we don’t tend to think of them as a general phenomenon. We can recognize them and solve them, but individually, without recognizing it as a “kind” of problem.

We have to imagine detail contaminating _all_ abstracts, though. Just as the theoretical construct of “metal-free” couldn’t help but mean “no metals explicitly added, though some contaminants remain,” “phlegmatic” can’t help but mean something more nuanced than “a symptom state such that all patients who exhibit it will behave exactly the same way to exactly the same interventions.” The more indexical the object is, the more impossible it is to run two experiments and equate them with each other, and the more context you need to determine how much of the relevant detail your representations are actually capturing. Indexicality can’t be objectively measured or tested for, but that doesn’t mean it’s subjective or arbitrary. Clearly, a human being and a fire have many factors that could influence the outcomes of any given intervention, while palladium compounds and tables have fewer. What we don’t have is well-negotiated language to talk about _how_ indexical various concepts are, and _to what degree_ detail intrudes on the pure concept as it’s being used.

No one will give you the answer—so you have to figure it out yourself. This is not a manifesto about all scientific findings and modern rationality being wrong. It’s a warning that the right stuff and the wrong stuff are going to look exactly the same to the untrained eye. The same methods, the same data analysis techniques, the same probabilities. There’s only one way to sort the good from the bad: are the representations meaningful with respect to the differences? You can’t trust the people telling you “the facts” to get this part right. Look for clues. Is it a finding about something largely independent of its context like palladium, or is it highly indexical like a human being? If you see a headline, is it about something you can instantly imagine the definition of (like “all 2018 Volkswagen Jettas”) or is it something that doesn’t have a single socially negotiated meaning (like “healthy diets”or “predatory journals”)? Do you know the story of how the data was collected? If something very weird happened, whose job would it be to encode it, and what categories would they pick to describe it? Was this analysis done by someone in direct contact with the data collection, or are there multiple layers of abstraction between the phenomena and the conclusion?

It’s becoming easier than ever to collect big gobs of data, cheaper than ever to hold on to it, and faster than ever to send it out for other people to derive insight from. Once you start asking these questions about representation, you can’t help but notice the problems are getting worse and worse every year. This is the urgency that drove me to start _Desystemize_ in the first place. You can see this concern right at the very beginning in [Desystemize #1](https://desystemize.substack.com/p/desystemize-1?utm_source=url):

> Dr. Ostfeld didn’t start that paragraph by noting such-and-such statistical technique clearly indicated something was off with the tick counts. He started with the sentence “My research group has set and checked many hundreds of thousands of live animal traps over the years.” In other words, it was _familiarity with the data-generating process_ that enabled the lab group to imagine this potential vulnerability and come up with this experiment. By the time the data gets into the hands of analysts, it’s too late to fix. You can’t math your way out of a wrong number. This mistake was caught only because it was the same people generating the data as analyzing it. Which, great for ecology - but as data science becomes more and more specialized, it will be increasingly done by people who are explicitly and solely data scientists. And they’ll inherit datasets from repositories somewhere and never catch a single one of these systemic errors because they couldn’t sift through the wet mouse turds even if they wanted to.

After all of my previous articles dancing around these issues of representation, at last we’ve arrived within the right arena to face the beast head on. No “scientific method” will ever be enough on its own, because the same method may succeed in domains with meaningful representations and fail dramatically when the representations are drowning in meaning-debt. The solution is to open the door and to engage with differences beyond dead representation. Trust your ear to tell you when the fire’s too quiet. And when you’re asked to make a judgment about something you can’t open the door to yourself—a study or an article or a graph, the sort of thing you’ve been shown thousands of times and will be shown thousands more—don’t trust their ontologies without question. Look for hints that they’ve taken representation as seriously as they ought to. Ask questions, and from their answers, forge a proper language of representation, a social understanding of which ontologies are useful and which are bankrupt. Take this tacit skill scattered among a few experts and make it a core part of education and the human experience. It’s gotten too easy to live behind the door, and the stakes are too high to keep it up much longer.

_Thanks to [Crispy Chicken](https://crispychicken.cc/) for significant conceptual feedback, the rest of the [Inexact Sciences](https://theinexactsciences.github.io/) crew for inspiration, [Lyta Gold](https://twitter.com/lyta\_gold) for editing, and everyone who kept me company while I wrote._
]]></description>
</item>
<item>
<title><![CDATA[Vercel Security Checkpoint]]></title>
<link>https://www.lesswrong.com/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption</link>
<pubDate>Mon, 20 Oct 2025 05:16:00 -0300</pubDate>
<description><![CDATA[Title: Vercel Security Checkpoint

URL Source: http://www.lesswrong.com/posts/QmWNbCRMgRBcMK6RK/the-absolute-self-selection-assumption

Warning: Target URL returned error 429: Too Many Requests

Markdown Content:
Vercel Security Checkpoint

|

cle1::1760948157-uEG2ofzzodSTpe1ypeGT4c6uggoLRjqp
]]></description>
</item>
<item>
<title><![CDATA[Unlearning Default Awayness - by Evan Erickson - Frames]]></title>
<link>https://emframes.substack.com/p/unlearning-default-awayness?utm_source=%2Finbox%2Fsaved&utm_medium=reader2</link>
<pubDate>Mon, 20 Oct 2025 05:16:27 -0300</pubDate>
<description><![CDATA[Title: Unlearning Default Awayness

URL Source: http://emframes.substack.com/p/unlearning-default-awayness

Published Time: 2025-09-02T23:09:21+00:00

Markdown Content:
[![Image 1](https://substackcdn.com/image/fetch/$s_!ieJ2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51d2f882-b9d2-4e36-bb47-fdad23cb9cfd_1536x1024.heic)](https://substackcdn.com/image/fetch/$s_!ieJ2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51d2f882-b9d2-4e36-bb47-fdad23cb9cfd_1536x1024.heic)

I've been meditating for almost ten years. I've dabbled in many methods and frameworks: _[Seeing that Frees](https://hermesamara.org/seeing-that-frees)_, [Aro gTér](https://aroterlineage.org/en/meditation-course), [Sam Harris](https://a.co/d/f7ollAq), _[Mastering the Core Teachings of the Buddha](https://a.co/d/1zHPAxm)_, _[The Mind Illuminated](https://a.co/d/eWExBnq)_. Time and again, the spacious, open, inclusive, “non-doing” practices resonated most deeply. I finally took the hint and adopted [Opening Awareness](https://www.evolvingground.org/opening-awareness) as my base practice.

The basic instruction is deceptively simple: “[Remain uninvolved in whatever arises.](https://a.co/d/iYHhdhF)” Involvement manifests as three “muscular contractions” of the mind: emphasizing, de-emphasizing, and setting aside. In their compulsive forms, these map to clinging (attachment), pushing away (aversion), and ignoring (ignorance). [Discovering](https://anielsen.substack.com/p/the-simplest-exercise-of-searchlessness) what the [instruction means](https://feelingtones.substack.com/p/full-of-feeling-in-any-situation) in the midst of specific sensations and concrete situations becomes integral to the practice, ultimately revealing what it means to rest in the _totality_ of experience.

While various [scaffolding practices](https://a.co/d/iYHhdhF) can help re-establish uninvolvement, the practice itself remains simple: remain uninvolved.

The two misunderstandings that confused my practice for years centered around the relationship between orientation[1](https://emframes.substack.com/p/unlearning-default-awayness#footnote-1-171513958), strategy, and these three involvements. To unpack them, we need a simple model of how intentions translate into actions through three distinct levels:

**Level 1: Orientation**

The level of intention with the felt sense of agency pointing in a direction. My fundamental aim in any given moment.

**Level 2: Strategy**

The level of tactics I employ to enact my orientation, including both habitual, patterned reactions and fresh, spontaneous responses.

**Level 3: Involvement**

The level of mental actions that are the “muscular contractions” of consciousness mentioned above:

*   **Emphasizing** sensations, which can escalate to compulsively clinging.

*   **De-emphasizing** sensations, which can escalate to compulsively pushing away.

*   **Setting aside** sensations, which can escalate to compulsively ignoring.

To [unlearn](https://chrislakin.blog/p/unlearning) my first misunderstanding, I had to _feel_ the difference between [two types of orientation](https://malcolmocean.com/2022/02/towardsness-awayness-motivation-arent-symmetrical/):

**Towardness** as coherent approach. I’m moving toward something specific I can name, feel, or envision.

**Awayness** as scattered flight. I’m moving away from something I don't want without a clear destination.

**I confused orientation with involvement**. I didn't see that an underlying Awayness orientation (Level 1) could be motivating my entire practice, causing me to constantly try to _get away from_ the three involvements themselves (Level 3).

For example, when approached with Towardness, “Remain uninvolved with whatever arises” is a clear aim. You can _intend_ to remain uninvolved without _clinging_ to remaining uninvolved. But when Awayness co-opts the instruction, it becomes, “Get away from all involvement,” creating a paradox that generates endless struggle.

**I saw my defensive patterns as broken**, stuck strategies (Level 2) from the past; outdated, malfunctioning, and in desperate need of fixing. This created an _Awayness orientation toward seeing my own patterns_.

What started to unwind Misunderstanding 2 was adopting a view that saw my defensive patterns as _[brilliant](https://chrislakin.blog/p/locally-optimal)_ at what they're motivated to do: move me away from threatening experiences. They may have originated in the past, but they persist because they're still effective _[right now](https://chrislakin.blog/p/social-anxiety)_.

Through this view, I developed a _Towardness orientation_ with respect to seeing these patterns, resting in the full experience of them. They have become fascinating, each with its own intricate logic, intelligence, and resourcefulness.

Returning to Misunderstanding 1, I've started to unlearn it by recognizing two interesting asymmetries between Towardness and Awayness.

**Directional Clarity:**

Towardness implies a single destination. Like swimming toward a visible shore, I have an attractor: [kindness](https://meaningness.substack.com/p/learning-kindness-skills), [nobility](https://meaningness.substack.com/p/nobility-table-of-contents), [connection](https://vajrayananow.com/relating-as-space), [searchlessness](https://anielsen.substack.com/p/introduction-searchless-responsiveness). I'm familiar with what calls me—or at least the direction it lives in—and orient toward it.

Awayness has no such directional clarity. I can go in any direction, as long as it's away from what I _don't want_. Like fleeing a swarm of bees, I have a repulsor: pain, rejection, embarrassment, failure, [Samsara](https://vividness.live/renunciation-in-buddhism). There's no specific target, simply “Not this. Away!”

**Relationship to Involvement:**

This directional asymmetry creates another: how eager Towardness and Awayness are to get involved, how much they churn involvement.

A clearly seen and deeply felt Towardness motive uses involvement only to course-correct. When I've arrived, I can [simply rest](https://chrislakin.blog/p/being-present-is-not-a-skill).

Awayness incentivizes clinging, pushing, and ignoring in _any_ direction that moves me away from—or keeps me away from—the unwanted condition. This creates hyper-vigilance. I must guard in all directions to ensure the threat isn't approaching. Rest becomes dangerous because it means letting my guard down.[2](https://emframes.substack.com/p/unlearning-default-awayness#footnote-2-171513958)

Consider my walking into a social event where I don't know anyone.

**With a Towardness orientation (moving toward genuine connection):**

*   **Level 1 (Orientation):** Move toward genuine connection

*   **Level 2 (Strategy):** Coherent engagement

*   **Level 3 (Involvements):**

    *   Emphasizing moments of real resonance when they arise: making real eye contact, asking genuine questions, and sharing something authentic.

    *   De-emphasizing filling silence with empty chatter.

    *   Setting-aside the urge to look at my phone.

Notice how Towardness uses involvement purposefully. Each involvement serves the coherent aim rather than scattering in all directions.

**With an Awayness orientation (moving away from embarrassment):**

*   **Level 1 (Orientation):** Get away from potential embarrassment

*   **Level 2 (Strategy):** Scattered disengagement

*   **Level 3 (Involvements):**

    *   Clinging to phone screen for safe escape.

    *   Pushing away eye contact because it's too vulnerable.

    *   Ignoring interesting conversations nearby because it's too threatening.

Moving away from embarrassment uses any involvement to scatter chaotically. Yet this isn't brokenness! It's successfully implementing a defensive strategy that's working perfectly at what I'm (unknowingly) intending to do.[3](https://emframes.substack.com/p/unlearning-default-awayness#footnote-3-171513958)

To be clear, I'm _not_ saying Towardness = good, Awayness = bad. Indeed, it's not always bad to be motivated by Awayness. Running the hell away from a swarm of killer bees—in any direction—is perfectly legitimate!

Awayness _might_ become problematic only if I'm _not seeing_ that it is motivating action. There's not even anything _inherently_ wrong with keeping motives—and the patterns that serve them—unseen. There are no [existential](https://vividness.live/there-are-no-spiritual-problems)[problems](https://anielsen.substack.com/i/143642195/searchlessness) or [ultimate solutions](https://anielsen.substack.com/p/the-search). Awayness only becomes a “problem” in a relative sense when I want to move in a _specific_ direction (Towardness), but the unseeing of Awayness makes that difficult or impossible.

**1. Valuing the Aim More Than Avoiding Discomfort**

I had to want the result more than I feared what I’d encounter on the path. Many genuine methods led directly toward experiences I wanted to get further from. If presence means feeling everything—including pain—while I'm unknowingly motivated by pain-Awayness, my hidden strategies will sabotage every move toward presence.

Moreover, many (all?) beautiful experiences contain their shadows as inseparable aspects. Deep appreciation holds the seed of loss. Genuine intimacy requires vulnerability. Vivid aliveness includes encountering uncertainty and the uncontrollable.

So when I lacked this clarity of values, I defaulted to Awayness, trying to get the “good” by moving away from the “bad.” But since they're experientially inseparable, the consequences of my strategies' success at getting me away from difficult experiences was to move me away from some of life's most beautiful.[4](https://emframes.substack.com/p/unlearning-default-awayness#footnote-4-171513958)

**2. Experiential Knowledge of the Aim**

I needed to know what I was moving toward through direct experience, not just concepts. At a minimum, I needed to feel what it was like to move in the right direction. “Remain uninvolved with whatever arises” remained empty words until I tasted that quality of uninvolvement. Without this experiential knowledge, I navigated by rumors and negations, trying to eliminate everything that seemed like "involvement."

To clarify: the _method_ “Remain uninvolved with whatever arises” involves specific steps like recognizing involvement when it arises, gently relaxing the grip, returning to uninvolvement. The _result_ is the felt quality of uninvolvement itself, a particular flavor of noninterference.

But without having experienced genuine uninvolvement, I only had concepts. So instead of following the method, I tried to manufacture the result through negation, eliminating everything that seemed like “clinging,” “pushing,” “ignoring,” “thought,” “crampedness,”… on into infinity. I was defining my target by what it _wasn't_ rather than knowing what it _was_. This was Awayness mimicking Towardness.[5](https://emframes.substack.com/p/unlearning-default-awayness#footnote-5-171513958)

**3. Felt Recognition of the Difference**

I needed to know what the energetic quality of both types of orientation _felt_ like. Towardness feels like opening, flowing, extending, motivating, energizing. Awayness feels like contracting, backing up, scattering, folding, depressing. Without this felt discrimination, my overwhelming default was Awayness.

The critical failure here was not noticing when Towardness flipped to Awayness. What began as genuine intention—“Remain uninvolved with whatever arises”—would subtly transform:

1.   I'd make instrumental adjustments: “Relax this clinging by noticing what other sensations in awareness are present.”

2.   The adjustments became the focus: “Monitor for any sign of involvement to relax.”

3.   The means became the end: “Actively scan for and eliminate all forms of clinging, pushing, or ignoring.”

4.   I was now in Awayness, desperately using involvement while claiming to practice uninvolvement.

The result was exhausting vigilance and hollow victories, achieving the “uninvolvement” of successful avoidance rather than genuine arrival.

To illustrate how unseen Awayness operates, here are a few of my most persistent patterns, ordered roughly by how difficult they've been to see:

**People-Pleasing**

*   **Pattern:** Default to agreement, smoothing, and self-erasure. Often slip into dishonesty about my wants, needs, and abilities (see Meta-Awayness of Towardness below).

*   **Brilliant Logic:** If I control how others feel, I can avoid rupture, rejection, shame, and the pain of empathy.

**Joy Dampening**

*   **Pattern:** Brace against the experience of joy.

*   **Brilliant Logic:** If highs stay moderate, lows hurt less. Intensity control = intensity avoidance.

**Appreciation Blindness**

*   **Pattern:** Block felt appreciation for anything.

*   **Brilliant Logic:** If nothing is appreciated, nothing can devastate me when lost.

**Awayness From All Arisings**

*   **Pattern:** Maintain constant vigilance against all arising sensations/experiences.

*   **Brilliant Logic:** Any painful or unwanted arising could ambush me at any time. Never relaxed = never getting caught off-guard.

**Meta-Awayness of Towardness**

*   **Pattern:** Block recognition of _any_ Towardness orientation.

*   **Brilliant Logic**: I can't choose wrong if I never choose. I can't waste time on the wrong aim if I never pick one. I can't feel bad for having harmful or immoral desires if I never recognize any desires at all.

If any of this resonates and you find yourself struggling with a practice, it may be worth exploring a few questions somatically:

*   “Do I truly want the results of this practice?”

*   “Do my _assumptions_ about what the results of this practice will be like involve experiences I have reasons to avoid?”

*   “Does _actually moving toward the results_ of this practice cause me to confront experiences I’m strongly motivated to stay away from?”

No amount of rephrasing practice instructions will help if following them leads somewhere you unknowingly _don't want to go_.

I’ve often found that _a method was actually working_, but it was resulting in experiences I had unseen, legitimate reasons to avoid. I could only make progress once those Awayness incentives were seen and relaxed.

**Somatic-based emotional work like [Focusing](https://a.co/d/etMe6Ad) or [Internal Family Systems](https://a.co/d/hm0SgNo):** A prerequisite of feeling Towardness and Awayness is the ability to feel in the first place. This is particularly tricky if you have Awayness incentives to not feel the intensity of embodied experience. If I could tell my past self one thing, it would be, “Learn how to inquire somatically before trying anything else!”

**[Existential Kink](https://a.co/d/4wbi99h):** An Awayness orientation toward my patterns incentivized keeping them unseen. EK gave me a [playful framework and a set of practices](https://sashachapin.substack.com/p/the-craziest-thing-that-ever-happened) to start establishing a Towardness orientation with respect to those unseen patterns.

**Shadow Appreciation:** I formulated this practice after noticing I was completely blocking the experience of appreciation. Whenever I asked what I truly appreciated, I only felt hazy numbness. So I flipped the block and went straight for the heart: _“What would devastate me most to lose?”_ Immediately, answers poured in. I chose one and refined it: _“What, specifically, would devastate me most about losing my girlfriend?”_ A cascade of beautiful details I deeply value about her flowed effortlessly into awareness.

This can be repeated with anything that arises. Here are the steps:

1.   **Rest in Receptive Presence:** Start with an amount of Opening Awareness you find appropriate.

2.   **Drop in the Question:** Silently drop the question, _“What would devastate me the most to lose?”_ into awareness, without effort.

3.   **Notice What Arises:** Allow memories, images, or sensations to surface; feel their bodily resonance.

4.   **Savor & Amplify:** Deepen appreciation by naming what matters, then increase intensity and specificity by asking, _“What,_ specifically _, would devastate me the most about losing X?”_

5.   **Meet Resistance:** If numbness or resistance arises, greet them kindly and rest in spaciousness as needed.

6.   **Iterate:** Cycle 2 through 5 however many time feels appropriate.

7.   **Rest Again:** Conclude by resting again with Opening Awareness, allowing whatever arose to settle naturally.

**Worst Case Scenario Simulation:** This practice treats every avoidance or resistance that arises as a [locally optimal strategy](https://chrislakin.blog/p/boundaries) (a Chris Lakin’s [phrase](https://chrislakin.blog/p/locally-optimal)), a successful way to move away from an unwanted experience. The practice helps you feel what Towardness might be like right in the middle of the worst expression of the unwanted experience:

1.   **Rest in Receptive Presence:** Start with an amount of Opening Awareness you find appropriate.

2.   **Recall a Triggering Situation:** Bring to mind a moment where resistance or fear arose (social anxieties work especially well for me).

3.   **Enter the Catastrophe:** Vividly imagine the absolute worst outcome, tracking the real-time bodily sensations the outcome provokes.

    *   Repeat until the scenario feels maximally vivid and fully “as bad as feared.”

4.   **Feel Towardness:** At peak distress, envision and enact how you'd like to respond with clarity, boundaries, kindness, strength, nobility, etc.

    *   The aim is to _experience_ what Towardness would be like in the midst of the worst-case outcome.

5.   **Rest in Towardness:** Linger in the felt sense of that orientation.

6.   **Re-run or Rest:** Replay the scenario until it becomes neutral or boring, then savor the spaciousness that remains.

7.   **Rest Again:** Conclude by resting again with Opening Awareness, allowing whatever arose to settle naturally.

Struggling with ’s _[Another “Simplest” Exercise of Searchlessness](https://anielsen.substack.com/p/another-simplest-exercise-of-searchlessness)_ and being completely dumbfounded by why it was so damn hard to follow the instructions was a major catalyst that started a process culminating in much of what I’ve written here.

The influence of ’s _[Towardness & Awayness Motivation are fundamentally asymmetric](https://malcolmocean.com/2022/02/towardsness-awayness-motivation-arent-symmetrical/)_, along with that of  and 's conversation in _[Aim at what you want, not what you don’t](https://chrislakin.blog/p/aim)_, on all of what I wrote can be seen clearly.

Exploring Bruce M. Di Marscio’s _[The Option Method](https://www.amazon.com/dp/B09ZS7JB8Z?binding=kindle\_edition&qid=1755385396&sr=8-3&ref=dbs\_dp\_rwt\_sb\_pc\_tkin)_ also planted many seeds:

*   ’s _[What is happiness, actually?](https://feelingtones.substack.com/p/what-is-happiness-actually)_

*   ’s _[How to Be Happy](https://andrewblevins.substack.com/p/how-to-be-happy-basically)_ and follow-up _[Sample Problem](https://andrewblevins.substack.com/p/sample-problem)_

The entirety of ’s blog [Locally Optimal](https://chrislakin.blog/) is worth reading, but here are some choice selections:

*   _[Social anxiety isn’t about being liked](https://chrislakin.blog/p/social-anxiety)_

*   _[Setting boundaries can feel effortless](https://chrislakin.blog/p/boundaries)_

*   _[How I’d rewrite The Courage to be Disliked](https://chrislakin.blog/p/courage)_

*   _[Choose Unlearning](https://chrislakin.blog/p/unlearning)_

If you're interested in spacious, inclusive, life-affirming meditation, I'd highly recommend  excellent introduction [Opening Awareness](https://a.co/d/cYXU2e7). I'm deeply grateful for their direct guidance on the path.

Many thanks to those who have had a direct or indirect influence on this material, particularly , , , , , , Ye’tsal Kandro, and everyone else over at [Evolving Ground](https://www.evolvingground.org/). Your practice is inspiring.

Finally, a very special thanks to  for encouraging me to turn this material into a post and offering advice on how to publish!

[1](https://emframes.substack.com/p/unlearning-default-awayness#footnote-anchor-1-171513958)

Throughout this post I’ll use the terms orientation, intention, motivation, aim, etc. interchangeably to refer to the same felt sense of being motivated or intentioned.

[2](https://emframes.substack.com/p/unlearning-default-awayness#footnote-anchor-2-171513958)

Notice how this incentivizes an Awayness orientation with respect to rest…

[3](https://emframes.substack.com/p/unlearning-default-awayness#footnote-anchor-3-171513958)

There's a third asymmetry I've started to notice: Awayness-motivated involvements tend to escalate more readily into their compulsive forms. When I'm oriented by Awayness, “emphasizing” quickly becomes desperate clinging, “de-emphasizing” hardens into forceful pushing away, and “setting aside” collapses into willful ignorance. This often results in a difference in tone or texture of each. Towardness-motivated involvements feel lighter and more spacious. What might be “clinging” under Awayness becomes “appreciating” under Towardness; “pushing away” becomes “releasing”; and “ignoring” becomes “letting be.”

[4](https://emframes.substack.com/p/unlearning-default-awayness#footnote-anchor-4-171513958)

Before I valued genuine connection more than I valued avoiding the discomfort of separation, I couldn't even _see_ that they were inseparable. And before I could even _see_ that I valued genuine connection, I needed to relax the Awayness motivation to not see what I deeply valued (see my discussion of my Meta-Awayness of Towardness pattern). This shit cuts deep!

[5](https://emframes.substack.com/p/unlearning-default-awayness#footnote-anchor-5-171513958)

I find community/sangha to be incredibly valuable in this regard. Without having experiential knowledge of the results of a practice, I can be inspired by others who seem to embody the results so beautifully.
]]></description>
</item>
<item>
<title><![CDATA[Vercel Security Checkpoint]]></title>
<link>https://www.lesswrong.com/users/jacob_cannell?from=post_header</link>
<pubDate>Mon, 20 Oct 2025 05:16:29 -0300</pubDate>
<description><![CDATA[Title: Vercel Security Checkpoint

URL Source: http://www.lesswrong.com/users/jacob_cannell?from=post_header

Warning: Target URL returned error 429: Too Many Requests

Markdown Content:
Vercel Security Checkpoint

|

cle1::1760948187-tP3UI2ZuE5wLns5jALq6aU1kUqoV65QI
]]></description>
</item>
<item>
<title><![CDATA[No Feedback ∴ No Good]]></title>
<link>https://entropicthoughts.com/no-feedback-no-good</link>
<pubDate>Mon, 20 Oct 2025 05:16:33 -0300</pubDate>
<description><![CDATA[Title: No Feedback ∴ No Good

URL Source: http://entropicthoughts.com/no-feedback-no-good

Markdown Content:
The strange character in the middle of the title is a maths symbol pronounced _therefore_.

* * *

When looking for a new job I got interviewed by a ceo who had formerly worked as a security advisory consultant. This meant their job used to be advising large organisations on the status of the softer parts of their security systems: people, processes, information barriers, etc.

This was something I’d always been curious about, so I had to ask:

> Beyond the basics, how did you know if you were doing a good job?

Their response was candid:

> I didn’t. I’m not sure how I would.

Security breaches of the kind they were trying to protect against are rare, and if they happen, they only tell us what failed, not all the things that worked. The advisory role has very few feedback paths and they are all low-quality. The advisor simply cannot tell whether what they are doing is working or not; much less if it’s an effective use of money.

These professions are not altogether uncommon: large parts of of social science, political analysis, career counseling, macroeconomics, education policy, and advisory consultancy fall prey to this problem. When the feedback paths are missing, success is measured through peer opinion, i.e. the practitioners that have a good reputation among their peers are considered skilled, [regardless of what their real world impact is](https://entropicthoughts.com/validate-your-skill.html).

I don’t know exactly what the point of this is – and I am sure Nassim Nicholas Taleb has rambled about it far more than I could ever dream of – but I recommend asking that question of people you admire. _How do you know if you’re doing a good job?_ can yield fascinating answers from skilled people.

Sometimes the answer sounds sensible but is a veiled “when other people tell me I did a good job.” These are not the types of professions I would be good at, but I some people are very successful at them.

* * *

Just after writing this article, I was coincidentally reminded of where I got this question from in the first place. In _Working Minds_ 1 1 _Working Minds: A Practitioner’s Guide to Cognitive Task Analysis_; Crandall, Klein, Hoffman; MIT Press; 2006., the authors give some advice on how to find an expert to subject to cognitive task analysis. But they caution that in some fields, it might be hard to find an actual expert. They list three signs of such a field:

1.   High turnover (few people work long enough to build expertise);
2.   Recent technological revolution (expertise requirements changed); and
3.   Lack of clear feedback.

The third point is what this article is about, and _how do you know if you’re doing a good job_ is one of the first questions one should ask of experts when learning to navigate their field.2 2 Another good question is _Was that outcome your intention?_ – which, to my delight – my son is asking a lot.
]]></description>
</item>
<item>
<title><![CDATA[Vercel Security Checkpoint]]></title>
<link>https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators</link>
<pubDate>Mon, 20 Oct 2025 05:16:34 -0300</pubDate>
<description><![CDATA[Title: Vercel Security Checkpoint

URL Source: http://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators

Warning: Target URL returned error 429: Too Many Requests

Markdown Content:
Vercel Security Checkpoint

|

cle1::1760948193-gP3SEcsecZJCFacLhqX6LK2Cy8O6SBVE
]]></description>
</item>
<item>
<title><![CDATA[CRYSTAL CURSE (King Sombra song) [METAL] - YouTube]]></title>
<link>https://www.youtube.com/watch?v=52OxtHa7qT0</link>
<pubDate>Sat, 25 Oct 2025 13:44:05 -0300</pubDate>
<description><![CDATA[Title: CRYSTAL CURSE (King Sombra song) [METAL]

URL Source: http://www.youtube.com/watch?v=52OxtHa7qT0

Markdown Content:
CRYSTAL CURSE (King Sombra song) [METAL] - YouTube

===============

 Back [![Image 1](http://www.youtube.com/watch?v=52OxtHa7qT0)](http://www.youtube.com/ "YouTube Home")

Skip navigation

 Search 

 Search with your voice 

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

[Sign in](https://accounts.google.com/ServiceLogin?service=youtube&uilel=3&passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Faction_handle_signin%3Dtrue%26app%3Ddesktop%26hl%3Den%26next%3Dhttps%253A%252F%252Fwww.youtube.com%252Fwatch%253Fv%253D52OxtHa7qT0&hl=en&ec=65620)

[![Image 2](http://www.youtube.com/watch?v=52OxtHa7qT0)](http://www.youtube.com/ "YouTube Home")

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

[CRYSTAL CURSE (King Sombra song) [METAL]](http://www.youtube.com/watch?v=52OxtHa7qT0)

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

Tap to unmute

2x

[![Image 3](http://www.youtube.com/watch?v=52OxtHa7qT0)](http://www.youtube.com/watch?v=52OxtHa7qT0)

CRYSTAL CURSE (King Sombra song) [METAL]
----------------------------------------

Elias Frost 3,095 views 3 months ago

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

Search

Copy link

Info

Shopping

![Image 4](http://www.youtube.com/watch?v=52OxtHa7qT0)

[![Image 5](http://www.youtube.com/watch?v=52OxtHa7qT0)](http://www.youtube.com/watch?v=52OxtHa7qT0)

If playback doesn't begin shortly, try restarting your device.

•

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

Cancel Confirm

[](http://www.youtube.com/watch?v=52OxtHa7qT0)

Share

[](http://www.youtube.com/watch?v=52OxtHa7qT0 "Share link")- [x] Include playlist 

An error occurred while retrieving sharing information. Please try again later.

![Image 6](http://www.youtube.com/watch?v=52OxtHa7qT0)

0:00

[](http://www.youtube.com/watch?v=52OxtHa7qT0)[](https://www.youtube.com/watch?v=00f3Ks3qkJI "Next (SHIFT+n)")

0:00 / 0:00 Live

•Watch full video

•

•

[4:45 A WORLD I BARELY UNDERSTAND (Princess Twilight Song) [Industrial Metal]Elias Frost 2.1K views • 2 months ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=00f3Ks3qkJI)[1:16:32 DCU: All-Star Superman Action & adventure • 2011 3 months ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=MGHaT7m3ys4)[13:56 Sombra Deserved BETTER SPOOKY CXCD 85K views • 11 months ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=ws6AjjgY-F0)[29:42 POV: What You Would See During an AI Takeover Species | Documenting AGI 693K views • 5 days ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=D8RtMHuFsUw)[13:01 These Statues are Cursed...StoryBoredz 50K views • 19 hours ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=8yuSmAiSYvw)[4:18 AZURE CHASE THEME (UST) WITH LYRICS | FORSAKEN ches 339K views • 6 months ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=tzRqRENQ_Cw)[19:19 "No Kings" Protests Defy GOP Expectations & Jon Gives Trump a Royal Inspection | The Daily Show The Daily Show 5.8M views • 4 days ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=ggIBtdtypCw)[41:49 Searching For A World That Doesn’t Exist Wifies 952K views • 19 hours ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=3V7Rvo4Gvic)[5:12 Prince & Jalmaan - Enemy Undefined (Destabilize pt.3) [MLP MUSIC]PrinceWhateverer 1.7M views • 4 years ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=E8eBdZR0Qeo)[6:01 Umbrella Corp. [RESIDENT EVIL theme] (Cover by Elias Frost)Elias Frost 224K views • 3 years ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=oeEj1BkGwiw)[3:11 {Calamity Ganon / Malice} I Am the Curse | Legend of Zelda Song Mythic Melodies 99 views • 2 weeks ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=-U_bNdyjrt0)[2:30 CG5 - Locked Away (from Dandy's World)CG5 3.2M views • 7 days ago Live Playlist ()Mix (50+)](https://www.youtube.com/watch?v=GVU9bmt1QK4)

Sign in to confirm you’re not a bot This helps protect our community. [Learn more](https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube)

[Sign in](https://accounts.google.com/ServiceLogin?service=youtube&uilel=3&passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Faction_handle_signin%3Dtrue%26app%3Ddesktop%26hl%3Den%26next%3D%252Fwatch%253Fv%253D52OxtHa7qT0&hl=en)

CRYSTAL CURSE (King Sombra song) [METAL]
========================================

[![Image 7: Elias Frost](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s48-c-k-c0x00ffffff-no-rj)](http://www.youtube.com/@Elias_Frost)

[Elias Frost](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w)

 Elias Frost 

 Official Artist Channel 

6.1K subscribers

Subscribe

Subscribed

157

Share

Download

 Download 

3K views 3 months ago

 3,095 views • Premiered Jul 20, 2025 

Show less 

Hi! It's been a while since my last video here:) I've been working on something cool, and heavy XD…...more 

...more 

Transcript

Follow along using the transcript.

Show transcript

[![Image 8](http://www.youtube.com/watch?v=52OxtHa7qT0) ### Elias Frost 6.1K subscribers](http://www.youtube.com/@Elias_Frost)

[Videos](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/videos)

[About](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/about)

[Videos](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/videos)[About](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/about)

[![Image 9](http://www.youtube.com/watch?v=52OxtHa7qT0) 3:31 3:31](http://www.youtube.com/watch?v=lUWAHn0Ooi4)[This world needs a change (Chrysalis Anime Opening song) by Elias Frost](http://www.youtube.com/watch?v=lUWAHn0Ooi4)

[![Image 10](http://www.youtube.com/watch?v=52OxtHa7qT0)57 57](http://www.youtube.com/watch?v=q6Ptb90wd3E&list=PLIDDtsNf_UbnMCGiEnFcOMwc61lxitWGm)

My little Metal

by Elias Frost

[![Image 11](http://www.youtube.com/watch?v=52OxtHa7qT0) Patreon support](https://www.youtube.com/redirect?event=infocard&redir_token=QUFFLUhqbHVnRXhsRENBTmlxMXd1cm5lQTJhOE5KaUg1QXxBQ3Jtc0ttelMtS3VSc0NXVU5KRFZhVWJ6YjJUSDhDSEFiSFczNW9nMWtsWEdJWFVOdlIteldWODBLbW42Z0V0SXU5TFhKUUlHVWF5ajhOelU0RXpxWHJZMUxXQkxmdnVuMkM2NmR6TjI5c1RHYThZTk5SejhqMA&q=https%3A%2F%2Fwww.patreon.com%2Feliasfrost)

[![Image 12](http://www.youtube.com/watch?v=52OxtHa7qT0) BandCamp All my music is here](https://www.youtube.com/redirect?event=infocard&redir_token=QUFFLUhqbHd4X0NvYWg0dmw3QlJjWDNmeDYyNkNjdHVGQXxBQ3Jtc0trRHVuSG1nZGhfWEVCZ25lU2ZsS2hDTXhiMTJqWW5VSDRmdlRwYWt0SzF2VTlHVjJoMFNkVzlGcWtzTW1mc2pXcTF4X0JSRDhtR1JrV2JJbEJ5VEs1cE85QzE5d3o3MW5NVkQ5ZVJKV2lZdTU1dVRBSQ&q=https%3A%2F%2Feliasfrost.bandcamp.com%2F)

Show less 

Live chat replay
----------------

See what others said about this video while it was live.

Open panel

[](http://www.youtube.com/watch?v=52OxtHa7qT0)
CRYSTAL CURSE (King Sombra song) [METAL]
========================================

3,095 views 3K views

Premiered Jul 20, 2025

157

Share

Download

 Download 

Save

33 Comments
-----------

 Sort comments 

Sort by

[Top comments](http://www.youtube.com/watch?v=52OxtHa7qT0)[Newest first](http://www.youtube.com/watch?v=52OxtHa7qT0)

![Image 13: Default profile photo](https://yt3.ggpht.com/a/default-user=s48-c-k-c0x00ffffff-no-rj)

Add a comment...

![Image 14](https://yt3.ggpht.com/5FiAS-euDMwd5EuX5ney_O39KGgNxpHquD_rWaj7ZDnT0Vm4Tbyz0oyd7jpH7SCmzDSJ4SXsJA=s88-c-k-c0x00ffffff-no-rj)

### [@RavenFlight_Music](http://www.youtube.com/@RavenFlight_Music)

[@RavenFlight_Music @RavenFlight_Music](http://www.youtube.com/@RavenFlight_Music)[2 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugw4Gev_Qfcr9TKT6ql4AaABAg)

Oh you have a new fellow metal/rock pony fan right here. Love your work!!

Show less Read more

 Like 

 5 

 Dislike 

![Image 15](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s88-c-k-c0x00ffffff-no-rj)

 ❤ by @Elias_Frost 

Reply

![Image 16](https://yt3.ggpht.com/IDnKeuW01_aObqCm_zcge58L707awIRvAEdXzmbPMj3ZQ6YidTYRFunmpAQMppDTw9PjKspocug=s88-c-k-c0x00ffffff-no-rj)

### [@ASingleApe](http://www.youtube.com/@ASingleApe)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwaRHt_-ixinWJg6614AaABAg)

Fantastically done! He was always my favorite villain and the song feels just perfect

Show less Read more

 Like 

 6 

 Dislike 

![Image 17](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s88-c-k-c0x00ffffff-no-rj)

 ❤ by @Elias_Frost 

Reply

![Image 18](https://yt3.ggpht.com/LHa2FJ1OYwjiarVOD5ttCFobYFejaUVx0ld7Q1zYqTi_4tCTg6pKMu8G6f9KGCO1-Pr9IbcN=s88-c-k-c0x00ffffff-no-rj)

### [@pegasuscheese4457](http://www.youtube.com/@pegasuscheese4457)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgxUWwkSLm5cwRwn8BN4AaABAg)

![Image 19: 🙌](https://www.youtube.com/s/gaming/emoji/7ff574f2/emoji_u1f64c.png)Absolute music![Image 20: 🙌](https://www.youtube.com/s/gaming/emoji/7ff574f2/emoji_u1f64c.png)

Show less Read more

 Like 

 4 

 Dislike 

![Image 21](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s88-c-k-c0x00ffffff-no-rj)

 ❤ by @Elias_Frost 

Reply

![Image 22](https://yt3.ggpht.com/ytc/AIdro_l1MfHi3QnkEvrYs09F8pMMHMbjRLyxInTbsi_MDTA=s88-c-k-c0x00ffffff-no-rj)

### [@dustindiedrich4054](http://www.youtube.com/@dustindiedrich4054)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgyyFg7BuL7dPFHF1h94AaABAg)

Dude! Epic A.F !!!!!!!!! I love it

Show less Read more

 Like 

 4 

 Dislike 

![Image 23](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s88-c-k-c0x00ffffff-no-rj)

 ❤ by @Elias_Frost 

Reply

![Image 24](https://yt3.ggpht.com/ytc/AIdro_lFkjUTKmSqWNv1SaKXGcxSutkxnKsGr_R0qnRjGWY=s88-c-k-c0x00ffffff-no-rj)

### [@KWW-bf2km](http://www.youtube.com/@KWW-bf2km)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwnTR1xAO_xuaYw10t4AaABAg)

Great original song! I can't wait for more songs from this series. Also maybe You post rarely but at least You still keep posting quality songs, which I think is the most important thing.

Show less Read more

 Like 

 9 

 Dislike 

![Image 25](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s88-c-k-c0x00ffffff-no-rj)

 ❤ by @Elias_Frost 

Reply

![Image 26: Elias Frost](https://yt3.ggpht.com/ytc/AIdro_lRfZ1H_mGAG1Qa5Aa7S171rpYkHR3K86PhElb2vJfREUs=s48-c-k-c0x00ffffff-no-rj)

·

1 reply

![Image 27](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 28](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 29](https://yt3.ggpht.com/ytc/AIdro_m-dY0hP-jDe8XXLmTrgewYH4i8zOftRg8vtdkT-2oHiA=s88-c-k-c0x00ffffff-no-rj)

### [@gotic1926](http://www.youtube.com/@gotic1926)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugyz-pgcVd6mfiOTok54AaABAg)

From second1 start a shiver down my spine for nearly 5 minutes. 5 Minutes of a great work. The song is so cool.

Show less Read more

 Like 

 2 

 Dislike 

![Image 30](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 31](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@MillerTheDragon1995](http://www.youtube.com/@MillerTheDragon1995)

[12 days ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwcFc_n80E7s9zO-a54AaABAg)

crystals of darkess and hatred king Sombra: friendship is for the weak because friendship would stab you in back when given the chance too friendship likes to hide behind fake smiles that hide the truth from us

Show less Read more

 Like 

 1 

 Dislike 

![Image 32](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 33](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@ki-pattao9030](http://www.youtube.com/@ki-pattao9030)

[1 month ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgxT-1uIzhgHuIvXhvR4AaABAg)

Long live the King of Darkness.

Show less Read more

 Like 

 2 

 Dislike 

![Image 34](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 35](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@Feuerangst826](http://www.youtube.com/@Feuerangst826)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwsfTgQfdCRVsvMDaB4AaABAg)

Goes hard, I'm glad to see more awesome music. I feel like everyone has been putting out some banger pony songs. Keep it up /)

Show less Read more

 Like 

 4 

 Dislike 

![Image 36](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 37](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@Calciferchik_TV](http://www.youtube.com/@Calciferchik_TV)

[1 month ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgzX4KYc25d8L4QEN9N4AaABAg)

Я недавно прочитал комикс про Короля Сомбру. Песня идеально ему подходит!

Show less Read more

 Like 

 2 

 Dislike 

![Image 38](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 39](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@RomeoMan11](http://www.youtube.com/@RomeoMan11)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgzpJqvT6ecZK3txQ9R4AaABAg)

Amazing song!![Image 40: ❤‍🔥](http://www.youtube.com/watch?v=52OxtHa7qT0) (btw, in vid description it says "burning desires" instead of "blind desires")

Show less Read more

 Like 

 4 

 Dislike 

![Image 41](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 42](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 43](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 44](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 45](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@alphawarhed](http://www.youtube.com/@alphawarhed)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgzUuIYLWE_Z12PnJLx4AaABAg)

It's adorable! Thank you!

Show less Read more

 Like 

 5 

 Dislike 

![Image 46](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 47](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 48](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 49](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 50](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@Kvass1315](http://www.youtube.com/@Kvass1315)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugz1ZcSl1OFyzV9L9pN4AaABAg)

Похоже, у меня появилась новая любимая песня... Мне часто кажется, что песни, посвященные Королю Сомбре не всегда совпадают с моим ощущением этого персонажа, которого я очень люблю. Очень редкие исключения, в которых я вижу это самое "да, это оно, оно звучит также, как я чувствую его". Не знаю, как более внятно описать это чувство. Но здесь я уже с первой минуты чувствую, что да. Это Король Сомбра. Его вайб. Точнейшее попадание. Жестокий, эпичный и величественный. Но при этом, полный боли. В общем, абсолютный шедевр, спасибо за твои треки, Elias Frost и за то, что так много лет продолжаешь творить, привнося своё искусство в этот фандом

Show less Read more

 Like 

 6 

 Dislike 

![Image 51](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 52](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 53](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 54](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 55](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@venomsbite3925](http://www.youtube.com/@venomsbite3925)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwZ4dYVA4611ziJcY54AaABAg)

Ah hell yeah! Super epic song!

Show less Read more

 Like 

 6 

 Dislike 

![Image 56](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 57](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 58](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 59](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 60](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@BGMPonyDegeneracy](http://www.youtube.com/@BGMPonyDegeneracy)

[2 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugwl9KuEeynstqJrq4t4AaABAg&pp=0gcJCSIANpG00pGi)

This is awesome!

Show less Read more

 Like 

 2 

 Dislike 

![Image 61](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 62](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@pashkek3884](http://www.youtube.com/@pashkek3884)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugx6K2IL0ij0tavCbDV4AaABAg)

Amazing ![Image 63: ❤](http://www.youtube.com/watch?v=52OxtHa7qT0)

Show less Read more

 Like 

 1 

 Dislike 

![Image 64](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 65](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 66](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 67](http://www.youtube.com/watch?v=52OxtHa7qT0)

·

1 reply

![Image 68](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@WolfX1120](http://www.youtube.com/@WolfX1120)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugw4WROC0K7iM9TPnqV4AaABAg)

So awesome }:3 Great job,,, /)

Show less Read more

 Like 

 5 

 Dislike 

![Image 69](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 70](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@saranoxx709](http://www.youtube.com/@saranoxx709)

[2 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=Ugy0FTK8k97JGHYKY6d4AaABAg)

Безусловно, это выдающаяся композиция, которая идеально подходит одному из главных антагонистов! Она такая же мрачная и тяжёлая, как и его судьба. Музыка и слова великолепно передают его силу и величие, и это неоспоримо.

Show less Read more

 Like 

 2 

 Dislike 

![Image 71](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 72](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@FdotsgtCIIR](http://www.youtube.com/@FdotsgtCIIR)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgzyJUFIXnrdju8-cFR4AaABAg)

![Image 73: 💠](http://www.youtube.com/watch?v=52OxtHa7qT0)![Image 74: 🖤](http://www.youtube.com/watch?v=52OxtHa7qT0)![Image 75: 💠](http://www.youtube.com/watch?v=52OxtHa7qT0)

Show less Read more

 Like 

 Dislike 

![Image 76](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

![Image 77](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [@pegasuscheese4457](http://www.youtube.com/@pegasuscheese4457)

[3 months ago](http://www.youtube.com/watch?v=52OxtHa7qT0&lc=UgwqnpMPUl8MD-xDm5N4AaABAg)

Я всё думаю Насколько этот антагонист мог быть интересным персонажем если авторы на нем словили фиксацию Его эстетический вид отпечатывается в воспоминаниях, для его родной вселенной разноцветных пони и дружбымагии, этот дестопичный диктатор тиран, выглядит очень бруталтно Музыкальная тема идеально ложиться на этого персонажа! ![Image 78: ❤](http://www.youtube.com/watch?v=52OxtHa7qT0)![Image 79: ❤](http://www.youtube.com/watch?v=52OxtHa7qT0)

Show less Read more

 Like 

 3 

 Dislike 

![Image 80](http://www.youtube.com/watch?v=52OxtHa7qT0)

 ❤ by @Elias_Frost 

Reply

NaN / NaN

![Image 81](http://www.youtube.com/watch?v=52OxtHa7qT0)

Comments 33
-----------

[Top comments](http://www.youtube.com/watch?v=52OxtHa7qT0)[Newest first](http://www.youtube.com/watch?v=52OxtHa7qT0)

![Image 82](http://www.youtube.com/watch?v=52OxtHa7qT0)

Description
-----------

CRYSTAL CURSE (King Sombra song) [METAL]

Hi! It's been a while since my last video here:) I've been working on something cool, and heavy XD Crystal Curse is the first in series of songs inspired by the darker side of the events and characters of My Little Pony. This time, the song is about King Sombra! [You can get this song here]: [https://eliasfrost.bandcamp.com/track...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbGtCODZSYXIyM2tucXVZMmVfY0p0WlpEalhHQXxBQ3Jtc0tsNFlHR3pxMXh6NnByQ1NXbE9CSm1mWk5OQlRseVRGWWhJbUxrZE9xVFVEUEpmc2EzRVozamk0NFZpMmtfNU9BMFEwQjc4alAtWDVudm45OWxlamJxOGtIOW9TT0NhQmRTWDJhLTh1X0t6OThaLWxlSQ&q=https%3A%2F%2Feliasfrost.bandcamp.com%2Ftrack%2Fcrystal-curse&v=52OxtHa7qT0) //// Subscribe! and Support me on Patreon: [![Image 83](http://www.youtube.com/watch?v=52OxtHa7qT0)/eliasfrost](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVZ0cWgwMWp5Rkx3aEIzVGpLSHlLRHFrVExsd3xBQ3Jtc0ttTXVNRjFSTEg1eGh2ZExJRnVnTHJmN1dGemdqZEFTS2ZqckFYNURFZl9mV3RPSEN5Nl9Ienp0dHVzZEVyZl95eE4wNHBra3ZJWkMya2dfZThORTU5T3FWVUpJclJ1U21qUkl5eW4wSW1VMnVVYktqaw&q=https%3A%2F%2Fwww.patreon.com%2Feliasfrost&v=52OxtHa7qT0) Follow me on twitter X: [![Image 84](http://www.youtube.com/watch?v=52OxtHa7qT0)/eliasfrosttwits](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbDJCakIwR2ZQV3U1MjZGUzhjdmRLVHh3Y3Uxd3xBQ3Jtc0ttdVhiczVnaGxQMDFDSUFIV1ZabHNUSU9mXzV0X1NvMGo1SHNDcWJwTU8wLUJNNWhnemVnYTFiNUhSbHY1bE51ZHRGOUFaTjlFYUxNMUVmWW8ySFZrVUtlcnJSU2xHeXNLc2R5QURwM1ZJbFZXNDJNWQ&q=https%3A%2F%2Ftwitter.com%2FEliasFrostTwits&v=52OxtHa7qT0) //// Поддержать на Boosty: [https://boosty.to/eliasfrost](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbEtQNkVxaXM1UkUzWFVSeF95TjFhNS1Fdm1JQXxBQ3Jtc0tsNnJmRkR5cG1LLU9QSURId19hcW95Z2hhM3ZSSWhrWlZodFgzN2F3SEFOQnAtcXZkMGIxSHlCUEZHejJWT0diRm1UNUg5SUhBdVZ3amFoVG54a0NIM1hkYUlqM0xzdDJnT2pzRnJqOTU5TDZoTlBZSQ&q=https%3A%2F%2Fboosty.to%2Feliasfrost&v=52OxtHa7qT0) Music and Lyrics by Elias Frost Recorded and Mixed by Elias Frost [Verse 1] In the darkened halls of crystal spires, A shadow king, with blind desires, Eyes like obsidian, heart of ice, He plots and schemes, in the dead of night. Crystal ponies, trembling in fear, The reign of Sombra, drawing near, With every breath, he feels the pull, The Crystal Heart, his destiny's lull. [Chorus] Oh, the heart of light, in shadows’ grasp, A crystal curse, in darkness cast, King Sombra's soul, forever bound, To the Crystal Heart, his fate is found. [Verse 2] In the caverns deep beneath the throne, He whispers secrets, the dark unknown, The Heart's pure light, his only need, A twisted love, born of darkened greed. [Chorus] Oh, the heart of light, in shadows’ grasp, A crystal curse, in darkness cast, King Sombra's soul, forever bound, To the Crystal Heart, his fate is found. [Verse 3] Echoes of despair, in the crystal air, A monarch's madness, a love so rare, He'll never rest, until it's his, The Crystal Heart, his eternal bliss. [Verse 4] In the final hour, the battle's roar, A clash of light and shadow war, The Crystal Heart, its light will shine, But Sombra's soul, forever binds. His legacy, a shadow's dream, Its crystal shards, a silent scream, For even in the darkest night, The Crystal Heart, his guiding light. [Chorus] Oh, the heart of light, in shadows’ grasp, A crystal curse, in darkness cast, King Sombra's soul, forever bound, To the Crystal Heart, his fate is found.…...more 

...more Show less 

Transcript

Follow along using the transcript.

Show transcript

[![Image 85](http://www.youtube.com/watch?v=52OxtHa7qT0) ### Elias Frost 6.1K subscribers](http://www.youtube.com/@Elias_Frost)

[Videos](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/videos)

[About](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/about)

[Videos](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/videos)[About](http://www.youtube.com/channel/UCblJ5dEUBY8TWk-By1F_2_w/about)

[![Image 86](http://www.youtube.com/watch?v=52OxtHa7qT0) 3:31 3:31](http://www.youtube.com/watch?v=lUWAHn0Ooi4)[This world needs a change (Chrysalis Anime Opening song) by Elias Frost](http://www.youtube.com/watch?v=lUWAHn0Ooi4)

[![Image 87](http://www.youtube.com/watch?v=52OxtHa7qT0)57 57](http://www.youtube.com/watch?v=q6Ptb90wd3E&list=PLIDDtsNf_UbnMCGiEnFcOMwc61lxitWGm)

My little Metal

by Elias Frost

[![Image 88](http://www.youtube.com/watch?v=52OxtHa7qT0) Patreon support](https://www.youtube.com/redirect?event=infocard&redir_token=QUFFLUhqbHVnRXhsRENBTmlxMXd1cm5lQTJhOE5KaUg1QXxBQ3Jtc0ttelMtS3VSc0NXVU5KRFZhVWJ6YjJUSDhDSEFiSFczNW9nMWtsWEdJWFVOdlIteldWODBLbW42Z0V0SXU5TFhKUUlHVWF5ajhOelU0RXpxWHJZMUxXQkxmdnVuMkM2NmR6TjI5c1RHYThZTk5SejhqMA&q=https%3A%2F%2Fwww.patreon.com%2Feliasfrost)

[![Image 89](http://www.youtube.com/watch?v=52OxtHa7qT0) BandCamp All my music is here](https://www.youtube.com/redirect?event=infocard&redir_token=QUFFLUhqbHd4X0NvYWg0dmw3QlJjWDNmeDYyNkNjdHVGQXxBQ3Jtc0trRHVuSG1nZGhfWEVCZ25lU2ZsS2hDTXhiMTJqWW5VSDRmdlRwYWt0SzF2VTlHVjJoMFNkVzlGcWtzTW1mc2pXcTF4X0JSRDhtR1JrV2JJbEJ5VEs1cE85QzE5d3o3MW5NVkQ5ZVJKV2lZdTU1dVRBSQ&q=https%3A%2F%2Feliasfrost.bandcamp.com%2F)

![Image 90](http://www.youtube.com/watch?v=52OxtHa7qT0)

Transcript
----------

Show chat replay

[![Image 91](https://i.ytimg.com/vi/00f3Ks3qkJI/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLC_K9qDcLP_xuanN5cQJrM1wr8_iA) 4:45](http://www.youtube.com/watch?v=00f3Ks3qkJI&list=RD00f3Ks3qkJI&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

![Image 92](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [A WORLD I BARELY UNDERSTAND (Princess Twilight Song) [Industrial Metal]](http://www.youtube.com/watch?v=00f3Ks3qkJI&list=RD00f3Ks3qkJI&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

Elias Frost

2.1K views • 2 months ago

[![Image 93](https://lh3.googleusercontent.com/G9QNOeiMnOfqFwy9NiLPK5In2MbEDusU-yEb4-2cJ1iKyXKnFNzzV68KTedB0tvO_RA-x3dh2_LF) 1:16:32 1:16:32 Now playing](http://www.youtube.com/watch?v=MGHaT7m3ys4&pp=sAQB)

[### DCU: All-Star Superman YouTube Movies & TV YouTube Movies & TV • • Action & adventure • 2011 Free with ads PG](http://www.youtube.com/watch?v=MGHaT7m3ys4&pp=sAQB)

[![Image 94](https://i.ytimg.com/vi/ws6AjjgY-F0/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCr_4li3xTpL2jUKHKzhQvW67HTtA) 13:56](http://www.youtube.com/watch?v=ws6AjjgY-F0)

![Image 95](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Sombra Deserved BETTER](http://www.youtube.com/watch?v=ws6AjjgY-F0)

SPOOKY CXCD

85K views • 11 months ago

[![Image 96](https://i.ytimg.com/vi/D8RtMHuFsUw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCmkV3fFnzvJPOQv_gnlVUE3wPE5w) 29:42](http://www.youtube.com/watch?v=D8RtMHuFsUw)

![Image 97](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [POV: What You Would See During an AI Takeover](http://www.youtube.com/watch?v=D8RtMHuFsUw)

Species | Documenting AGI

693K views • 5 days ago

New

[![Image 98](https://i.ytimg.com/vi/8yuSmAiSYvw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCyCv4Ihpd8B6u8p9Qq7gj6y5SFrQ) 13:01](http://www.youtube.com/watch?v=8yuSmAiSYvw)

![Image 99](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [These Statues are Cursed...](http://www.youtube.com/watch?v=8yuSmAiSYvw)

StoryBoredz

50K views • 19 hours ago

New

[![Image 100](https://i.ytimg.com/vi/tzRqRENQ_Cw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAEIQNScOaUGxgyQ1AoHYKbjPddlQ) 4:18](http://www.youtube.com/watch?v=tzRqRENQ_Cw&list=RDtzRqRENQ_Cw&start_radio=1&pp=oAcB)

![Image 101](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [AZURE CHASE THEME (UST) WITH LYRICS | FORSAKEN](http://www.youtube.com/watch?v=tzRqRENQ_Cw&list=RDtzRqRENQ_Cw&start_radio=1&pp=oAcB)

ches

339K views • 6 months ago

[![Image 102](https://i.ytimg.com/vi/ggIBtdtypCw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLB-9Iog6fZ4xobskvO1f2mm4LGhnA) 19:19](http://www.youtube.com/watch?v=ggIBtdtypCw)

![Image 103](http://www.youtube.com/watch?v=52OxtHa7qT0)

### ["No Kings" Protests Defy GOP Expectations & Jon Gives Trump a Royal Inspection | The Daily Show](http://www.youtube.com/watch?v=ggIBtdtypCw)

The Daily Show

5.8M views • 4 days ago

New

[![Image 104](https://i.ytimg.com/vi/3V7Rvo4Gvic/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAbijKPsPbUKayXWRP69xfMXc6LCA) 41:49](http://www.youtube.com/watch?v=3V7Rvo4Gvic)

![Image 105](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Searching For A World That Doesn’t Exist](http://www.youtube.com/watch?v=3V7Rvo4Gvic)

Wifies

952K views • 19 hours ago

New

[![Image 106](https://i.ytimg.com/vi/E8eBdZR0Qeo/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAoNB6y_P3XWSnr7N7gvf6B6i5cqQ) 5:12](http://www.youtube.com/watch?v=E8eBdZR0Qeo&list=RDE8eBdZR0Qeo&start_radio=1&pp=oAcB)

![Image 107](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Prince & Jalmaan - Enemy Undefined (Destabilize pt.3) [MLP MUSIC]](http://www.youtube.com/watch?v=E8eBdZR0Qeo&list=RDE8eBdZR0Qeo&start_radio=1&pp=oAcB)

PrinceWhateverer

1.7M views • 4 years ago

[![Image 108](https://i.ytimg.com/vi/oeEj1BkGwiw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCd5hz3y1VBYIP6u4qQPFkvsJz64Q) 6:01](http://www.youtube.com/watch?v=oeEj1BkGwiw&list=RDoeEj1BkGwiw&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

![Image 109](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Umbrella Corp. [RESIDENT EVIL theme] (Cover by Elias Frost)](http://www.youtube.com/watch?v=oeEj1BkGwiw&list=RDoeEj1BkGwiw&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

Elias Frost

224K views • 3 years ago

[![Image 110](http://www.youtube.com/watch?v=52OxtHa7qT0) 3:11](http://www.youtube.com/watch?v=-U_bNdyjrt0&list=RD-U_bNdyjrt0&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

![Image 111](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [{Calamity Ganon / Malice} I Am the Curse | Legend of Zelda Song](http://www.youtube.com/watch?v=-U_bNdyjrt0&list=RD-U_bNdyjrt0&start_radio=1&pp=oAcB0gcJCQYKAYcqIYzv)

Mythic Melodies

99 views • 2 weeks ago

[![Image 112](http://www.youtube.com/watch?v=52OxtHa7qT0) 2:30](http://www.youtube.com/watch?v=GVU9bmt1QK4&list=RDGVU9bmt1QK4&start_radio=1&pp=oAcB)

![Image 113](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [CG5 - Locked Away (from Dandy's World)](http://www.youtube.com/watch?v=GVU9bmt1QK4&list=RDGVU9bmt1QK4&start_radio=1&pp=oAcB)

CG5

3.2M views • 7 days ago

[![Image 114](http://www.youtube.com/watch?v=52OxtHa7qT0) 4:40](http://www.youtube.com/watch?v=4ew1g49YfmQ&list=RD4ew1g49YfmQ&start_radio=1&pp=oAcB)

![Image 115](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Enchantment of the Illusionist (Trixie Song) [Gothic Metal]](http://www.youtube.com/watch?v=4ew1g49YfmQ&list=RD4ew1g49YfmQ&start_radio=1&pp=oAcB)

Elias Frost

1.3K views • 2 months ago

[![Image 116](http://www.youtube.com/watch?v=52OxtHa7qT0) 5:05](http://www.youtube.com/watch?v=jfmhOKpQwuM&list=RDjfmhOKpQwuM&start_radio=1&pp=oAcB)

![Image 117](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [[MLP FiM] King Sombra Boss Battle Theme](http://www.youtube.com/watch?v=jfmhOKpQwuM&list=RDjfmhOKpQwuM&start_radio=1&pp=oAcB)

KingSpartaX37

161K views • 13 years ago

[![Image 118](http://www.youtube.com/watch?v=52OxtHa7qT0) 5:09](http://www.youtube.com/watch?v=hZb_wOnWj0c&list=RDhZb_wOnWj0c&start_radio=1&pp=oAcB)

![Image 119](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Jyc Row & PrinceWhateverer - Pegasus Device 2022 (feat. Celica Soldream) [covering SlyphStorm]](http://www.youtube.com/watch?v=hZb_wOnWj0c&list=RDhZb_wOnWj0c&start_radio=1&pp=oAcB)

Jyc Row - Infinite Eclipse

538K views • 2 years ago

[![Image 120](http://www.youtube.com/watch?v=52OxtHa7qT0) 1:12:06](http://www.youtube.com/watch?v=RiugDDK5vO4&list=RDRiugDDK5vO4&start_radio=1&pp=oAcB)

![Image 121](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [🔥CHRONOS FANTASY ADVENTURE 🎸 Celtic Rock & Metal Vocal ✨ 1Hr Medieval Music for Work Gaming & Focus](http://www.youtube.com/watch?v=RiugDDK5vO4&list=RDRiugDDK5vO4&start_radio=1&pp=oAcB)

KageYume

2.3K views • 3 days ago

New

[![Image 122](http://www.youtube.com/watch?v=52OxtHa7qT0) 5:08](http://www.youtube.com/watch?v=wxsk-DRcacY&list=RDwxsk-DRcacY&start_radio=1&pp=oAcB)

![Image 123](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Jyc Row & PrinceWhateverer - Final Eclipse (feat. Celica Soldream)](http://www.youtube.com/watch?v=wxsk-DRcacY&list=RDwxsk-DRcacY&start_radio=1&pp=oAcB)

Jyc Row - Infinite Eclipse

1.4M views • 5 years ago

[![Image 124](http://www.youtube.com/watch?v=52OxtHa7qT0) 7:17](http://www.youtube.com/watch?v=AeiCnqG9l9o&list=RDAeiCnqG9l9o&start_radio=1&pp=oAcB)

![Image 125](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Devil May Cry [Dante Battle theme fan song]](http://www.youtube.com/watch?v=AeiCnqG9l9o&list=RDAeiCnqG9l9o&start_radio=1&pp=oAcB)

Elias Frost

881 views • 1 month ago

[![Image 126](http://www.youtube.com/watch?v=52OxtHa7qT0) 4:59](http://www.youtube.com/watch?v=yOp57AOLJPQ&list=RDyOp57AOLJPQ&start_radio=1&pp=oAcB)

![Image 127](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [Embrace Your Humanity - A Warhammer 40k Emperor of Mankind Inspired Song #warhammer #sunoai](http://www.youtube.com/watch?v=yOp57AOLJPQ&list=RDyOp57AOLJPQ&start_radio=1&pp=oAcB)

Endless Taverns

395K views • 5 months ago

[![Image 128](http://www.youtube.com/watch?v=52OxtHa7qT0) 4:39](http://www.youtube.com/watch?v=ROSV9QgdG7Y&list=RDROSV9QgdG7Y&start_radio=1&pp=oAcB)

![Image 129](http://www.youtube.com/watch?v=52OxtHa7qT0)

### [LORD OF CHAOS (Discord song) [Metal]](http://www.youtube.com/watch?v=ROSV9QgdG7Y&list=RDROSV9QgdG7Y&start_radio=1&pp=oAcB)

Elias Frost

935 views • 2 weeks ago

Show more

[[](http://www.youtube.com/watch?v=52OxtHa7qT0)](http://www.youtube.com/watch?v=52OxtHa7qT0)
]]></description>
</item>
</channel>
</rss>
